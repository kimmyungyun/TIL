# 머신러닝

## 목적

최적화 기술을 사용해 데이터가 주어진 모델 매개변수의 비용 함수를 최소화 하는 것

크게 지도, 비지도 머신 러닝으로 나뉜다

### 지도 학습

- 모델은 입력 특성 벡터가 주어진 경우 출력 레이블의 예측에 필요한 여러 매개변수로 구성
- 모델 매개변수는 예측 에러에 기초한 비용 함수를 최적화



### 비지도 학습

- 입력 데이터에 대한 흥미로운 변환을 찾는 것
- 지도 학습 문제를 풀기 전, 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계
- 대표적인 것이 차원 축소, 군집과 같은 방법



### 강화 학습

- agent는 환경에 대한 정보를 받아 보상을 최대화 하는 행동을 선택하도록 학습
- 알파고처럼 바둑판을 입력 받고, 그에 대해서 보상(승리)을 최대화 하는 행동을 선택하는 것



## 데이터셋을 나누는 방법

### 단순 홀드아웃 검정(Hold-out cross-validation)

- 데이터의 일정량을 테스트 세트로 나누는 것
- 데이터가 적을 때는 검증 세트와 테스트 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표할 수 없다



### K-겹 교차 검증(K-fold cross-validation)

- 데이터를 동일한 크기를 가진 K개로 분할
- 각 분할에 대해서 K-1개로 학습하고, 나머지 1개로 모델을 평가
- 최종 점수는 K개의 평균으로 사용




## 머신러닝 환경설정 이유

- 2의 x승으로 미니배치 사이즈를 잡는데 그 이유는 메모리 할당이 되지 않는 구간이 생길 가능성이 높아서 메모리 낭비를 줄이기 위해
- 데이터를 셔플하는 이유는 셔플하는 것만으로도 새로운 데이터로 학습하는 것과 같은 효과가 나타나기 때문

- 학습 비율(lr)
  - SGD의 위의 수식에서 Loss 미분 부분이 너무 커져서 global minimum에 수렴하지 않는 경우를 줄이기 위해서



## 하이퍼파라미터

- 학습 비율(lr - learning rate)
- 배치사이즈
- 모멘텀 값
  - 모멘텀 방식을 사용할 때



## Overfitting

![](https://binarycoders.files.wordpress.com/2019/10/01.png?w=1024)

- Underfitting
  - 학습이 덜 된 상태
- Good Fit/Robust
  - 적절하게 학습이 된 상태
- Overfitting
  - 학습이 과하게 되어 훈렬 셋에 대해서만 예측이 잘되는 상태
- Overfitting 제거 방법
  - 더 많은 데이터를 활용
  - Feature의 개수를 줄인다
  - 적절히 Parameter를 선정한다



## 다중공선성

- 각 독립변수 간에는 서로 연관성이 없이 독립적이어야 함

- 독립변수 간에 연관성이 있는지 다중공선성을 확인하기 위해 VIF를 계산

- VIF를 계산 하는 방법

  - 독립변수가 3개일 때.
    ![](assets/eq1.png)
    을 통해, a, b1, b2를 계산해서 R Score를 계산

    계산된 R스코어를 통해 VIF를 계산
    ![](assets/eq2.png)

- 독립변수를 제거하는 기준

  - VIF 계산이 10이상일 때, 가장 큰 것을 제거
  - 제거된 것을 제외하고 다시 VIF를 계산하면서 불필요한 변수를 제거
  - 상관계수를 통해 확인이 가능하지만 상관계수가 작더라도, 다중공선성이 있는 경우가 있다
  - 그래서 VIF를 꼭 계산해서 비교해봐야한다



## PCA

![](http://i.imgur.com/Uv2dlsH.gif)

- 분산이 가장 넓은 지역을 찾는 것

- 차원 감소를 하는데 사용되는 알고리즘

- 공분산 행렬의 최대값을 구하는데 고유벡터, 고유값이 사용되는 이유

  - 출처 : [다크프로그래머](https://darkpgmr.tistory.com/110)

  - 수식 중
  ![](assets/eq4.png)
    은 행렬 E의 제곱을 나타낸다