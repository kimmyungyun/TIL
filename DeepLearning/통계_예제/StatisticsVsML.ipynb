{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. regression\n",
    "\n",
    "Set : $y = X \\cdot w + b + \\epsilon = X \\cdot w + \\epsilon$\n",
    "- assume for 1 observative : x = (1, x), w = (b, w)\n",
    "\n",
    "We know:  (here, v and X is constant about w)\n",
    "\n",
    "$$\\begin{align}\n",
    "\\cfrac {\\partial}{\\partial w} \\left( v^T \\cdot w \\right) &= v \\\\\n",
    "\\cfrac {\\partial}{\\partial w} \\left( w^T \\cdot v \\right) &= v \\\\\n",
    "(w^T \\cdot X)^T &= X^T \\cdot w \\\\\n",
    "\\cfrac {\\partial}{\\partial w} \\left( w^T \\cdot X \\cdot w \\right) &= X \\cdot w + X^T \\cdot w\n",
    "\\end{align}$$\n",
    "\n",
    "So, We solve: y.shape = (N, ), X.shape=(N, p+1), w.shape = (p+1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "y &= X \\cdot w + \\epsilon = \\hat y + \\epsilon\\\\\n",
    "Loss(w) &= \\epsilon ^2 =||y - \\hat y||^2 = (y - X \\cdot w)^T \\cdot (y - X \\cdot w)\\\\\n",
    "\\cfrac {\\partial Loss}{\\partial w} &= 2 (X^T \\cdot X) \\cdot w - 2X^T \\cdot y = 0 \n",
    "\\end{align}$$\n",
    "\n",
    "We get $\\hat w$ :\n",
    "$$ \\left| {\\cfrac {\\partial Loss}{\\partial w}} \\right|_{w = \\hat w} = 0 \\Rightarrow \n",
    "\\hat w = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y $$\n",
    "\n",
    "### 1.1 Using statistical tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "bunch = load_iris()\n",
    "bunch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(bunch.data, columns=bunch.feature_names)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      "sl    150 non-null float64\n",
      "sw    150 non-null float64\n",
      "pl    150 non-null float64\n",
      "pw    150 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "iris.columns = ['sl', 'sw', 'pl', 'pw']\n",
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "petal width를 target으로 회귀식을 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sl + sw + pl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' + '.join(iris.columns[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pw ~ sl + sw + pl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula = 'y ~ x1 + x2 + x3'\n",
    "features = iris.columns\n",
    "formula = '%s ~ '%iris.columns[3]\n",
    "formula += ' + '.join(iris.columns[:3])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>pw</td>        <th>  R-squared:         </th> <td>   0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   734.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>7.83e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:34:34</td>     <th>  Log-Likelihood:    </th> <td>  36.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>  -65.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   146</td>      <th>  BIC:               </th> <td>  -53.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.2403</td> <td>    0.178</td> <td>   -1.347</td> <td> 0.180</td> <td>   -0.593</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sl</th>        <td>   -0.2073</td> <td>    0.048</td> <td>   -4.363</td> <td> 0.000</td> <td>   -0.301</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sw</th>        <td>    0.2228</td> <td>    0.049</td> <td>    4.553</td> <td> 0.000</td> <td>    0.126</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pl</th>        <td>    0.5241</td> <td>    0.024</td> <td>   21.399</td> <td> 0.000</td> <td>    0.476</td> <td>    0.572</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.609</td> <th>  Durbin-Watson:     </th> <td>   1.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.061</td> <th>  Jarque-Bera (JB):  </th> <td>   6.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.223</td> <th>  Prob(JB):          </th> <td>  0.0332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.944</td> <th>  Cond. No.          </th> <td>    90.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     pw   R-squared:                       0.938\n",
       "Model:                            OLS   Adj. R-squared:                  0.937\n",
       "Method:                 Least Squares   F-statistic:                     734.4\n",
       "Date:                Tue, 24 Dec 2019   Prob (F-statistic):           7.83e-88\n",
       "Time:                        09:34:34   Log-Likelihood:                 36.751\n",
       "No. Observations:                 150   AIC:                            -65.50\n",
       "Df Residuals:                     146   BIC:                            -53.46\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.2403      0.178     -1.347      0.180      -0.593       0.112\n",
       "sl            -0.2073      0.048     -4.363      0.000      -0.301      -0.113\n",
       "sw             0.2228      0.049      4.553      0.000       0.126       0.320\n",
       "pl             0.5241      0.024     21.399      0.000       0.476       0.572\n",
       "==============================================================================\n",
       "Omnibus:                        5.609   Durbin-Watson:                   1.573\n",
       "Prob(Omnibus):                  0.061   Jarque-Bera (JB):                6.811\n",
       "Skew:                           0.223   Prob(JB):                       0.0332\n",
       "Kurtosis:                       3.944   Cond. No.                         90.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(formula = formula, data = iris)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -0.240307\n",
       "sl          -0.207266\n",
       "sw           0.222829\n",
       "pl           0.524083\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using numpy with linear algebra\n",
    "Now, we'll compute with numpy :\n",
    "$$ \\hat w =  (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, _ = load_iris(return_X_y = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set : $y = X \\cdot w + b + \\epsilon = X \\cdot w + \\epsilon$\n",
    "- assume: x = (1, x), w = (b, w). So,\n",
    "- y = X[:, 3]\n",
    "- X = np.hstack(np.ones(shape), X[:, :3])\n",
    "\n",
    "And then, you can use numpy.linalg.inv for inverse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150,), (150, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X[:, 3]\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X[:, :3]))\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat w =  (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24030739, -0.20726607,  0.22282854,  0.52408311])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X's covariant's inverse\n",
    "from numpy.linalg import inv\n",
    "invCov_X = inv(X.T.dot(X))\n",
    "w = invCov_X.dot(X.T).dot(y)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24030739, -0.20726607,  0.22282854,  0.52408311])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Machine Learning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46903266, -0.24571793,  0.41240044,  0.4701742 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import shuffle, rand\n",
    "np.random.seed(234)\n",
    "w = rand(X.shape[-1]) - 0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20000 # 50000\n",
    "batch = 16\n",
    "lr = 0.0001 # 0.00005\n",
    "rows = X.shape[0]\n",
    "losses = []\n",
    "randRow = np.arange(rows)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # for each epoch, shuffle X, y\n",
    "    shuffle(randRow)\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(0, rows, batch):\n",
    "        batch_index = randRow[i:i+batch]\n",
    "        x_batch = X[batch_index]\n",
    "        y_batch = y[batch_index]\n",
    "        y_hat = x_batch.dot(w)\n",
    "        loss += (y_batch - y_hat).dot((y_batch - y_hat))\n",
    "        dw = X.T.dot(X).dot(w) - X.T.dot(y) # = d Loss(w) / d(w)\n",
    "        w -= lr*dw\n",
    "        \n",
    "    loss /= rows\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "Loss(w) &= (y - X \\cdot w)^T \\cdot (y - X \\cdot w)\\\\\n",
    "\\cfrac {\\partial Loss}{\\partial w} &= 2 (X^T \\cdot X) \\cdot w - 2X^T \\cdot y \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24030739, -0.20726607,  0.22282854,  0.52408311])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24030739, -0.20726607,  0.22282854,  0.52408311])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e731e0e6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#matplotlib inline\n",
    "loss_df = pd.DataFrame(losses)\n",
    "loss_df[:100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e731eea710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xU5b3v8c8vNwJIuF+CUQMiglCvkYJXBAoUlZ62ti97qtVq9ezuHnVrb1qttnS3Wmy3nlb3bmmt2tpq1Wq1KlpLjdYLYCiCXERRUIPWYBC5SUKS3/ljVpJJmEkmmUnWXL7v12terPWsZ635zcriN88861lrmbsjIiKZLy/sAEREJDWU0EVEsoQSuohIllBCFxHJEkroIiJZQgldRCRLhJrQzew3ZlZjZmtStL3HzWy7mT3Srvz/mtlGM3MzG9aF7RWb2XIzW2Vma83s+3HqnW9mW83speD1lahlC4N115vZz8zMgvIiM1tkZq+a2Stm9tmg/GAze8rMVprZajObF7WtI83shWB7L5tZcVBeaWYbot5/RFB+ipn908wazOysRPZVd5nZJ8xsRRDXCjObkYrtikgXuHtoL+AU4FhgTYq2NxM4E3ikXfkxQDmwGRgWZ907gOntygw4IJguBJYBU2Osez5wS4zyE4DngPzg9ULzewDfB/4zmM5rjgtYBHw1mD4C2BxMFwCrgaOC+aFAfjBdCVTEeP9y4Ejgt8BZieyrJPb9McDoYHoysCXMY0svvXLxFWoL3d2fAbZFl5nZoUHrcYWZ/cPMJnRhe0uAnTHKV7r75m7E5+6+K5gtDF5duRLLgWKgCOgTrP9esOwC4PrgfZrc/f2odUqC6YHAO8H0bGC1u68K1ql198ZO4t/s7quBphjLYu4rMzvOzJ4O9v8TZlaa0AeN7OPmWNcCxWbWJ5F1RSQ10rEPfRFwibsfB3wD+O8wgzGzfDN7CagBnnT3ZXGqfjboIrnfzA4CcPcXgKeAd4PXE+6+3swGBev8IOgSuc/MRgZl3wPOMbNq4DHgkqB8POBBkv2nmX2r3fvfHnS3fLe5W6cbn7UQ+DmR1vxxwG+AH3ZjU58FVrp7XXfiEJHuKQg7gGhmdgCRbor7onJSn2DZZ4AFMVbb4u5zuvl+c4AfB7MHAyeZ2S6gzt0/DhC0go8OkvCDZjbZ3dv3+f8FuNvd68zs34A7gRlmNg6YCJQF9Z40s1OAdUHZc+5+hZldAfwEOBf4AnCHu//UzKYBvzOzyUT+VicBxwN7gCVmtiJoaX/R3beY2QDgT8F2ftuNXXI4ke6SJ4P9n0/kiwgzuwT4PzHWedHdv9w8Y2aTiOzT2d14fxFJQloldCK/GLa7+9HtF7j7A8ADqXwzd38CeALAzO4gkkgr49TdbmaVwFxgTbtltVGzv6L1S+LTwNLmbhszWwxMBf5BJCk/GNS7D7gwmL4weA/c/YXgxOcwoBp4urlrxsweI3L+YYm7bwnq7zSzPwBT6F5CN2Ctu0+L8fl/TqT1Hn9ls7LgM33J3V/vxvuLSBLSqsvF3XcAm8zscwAWcVRY8ZjZ8ObuETPrC8wCXolRL7qfeT6wPph+CzjVzAqC7oxTgfXu7kRa9dODejOJtNqb15kZbHcikT74rUS+eI40s35mVhBsa12w7WFB/ULgDNp94XTBBmB48MsAMysMWtydCvbTo8BV7v5cN99fRJIR5hlZ4G4iP+n3EWmBXgiMAR4HVhFJctd2YXv/IJL8Pgq2NycovzSYbyBykvHXMda9g/1HuRwJrCQyumRNdCxEun/mB9PXEzkRuIpIn/mEoDwf+CWRBL8O+K+o9Q8Bngm2vQQ4OCg/gsjImFXAS8DsqHXOCd5nDbAwKOsPrAi2sxb4f7SOfjk++Ny7gVoire/O9tXRQVyrgu1dlOC+vyZ4n5eiXiPCPL700ivXXuau2+eKiGSDtOpyERGR7gvtpOiwYcO8vLw8rLcXEclIK1aseN/dh8daFlpCLy8vp6qqKqy3FxHJSGb2Zrxl6nIREckSSugiIllCCV1EJEuk25WiIiI9bt++fVRXV7N3796wQ4mruLiYsrIyCgsLE15HCV1Eck51dTUDBgygvLycbt7Lrke5O7W1tVRXVzNmzJiE11OXi4jknL179zJ06NC0TOYAZsbQoUO7/AtCCV1EclK6JvNm3Ykv9IS+p76BB1dWhx2GiEjGCz2hX/fQWi7/4yqqNm/rvLKISJZ4/PHHOfzwwxk3bhw33HBDSrYZekL/145IH9Hu+g6fpiYikjUaGxv52te+xuLFi1m3bh13330369at63zFToSe0EVEcs3y5csZN24cY8eOpaioiLPPPpuHHnoo6e2mzbBF3cZXRMLw/b+sZd07O1K6zSNGl3DdmfGfDbNlyxYOOuiglvmysjKWLYv3uOLEhd5CT/czzSIiqRarAZuKXJg2LfSanXWcsvApfnfhFA4Z2j/scEQkR3TUku4pZWVlvP322y3z1dXVjB49Ountht9CD/79y6p3eGvbHu58Pu6dIUVEssLxxx/Pa6+9xqZNm6ivr+eee+5h/vz5SW83bVroIiK5oqCggFtuuYU5c+bQ2NjIBRdcwKRJyf9SSDihm1k+UAVscfcz4tQ5C7gPON7du/T0Cp0TFZFcMm/ePObNm5fSbXaly+UyIk+vj8nMBgCXAl06VatzoiIiqZFQQjezMuB04NcdVPsBsBBI3/tRiohksURb6DcD3wKaYi00s2OAg9z9kY42YmYXm1mVmVVt3bq1a5GKiKRQul/70p34Ok3oZnYGUOPuK+IszwNuAr6eQICL3L3C3SuGD2/70GonvXeuiGSP4uJiamtr0zapN98Pvbi4uEvrJXJS9ERgvpnNA4qBEjO7y93PCZYPACYDlcHA+FHAw2Y2v6snRkF96iLS88rKyqiuriadewqan1jUFZ0mdHe/CrgKwMymA9+ISua4+4fAsOZ5M6sM6miUi4ikpcLCwi49CShTdPvCIjNbYGZJj4RXg1xEJDW6dGGRu1cClcH0tXHqTO9OIGqhi4gkJ/xL/9VpLiKSEqEn9GZ79ukBFyIiyQg9oW/bXQ/Aqre3hxyJiEhmCz2h71XLXEQkJUJP6CIikhppmdDrGhrVchcR6aK0TOgnXP93Jnz38bDDEBHJKGmZ0GuDE6UiIpK4tEvoiYxKb2hsoq5BXTIiItHSLqEn4tzblnP4NeqSERGJlpEJ/YU3asMOQUQk7YSe0HXpv4hIaoSe0EVEJDVCT+hqn4uIpEb4CV0ZXUQkJUJN6HvqG1j7zo64y8uvfJTL//hSL0YkIpK5Qk3o7+2o67TOgyu39EIkIiKZL9SEvq+xKan1N72/mxVvbqO+IbntiIhkgy49gi6VGho94Xug79i7j5Liwv3KT/tJJQDnn1DO9+ZPSmV4IiIZJ7QW+vp/7eCb96/erzzWo0Uv+cPKDrf1yr/i98OLiOSKhBO6meWb2UozeyTGsivMbJ2ZrTazJWZ2SHcDuu3ZTfuVPf3q1g7X0QOmRUS61kK/DFgfZ9lKoMLdjwTuBxYmG5iIiHRNQgndzMqA04Ffx1ru7k+5+55gdilQlprwEqOx7CIiibfQbwa+BSQynORCYHGsBWZ2sZlVmVlVgu8rIiIJ6jShm9kZQI27r0ig7jlABXBjrOXuvsjdK9y9osuRBhY+/kp3VxURyWqJDFs8EZhvZvOAYqDEzO5y93OiK5nZLOBq4FR37/yKoW7678rX9yvTSVERkQRa6O5+lbuXuXs5cDbw9xjJ/Bjgl8B8d6/pkUhFRKRD3R6HbmYLzGx+MHsjcABwn5m9ZGYPpyS6KOffvjzusmWbtrHp/d2pfksRkYzSpStF3b0SqAymr40qn5XSqGKo3NDxWPTP/eIFqq7p8TBERNJW6LfPTZXddQ1hhyAiEqqsSegiIrkuKxN6XUNj2CGIiPS6rEvoyzdt4/BrHue5je+HHYqISK/KmoT+0b5Gtmz/iOWbagF4/nUldBHJLVmT0AFOvOHvetiFiOSsjEroK978oNM6P/v7RkBXj4pI7smohP5ydWJPOBIRyUUZldBFRCS+rE3o6nERkVyTUQldSVpEJL6MSugiIhJfRiX0bbvru1T/V8+8wZV/Wt1D0YiIpJeMSuhdvUXuDx9bzz0vvh13+Rtbd7Fmy4fJhiUikha6dPvcTJLIOPQZP30agNXfm01JcWEPRyQi0rMyqoWejGde3crrW3fx3o69+y37yh16ZrWIZL6sbaG396XftD7xaOMPP0l+nrXMv7zlQyo31FC7q57PHlfW6bZqdu6lpLiQ4sL8HolVRKQ7sjah31fV2ndefuWjbZaNu3ox5007pGXeDM6//UWAhBL6lB8u4cRxQ/n9V6amKFoRkeRlVJdL7a7ER7nUdjIi5s4X3kwqluc21ia1vohIqmVUQm/UHbdEROJKOKGbWb6ZrTSzR2Is62NmfzSzjWa2zMzKUxlks+WbtvXEZtlT3/qEo9pddT3yHiIiPa0rLfTLgPVxll0IfODu44CbgB8nG1hYvvPgy2GHICLSLQkldDMrA04Hfh2nyqeAO4Pp+4GZZmZx6qa1j/ZFHpDxuxc2c8EdL4YbjIhIFyQ6yuVm4FvAgDjLDwTeBnD3BjP7EBgKtHkOnJldDFwMUDRqXHfi7XEe9NN/96G1+y17ct17DCjO2oFBIpLhOs1OZnYGUOPuK8xserxqMcr2O4Pp7ouARQB9Sg/LuDOcF/1WFyCJSPpKpMvlRGC+mW0G7gFmmNld7epUAwcBmFkBMBDomTOYPewfr71PXUNj5xVFRNJMpwnd3a9y9zJ3LwfOBv7u7ue0q/YwcF4wfVZQJ+Na4M1+v/StsEMQEemybncIm9kCoMrdHwZuA35nZhuJtMzPTlF8oXj+9fc7ryQikma6dGGRu1e6+xnB9LVBMsfd97r759x9nLtPcfc3eiLY3vK39TUt09OuXxJiJCIiidOQjU68++Fe6hoa+Z/K18MORUSkQxl16X9Yfvv8m9z8t9fCDkNEpENK6An4aJ9GvYhI+lNCT0DmjtcRkVyihJ6A17fu6nB5rKcgiYj0NiX0BDy86p2Y5bvqGnjqlRo+/qMl/H5ZcvdXFxFJlhJ6EiZf9wS/eDoy+uXqB9cw+6ank97mtt317FWfvYh0gxJ6kqre/KBl+tX3dnHNn1+m/MpHuWd59642PfYHT/LFXy9LVXgikkOU0JPU/g4HdwW3Dbjygdb7qn/t9/9kxk8rE97miqgvCRGRROnCoiQ1JTAC5tGX3wXgxide4danXuc/Zh3GtLFDqdlZx9addVxw0pgejlJEcoESeg/a8K+dzLn5mZb5W5+K9Lff/LfXuJnWC5VmTBhB+bD+vR6fiGQXJfQeFJ3MOzL9J5X0K8rnU0cfmFD95Zu2UTa4L6MH9U0mPBHJMkroaWJPfSN3R51I3buvkR0f7WNESXFL2VMbavjy7ZHH4hXl5/HqDz/ZZhub3t9N38J8Rg0sRkRyj06Kpqlzb1vGlB8t4elXt/LqezsBWpI5QH1jE+VXPsrGmp0tZaf9pJKpujukSM5SQk9TL26OjHQ57zfLmX3TMzy+5t2Y9c6//UX+tu69NmPX6xua2tTZXdew32gcEck+FtZ/9D6lh3npeTeH8t654DPHHsjGml3c8oVjOeXGp/jhpyfzmWPKKMg3CvPzaGxy/vji23y+ooyCfH2vi2QKM1vh7hUxlymh5545k0ZSNrgftz27CYBfnHMscyeXtix/6KUt3LX0Tc6dVs7AvoWcOn54WKGKSDtK6NKp1d+bzY6P9uEOJy98qs2y9Qvm0uROUUEeC/6yjt8tfZPrP/Mxrnt4LXdfNJVxww9gYL/CNut8VN9IfWMTA/u2LReR5CihS6+Yf9RoHl/zL+ob2/bhTx07hDwzrvrkRM685VmOLx/M7V+ewqdvfY75R41m0oElTBhVwqiSYszgw4/28eeVW5hQWkJJcSFHjC4BoLHJMaDJnTwz8vIMd8cd8vIshE8s0vuU0EVCNH7kAbz6XustmIf2L+LQEQfwxtZdNDmMHdaff771QctVx7MmjgBgd10jA4oLWFW9nYOH9OOoskEUFuTx2nu7KC7M47ARAxhyQBFbd+xlREkxo6KGuFrU91ubadrM7DfpDg1NTp+CyHmVJnccwCNfqPl5kS/SxqamNtsyo+WLtTmnmO3/JdvUvCyyyU5Z1Haat+tRy/arH+M9Y8nkQQKnTRgZN6F3Og7dzIqBZ4A+Qf373f26dnUOBu4EBgH5wJXu/liygYtkg+hkDlC7u57aTdta5rftrm+zPPoh5c3e21HXMvKpVeyRT5K7ErmwqA6Y4e67zKwQeNbMFrv70qg61wD3uvv/mNkRwGNAeerDFUkvzS1TgAMH9WXL9o9alvUrymdPfSNzJ41ib0Mjb9buYdP7uxnUr5BpY4eyY+8+1r6zg4+PGcLoQX3514d7ef71Ws44spT6hsj5hw/27KMgz+hbFLlgrLggj+0f7WPn3gYmlpawbXcdA4oLGT/yAIry8wHwqLZvdEM0uk0a3UKNLm9qam0FR3qxDDPIs0jLu76hiYJ8Iz8vj8amJtybfwEY+UHLPdgz0e/WMt/cgG5dL3bttvF7mxrxGuGx6nYkwcZ8m+13tE7zLu3qdrsaQ8WP4y/vNKF75C/f3MQoDF7tf684UBJMDwRiPxFCss635h7Owsc3xF1+6PD+fLBnH9t213P5rPHc9LdXOXX8cG47r4IHVm5h+vjhDB/QhyaHZ17dytsf7OHs4w+mKPjJ7+4tP6O37a5nUN/Clv7yt7ftobHJdR8ckUBCfehmlg+sAMYBt7r7t9stLwX+CgwG+gOz3H1FjO1cDFwMUDRq3HHqQw/f8AF92LqzrmV+yddP5cyfP8ue+siFSndfNJV/vLaVxibnkdXv0r9PfuS+76dP5Csnj4273XXv7ODqP7/MonMrGD6gT49/DpFckbKTomY2CHgQuMTd10SVXxFs66dmNg24DZjs7k1xNqWToiEqG9yXZ789A4i0gL9+7yoeWLmFiaUlLL7sZNydJetrmDFhhEaPiKSZjhJ6l27O5e7bzawSmAusiVp0YVCGu78QnEgdBux/dkd6zJD+RRQX5PHOh5GHVk8pH8Lyzds4adwwRpYUs/adD5kzaRRnHVfWso6Z8eOzjmRXXQOXzjyspWzWESND+Qwi0n2JjHIZDuwLknlfYBbQvlv+LWAmcIeZTQSKga2pDlYi/nr5KTy4cgsr3/qApW9ERktsun5ezCFbG2t2UjqwL/37xP9TF+bnsehLMb/wRSSDJNJCLwXuDPrR84iMZnnEzBYAVe7+MPB14FdmdjmRE6TneyYP9EwT3z3jCD577IGcecuzvL0tMnqiOXF/e+4EPvxoH9+8bxWzJ42KO/523IgBvRmyiIRIFxb1shPHDeW5jbVtyq45fSL/+ej6/epuvuF0INLPPeaqx+hflM/aBXN7JU4RSU8p60OX5F135iRm39T6JKNF5x7H7EmjOP+Ecgry82hqcsZ+5zEGRd0bxcx47NKTGTagKIyQRSRD6L6pPeyik8fwyCUntcyPHzmAzTecvt/FB823sM3LM5Z/ZyZPf/O0NsuPGF3CiAF6EpGIxKeE3sMuPuVQJh84cL/ymRMi9+uI1fc9oqRYdykUkS5TQk+BkSVdv3Bm/MjIyUpddCMiqaI+9BT45ORS7nh+c4d17r5oKuve3dEyf8UnxnPahBEcfdCgHo5ORHKFWugp8O25E/jdhVMYdkD81va0Q4dy4UljWuYL8vM4vnxIb4QnIjlCCT1JFYcMpm9RPicfNpyqa2a1lA/trxEpItK71OWSpPNOKG8z/5vzK3j3w73c+fxmanfXo1uhiEhvUULvgtMOH85TG1rvaNB84U+0GRNGBv+OoHLDVoZ20A0jIpJK6nLpgtu/PCXhuqUD+/KFKQf3YDQiIm0poSfowX8/oc189MVCIiLpQAm9A+dOPaSlD7x53HizWBcLiYiESQm9A+dOO4Q+BflhhyEikpCcS+h3fPn4bq3Xkw9+FRFJhZxL6NMPH8Gm6+clVDfP2j5BXUQkneXksMV4D4NoL7q7xYis8/MvHMOT697rkbhERJKRUwk9P8ZVPiMG9KEm6qn30foU5NH++R9nHjWaM48a3RPhiYgkJae6XKLz+VenHwrA6EF9W8omjS7hxrOO5L8+fxT9ivIZHHX5vvrQRSTd5VRCj/bpYw4EYN7HRrWU9S3M53MVB/GZY8tYt2Auhfl5fO20cUDkQcoiIuksp7pcmvvBofXJQcs3bWspu/nso/db59KZh3HpzMN6JT4RkWR02uw0s2IzW25mq8xsrZl9P069z5vZuqDOH1IfavI6GrFScchgygb368VoRERSK5EWeh0ww913mVkh8KyZLXb3pc0VzOww4CrgRHf/wMxG9FC8PUZ95CKS6TpN6O7uwK5gtjB4tW/qXgTc6u4fBOvUpDLIVInucmk2fuQBAHzl5LG9HY6ISEoldKbPzPLN7CWgBnjS3Ze1qzIeGG9mz5nZUjObG2c7F5tZlZlVJRd26gzqV8TmG05nzqRRnVcWEUljCSV0d29096OBMmCKmU1uV6UAOAyYDnwB+LWZ7fewTHdf5O4V7l6RXNjdUzakb+eVREQyVJfG4rn7dqASaN8CrwYecvd97r4J2EAkwYeq/XVE91w0NZxARER6QSKjXIY3t7bNrC8wC3ilXbU/A6cFdYYR6YJ5I7WhJm9ESXHYIYiI9JhERrmUAneaWT6RL4B73f0RM1sAVLn7w8ATwGwzWwc0At9099oei1pERPaTyCiX1cAxMcqvjZp24IrgJSIiIciJK0UrvzGduoamsMMQEelRGX+Dkn5F+S33ZYnnoCH9OHzUgA7riIhkuoxP6AAD+xaGHYKISOiyIqGLiEgWJPT2D6AQEclVGZ/QIf6Ntc4/YUxkeS/GIiISloxP6GbxW+nfPWMib/xoHnkxHj0nIpJtsnbY4vknlGNmui2uiOSMjG+hx/O9+ZPCDkFEpFdlbUIXEck1SugiIlki4xO6ushFRCIyNqEvPOvI/cquPeOIECIREUkPGZvQ532sFNj/4aYXnzKWX5xzXO8HJCISsowdthivq+U78yb2ahwiIukiY1vosa4l0phzEcllGZvQmymHi4hEZFRCf+UH7Z9NLSIizTIqoRcX5ocdgohI2kq7k6JD+xdRu7s+7vJvzjmcj48Z0osRiYhkhk5b6GZWbGbLzWyVma01s+93UPcsM3Mzq+huQHd95eOsum523OVfO20cFeVDcN0IXUSkjURa6HXADHffZWaFwLNmttjdl0ZXMrMBwKXAsmQCKszP69Ij5UxDW0REgARa6B6xK5gtDF6xmsc/ABYCe1MXXufcXa11ERESPClqZvlm9hJQAzzp7svaLT8GOMjdH+lkOxebWZWZVXU74tZt7V+W7EZFRDJYQgnd3Rvd/WigDJhiZpObl5lZHnAT8PUEtrPI3Svcvdt97CIiEluXhi26+3agEogeED4AmAxUmtlmYCrwcDInRhOMpWW6uCgynLGoQMMaRSR3JTLKZbiZDQqm+wKzgFeal7v7h+4+zN3L3b0cWArMd/dudqu07Q/ffMPpncXHZTMP47KZh/G5irLuvaWISBZIZJRLKXCnmeUT+QK4190fMbMFQJW7P9yjESagX1EBl39ifNhhiIiEqtOE7u6rgWNilF8bp/705MMSEZGuyqhL/0VEJL6MTegaeS4i0lbGJnQREWkr7RJ636LE7hemi4hERNpKu4R+4KC+YYcgIpKR0u72uc0WX3Yya9/ZAUBJcQE79jaEHJGISHpLq4T+sy+0jo6cWFrCxNISAJZ+ZyYNTW1Pg+qkqIhIW2mV0OcfNTpmeb8O+tXVly4iEpEWCf35K2ewq05dKiIiyUiLhF46sFgPqhARSVLajXIREZHuSYsWencM6FPA6UeWct608rBDERFJCxmb0M2MW//3sWGHISKSNtKiy0X95yIiyUuLhC4iIslTQhcRyRJK6CIiWUIJXUQkSyihi4hkCSV0EZEs0WlCN7NiM1tuZqvMbK2ZfT9GnSvMbJ2ZrTazJWZ2SM+EKyIi8STSQq8DZrj7UcDRwFwzm9quzkqgwt2PBO4HFiYawJ++Oi3RqiIi0oFOE7pH7ApmC4OXt6vzlLvvCWaXAmWJBnDcIUMSrSoiIh1IqA/dzPLN7CWgBnjS3Zd1UP1CYHEqghMRkcQllNDdvdHdjybS8p5iZpNj1TOzc4AK4MY4yy82syozq+puwCIiEluXRrm4+3agEpjbfpmZzQKuBua7e12c9Re5e4W7V3QjVhER6UAio1yGm9mgYLovMAt4pV2dY4BfEknmNT0RqIiIdCyR2+eWAneaWT6RL4B73f0RM1sAVLn7w0S6WA4A7gvunPiWu8/vqaBFRGR/nSZ0d18NHBOj/Nqo6VkpjktERLpIV4qKiGQJJXQRkSyhhC4ikiWU0EVEsoQSuohIllBCFxHJEkroIiJZIrSEXjqwmMWXnRzW24uIZJ3QEvqwA/owsbQkrLcXEck66nIREckSSugiIllCCV1EJEsooYuIZAkldBGRLKGELiKSJZTQRUSyhBK6iEiWMHcP543NdgIbQnnz9DMMeD/sINKE9kUr7YtW2hetDnH34bEWJPJM0Z6ywd0rQnz/tGFmVdoXEdoXrbQvWmlfJEZdLiIiWUIJXUQkS4SZ0BeF+N7pRvuilfZFK+2LVtoXCQjtpKiIiKSWulxERLKEErqISJZIOqGb2W/MrMbM1kSVDTGzJ83steDfwUG5mdnPzGyjma02s2Oj1jkvqP+amZ0XVX6cmb0crPMzM7NkY+4JcfbDjWb2SvBZHzSzQVHLrgo+0wYzmxNVPjco22hmV0aVjzGzZcH++aOZFfXep+uaWPsiatk3zMzNbFgwn7XHBMTfF2Z2SfB3XmtmC6PKc+q4MLOjzWypmb1kZlVmNiUoz+rjose4e1Iv4BTgWGBNVNlC4Mpg+krgx8H0PGAxYMBUYFlQPgR4I/h3cDA9OFi2HJgWrLMY+GSyMffEK85+mA0UBNM/jtoPRwCrgD7AGOB1ID94vXepGh0AAAMkSURBVA6MBYqCOkcE69wLnB1M/wL4atifuSv7Iig/CHgCeBMYlu3HRAfHxWnA34A+wfyIXD0ugL82//2CY6EyF46Lnnol3UJ392eAbe2KPwXcGUzfCfyvqPLfesRSYJCZlQJzgCfdfZu7fwA8CcwNlpW4+wse+Yv9NmpbaSXWfnD3v7p7QzC7FCgLpj8F3OPude6+CdgITAleG939DXevB+4BPhW0NGYA9wfrR+/TtBPnmAC4CfgWEH0mPmuPCYi7L74K3ODudUGdmqA8F48LB5qfRTkQeCeYzurjoqf0VB/6SHd/FyD4d0RQfiDwdlS96qCso/LqGOWZ6AIirQbo+n4YCmyP+nLIuP1gZvOBLe6+qt2iXDwmxgMnB10lT5vZ8UF5zh0XwH8AN5rZ28BPgKuC8lw8LpLW2ydFY/VpeTfKM4qZXQ00AL9vLopRLWv3g5n1A64Gro21OEZZ1u6LQAGR7oKpwDeBe4PWdi7ui68Cl7v7QcDlwG1BeS7ui6T1VEJ/L/gJRPBv80/KaiL9qM3KiPzE6qi8LEZ5xghO2pwBfDH4KQhd3w/vE/nJWdCuPFMcSqRPeJWZbSYS/z/NbBQ5eEwQ+QwPBN0Jy4EmIjefyrXjAuA84IFg+j4i3UuQm8dF8lLREQ+U0/ZEx420PSm6MJg+nbYnOpZ764mOTURaLYOD6SHBsheDus0nOuaFfeKhC/thLrAOGN6u3iTanvx6g8iJr4JgegytJ78mBevcR9uTX/8e9uftyr5ot2wzrSdFs/qYiHNc/BuwIJgeT6QLwXLxuADWA9OD6ZnAilw5Lnpk/6bgD3Q38C6wj8i35IVE+vaWAK8F/zbvcANuJXLG/mWgImo7FxA5CbQR+HJUeQWwJljnFoKrW9PtFWc/bAz+s74UvH4RVf/q4DNtIOpsPJGz+68Gy66OKh9L5Cz+xuA/cZ+wP3NX9kW75ZtpTehZe0x0cFwUAXcFn+GfwIxcPS6Ak4AVRL6klgHH5cJx0VMvXfovIpIldKWoiEiWUEIXEckSSugiIllCCV1EJEsooYuIZAkldBGRLKGELiKSJf4/e4WZXSYmOS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df[10000:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. classification\n",
    "We consider binary classification, and want to predict not directly <font color='red'>y</font> but <font color='blue'>p(y=1)</font>.\n",
    "\n",
    "We Set:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\hat y &= P(y=1) = \\sigma(X \\cdot w) \\\\\n",
    "\\sigma(z) &= \\cfrac 1 {1+\\exp(-z)}\\\\\n",
    "\\cfrac {\\partial \\sigma(z)}{\\partial z} &= \\cfrac {\\exp(-z)} {(1+\\exp(-z))^2} = \\sigma(z)(1-\\sigma(z))\\\\\n",
    "Loss(w) &= NLL(w) \n",
    "= - \\left[ y^T \\cdot \\log P(y=1) \\right] - \\left[ (1-y)^T \\cdot \\log (1-P(y=1)) \\right] \\\\\n",
    "\\cfrac {\\partial Loss}{\\partial w} &= - X^T \\cdot \\left[ y (1 - P(y=1)) \\right] + X^T \\cdot \\left[(1-y) P(y=1) \\right] \\\\\n",
    "&= X^T \\cdot (\\hat y - y)\n",
    "\\end{align}$$\n",
    "\n",
    "### 2.1 statistical tool\n",
    "binary case만을 고려하기 위해, 첫 100개 항만 가져오도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.31629979,  0.70803893, -2.29291305,  0.28220666],\n",
       "       [-0.67690095, -0.77936232, -1.12511459, -0.85295128],\n",
       "       [ 2.70496343,  1.81256131,  0.09005406,  0.62008331],\n",
       "       [ 0.5868326 ,  0.36681905, -0.45731792, -0.46723319],\n",
       "       [ 0.65746416, -1.15725619, -0.03396529, -0.40039299]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_features=4, n_redundant=0, n_informative=1,\n",
    "                           n_clusters_per_class=1, random_state=4)\n",
    "print(X.shape)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.31629979,  0.70803893, -2.29291305,  0.28220666],\n",
       "       [ 1.        , -0.67690095, -0.77936232, -1.12511459, -0.85295128],\n",
       "       [ 1.        ,  2.70496343,  1.81256131,  0.09005406,  0.62008331],\n",
       "       [ 1.        ,  0.5868326 ,  0.36681905, -0.45731792, -0.46723319],\n",
       "       [ 1.        ,  0.65746416, -1.15725619, -0.03396529, -0.40039299]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "print(X.shape)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.124262\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   100</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 17 Oct 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.8207</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:34:44</td>     <th>  Log-Likelihood:    </th> <td> -12.426</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -69.295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.161e-23</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3037</td> <td>    0.603</td> <td>    0.503</td> <td> 0.615</td> <td>   -0.879</td> <td>    1.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.0410</td> <td>    0.731</td> <td>   -1.423</td> <td> 0.155</td> <td>   -2.474</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    5.6889</td> <td>    1.538</td> <td>    3.700</td> <td> 0.000</td> <td>    2.675</td> <td>    8.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.2788</td> <td>    0.553</td> <td>   -0.504</td> <td> 0.614</td> <td>   -1.363</td> <td>    0.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.8798</td> <td>    0.659</td> <td>   -1.336</td> <td> 0.182</td> <td>   -2.171</td> <td>    0.411</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.16 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  100\n",
       "Model:                          Logit   Df Residuals:                       95\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Thu, 17 Oct 2019   Pseudo R-squ.:                  0.8207\n",
       "Time:                        10:34:44   Log-Likelihood:                -12.426\n",
       "converged:                       True   LL-Null:                       -69.295\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.161e-23\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3037      0.603      0.503      0.615      -0.879       1.486\n",
       "x1            -1.0410      0.731     -1.423      0.155      -2.474       0.392\n",
       "x2             5.6889      1.538      3.700      0.000       2.675       8.703\n",
       "x3            -0.2788      0.553     -0.504      0.614      -1.363       0.805\n",
       "x4            -0.8798      0.659     -1.336      0.182      -2.171       0.411\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.16 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366162, -1.04095437,  5.68894902, -0.27882206, -0.87983546])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Using numpy with linear algebra\n",
    "can't get exact solution, but approximation method with Hessian Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Machine Learning Method\n",
    "#### 1) SGD(확률적 경사하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46903266, -0.24571793,  0.41240044,  0.4701742 , -0.25338022])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, rand\n",
    "np.random.seed(234)\n",
    "w = rand(X.shape[-1]) - 0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 150000 # 50000\n",
    "batch = 34 # 2^n이 좋으나 데이터가 100개라 1/3로 함\n",
    "lrs = [0.0005, 0.00005, 0.00001]\n",
    "rows = X.shape[0]\n",
    "losses = []\n",
    "randRow = np.arange(rows)\n",
    "\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # for each epoch, shuffle X, y\n",
    "    shuffle(randRow)\n",
    "    epochLoss = 0\n",
    "    if epoch < 50000:\n",
    "        lr = lrs[0]\n",
    "    elif epoch < 100000:\n",
    "        lr = lrs[1]\n",
    "    else: lr = lrs[2]\n",
    "    \n",
    "    for i in range(0, rows, batch):\n",
    "        batch_index = randRow[i:i+batch]\n",
    "        x_batch = X[batch_index]\n",
    "        y_batch = y[batch_index]\n",
    "        # 아래는 직접 구현해보세요.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\hat y &= P(y=1) = \\sigma(X \\cdot w) \\\\\n",
    "Loss(w) &= NLL(w) \n",
    "= - \\left[ y^T \\cdot \\log P(y=1) \\right] - \\left[ (1-y)^T \\cdot \\log (1-P(y=1)) \\right] \\\\\n",
    "\\cfrac {\\partial Loss}{\\partial w} &= X^T \\cdot (\\hat y - y)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30365817, -1.04094798,  5.68892956, -0.27881875, -0.87982798])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366162, -1.04095437,  5.68894902, -0.27882206, -0.87983546])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모멘텀 기법 사용하기\n",
    "<참고> https://twinw.tistory.com/247\n",
    "![](https://t1.daumcdn.net/cfile/tistory/99A14F455B0CF54C21)\n",
    "\n",
    "```\n",
    "v(t+1) = m * v(t) - a * dW(t)\n",
    "W(t+1) = W(t) + v(t+1)\n",
    "\n",
    "v(0) = 0, m = 0.9\n",
    "v(1) = - a * dW(0)\n",
    "W(1) = W(0) + v(1) = W(0) - a * dW(0)\n",
    "\n",
    "v(2) = m * v(1) - a * dW(1) = - 0.9 * a * dW(0) - a * dW(1)\n",
    "W(2) = W(1) - a * [ 0.9 * dW(0) + dW(1) ]\n",
    "\n",
    "v(3) = m * v(2) - a * dW(2) = - a * [ 0.9 * 0.9 * dW(0) + 0.9 * dW(1) + dW(2) ]\n",
    "W(3) = W(2) + v(3) = W(2) - a * [ 0.9 * 0.9 * dW(0) + 0.9 * dW(1) + dW(2) ]\n",
    "```\n",
    "- a: learning rate\n",
    "- m: momentum. memory of prior velocity. generally 0.9 ~ 0.99\n",
    "- v: velocity. moving speed and direction.\n",
    "\n",
    "```python\n",
    "v = m * v - learning_rate * dW\n",
    "W += v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19646919, -0.21386067, -0.27314855,  0.05131477,  0.21946897])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, rand\n",
    "np.random.seed(123)\n",
    "w = rand(X.shape[-1]) - 0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50000 # 50000\n",
    "batch = 34\n",
    "# lrs = [0.0005, 0.00005, 0.00001]\n",
    "lr = 0.00005\n",
    "rows = X.shape[0]\n",
    "losses = []\n",
    "randRow = np.arange(rows)\n",
    "m = 0.95\n",
    "v = 0\n",
    "\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # for each epoch, shuffle X, y\n",
    "    shuffle(randRow)\n",
    "    epochLoss = 0\n",
    "#     if epoch < 50000:\n",
    "#         lr = lrs[0]\n",
    "#     elif epoch < 100000:\n",
    "#         lr = lrs[1]\n",
    "#     else: lr = lrs[2]\n",
    "    \n",
    "    for i in range(0, rows, batch):\n",
    "        batch_index = randRow[i:i+batch]\n",
    "        x_batch = X[batch_index]\n",
    "        y_batch = y[batch_index]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366714, -1.04104417,  5.68896705, -0.27878876, -0.879781  ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366162, -1.04095437,  5.68894902, -0.27882206, -0.87983546])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Nesterov 기법 사용하기\n",
    "![](https://t1.daumcdn.net/cfile/tistory/996E494B5B0D03A003)\n",
    "\n",
    "```python\n",
    "v = m * v - learning_rate * d(w + m*v)\n",
    "weight += v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46903266, -0.24571793,  0.41240044,  0.4701742 , -0.25338022])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, rand\n",
    "np.random.seed(234)\n",
    "w = rand(X.shape[-1]) - 0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50000 # 50000\n",
    "batch = 34\n",
    "# lrs = [0.0005, 0.00005, 0.00001]\n",
    "lr = 0.00005\n",
    "rows = X.shape[0]\n",
    "losses = []\n",
    "randRow = np.arange(rows)\n",
    "m = 0.95\n",
    "v = 0\n",
    "\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # for each epoch, shuffle X, y\n",
    "    shuffle(randRow)\n",
    "    epochLoss = 0\n",
    "    \n",
    "    for i in range(0, rows, batch):\n",
    "        batch_index = randRow[i:i+batch]\n",
    "        x_batch = X[batch_index]\n",
    "        y_batch = y[batch_index]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30356006, -1.04103874,  5.68890987, -0.27882635, -0.87985212])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366162, -1.04095437,  5.68894902, -0.27882206, -0.87983546])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) RMSprop 사용하기\n",
    "```python\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, rand\n",
    "np.random.seed(234)\n",
    "w = rand(X.shape[-1]) - 0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50000 # 50000\n",
    "batch = 34\n",
    "# lrs = [0.0005, 0.00005, 0.00001]\n",
    "lr = 0.00005\n",
    "rows = X.shape[0]\n",
    "losses = []\n",
    "randRow = np.arange(rows)\n",
    "m = 0.95\n",
    "v = 0\n",
    "cache=np.zeros(w.size)\n",
    "decay_rate=0.99\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # for each epoch, shuffle X, y\n",
    "    shuffle(randRow)\n",
    "    epochLoss = 0\n",
    "    \n",
    "    for i in range(0, rows, batch):\n",
    "        batch_index = randRow[i:i+batch]\n",
    "        x_batch = X[batch_index]\n",
    "        y_batch = y[batch_index]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18226938, -0.81510438,  5.04788791, -0.18684718, -0.70703686])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30366162, -1.04095437,  5.68894902, -0.27882206, -0.87983546])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
