{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_FrozenLake.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvQfcJsAs18y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.envs.registration import register\n",
        "import numpy as np\n",
        "import random as pr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL8eT3kp3nKv",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤 프로즌레이크 게임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO87FcU4tXKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "register(\n",
        "    id=\"FrozenLake-v1\",\n",
        "    entry_point=\"gym.envs.toy_text:FrozenLakeEnv\",\n",
        "    kwargs={\n",
        "        \"map_name\":\"4x4\",\n",
        "        \"is_slippery\":False\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJMX3PZyxgR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"FrozenLake-v1\")\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-uTNAHgN6Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLjZSLQESMWf",
        "colab_type": "text"
      },
      "source": [
        "## NN을 위한 weight 값 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLpURhFbQUAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = tf.Variable(tf.random_uniform([16, 4], 0, 0.1))\n",
        "w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X48WCB7mSLf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIrp4kS9SY21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(num):\n",
        "    onehot_arr = np.identity(16)[num:num+1]\n",
        "    return np.array(onehot_arr, dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yHdCoBUvZ6E",
        "colab_type": "text"
      },
      "source": [
        "## 텐서플로우와 Q 함수를 활용한 랜덤 Frozen Lake 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFYbCjXtvc7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = np.zeros([16, 4])\n",
        "discount = 0.99\n",
        "successList = []\n",
        "for index in range(2000):\n",
        "    position = env.reset()\n",
        "    total_reward = 0\n",
        "    e = 1.0/((index // 100) +  1)\n",
        "    while True:\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "        \n",
        "            position_onehot = one_hot(position)\n",
        "\n",
        "            predQ = tf.matmul(position_onehot, w)\n",
        "\n",
        "            if np.random.rand(1) < e:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(predQ)\n",
        "\n",
        "            new_position, reward, done, info = env.step(action)\n",
        "\n",
        "            # print(f\"new_position : {new_position}, reward : {reward}, done : {done}, info : {info}\")\n",
        "            Qs = predQ.numpy()\n",
        "            if done == True:\n",
        "                \n",
        "                Qs[0, action] = reward\n",
        "                Qs = tf.convert_to_tensor(Qs, np.float32)\n",
        "                successList.append([index, reward])\n",
        "            else:\n",
        "                new_position_onehot = one_hot(new_position)\n",
        "                nextQ = tf.matmul(new_position_onehot, w)\n",
        "\n",
        "                Qs[0, action] = reward + discount * np.max(nextQ)\n",
        "\n",
        "                Qs = tf.convert_to_tensor(Qs, np.float32)\n",
        "            cost = tf.reduce_sum(tf.square(Qs - predQ))\n",
        "\n",
        "            grads = tape.gradient(cost, [w])\n",
        "\n",
        "            optimizer.apply_gradients(grads_and_vars=zip(grads, [w]))\n",
        "            position = new_position\n",
        "\n",
        "            if done == True:\n",
        "                break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x15wfZq9Ylw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Qs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a9NMuhEvXa",
        "colab_type": "text"
      },
      "source": [
        "## 학습된 결과 중 목적지에 도착한 비율 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6glTKk5h-p3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "result_list = list(zip(*successList))\n",
        "print(sum(result_list[1]))\n",
        "plt.bar(range(len(successList)), result_list[1], color=\"blue\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDGJC4E_65qg",
        "colab_type": "text"
      },
      "source": [
        "## 학습된 모델을 가지고 게임 재 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GovjzPf167_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "position = env.reset()\n",
        "\n",
        "while True:\n",
        "    env.render()\n",
        "\n",
        "    position_onehot = one_hot(position)\n",
        "\n",
        "    predQ=tf.matmul(position_onehot, w)\n",
        "\n",
        "    action = np.argmax(predQ)\n",
        "\n",
        "    new_position, reward, done, info = env.step(action)\n",
        "\n",
        "    position = new_position\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lk2M2IwBdsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}