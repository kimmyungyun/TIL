{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_FrozenLake.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvQfcJsAs18y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.envs.registration import register\n",
        "import numpy as np\n",
        "import random as pr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL8eT3kp3nKv",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤 프로즌레이크 게임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO87FcU4tXKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "register(\n",
        "    id=\"FrozenLake-v1\",\n",
        "    entry_point=\"gym.envs.toy_text:FrozenLakeEnv\",\n",
        "    kwargs={\n",
        "        \"map_name\":\"4x4\",\n",
        "        \"is_slippery\":True\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJMX3PZyxgR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"FrozenLake-v1\")\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W8tAyPL0Cxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "position= env.reset()\n",
        "position"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yHdCoBUvZ6E",
        "colab_type": "text"
      },
      "source": [
        "## Q 함수를 활용한 랜덤 Frozen Lake 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFYbCjXtvc7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = np.zeros([16, 4])\n",
        "discount = 0.99\n",
        "total_reward_list = []\n",
        "for index in range(2000):\n",
        "    print(f\"index : \", index)\n",
        "    position = env.reset()\n",
        "    total_reward = 0\n",
        "    while True:\n",
        "        env.render()\n",
        "        print()\n",
        "        e = 1.0/((index // 100) +  1)\n",
        "        if np.random.rand(1) < e:\n",
        "            action = pr.choice([0, 1, 2, 3])\n",
        "        else:\n",
        "            action = np.argmax(Q[position, :])\n",
        "\n",
        "        new_position, reward, done, info = env.step(action)\n",
        "\n",
        "        # print(f\"new_position : {new_position}, reward : {reward}, done : {done}, info : {info}\")\n",
        "\n",
        "        Q[position, action ] = reward + discount * np.max(Q[new_position, :])\n",
        "\n",
        "        position = new_position\n",
        "        total_reward += reward\n",
        "        if done == True:\n",
        "            break\n",
        "    total_reward_list.append([index, total_reward])\n",
        "    print(f\"Q: {Q}\")\n",
        "    print(\"=\"* 100)\n",
        "    print(f\"total_reward = {total_reward}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a9NMuhEvXa",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤한 상황에서는 학습이 제대로 진행이 안되는 것을 확인할 수 있음\n",
        "## 성공 비율이 24/1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6glTKk5h-p3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "result_list = list(zip(*total_reward_list))\n",
        "print(sum(result_list[1]))\n",
        "plt.bar(range(len(total_reward_list)), result_list[1], color=\"blue\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1r-E2EDOAMu",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤으로 이동하는 경우가 발생하기 때문에 최단경로는 의미가 사라짐\n",
        "## 그래서 Goal로 가는 확률이 높은 것(Goal과 가까운 위치로 향하는 것)을 Q 함수 값으로 설정한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVytBAbCY20j",
        "colab_type": "text"
      },
      "source": [
        "## 바로 이전에 수행한 행동과 지금 행동함으로써 발생하는 행동에 가중치를 주어 학습시킨다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTdZC0DqOIqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = np.zeros([16, 4])\n",
        "weight = 0.99\n",
        "learning_rate = 0.85\n",
        "total_reward_list = []\n",
        "for index in range(2000):\n",
        "    print(f\"index : \", index)\n",
        "    position = env.reset()\n",
        "    total_reward = 0\n",
        "    while True:\n",
        "        # env.render()\n",
        "       \n",
        "        rand_arr = np.random.randn(1, 4)\n",
        "\n",
        "        noise = rand_arr / (index + 1)\n",
        "\n",
        "        action = np.argmax(Q[position, :] + noise)\n",
        "        new_position, reward, done, info = env.step(action)\n",
        "\n",
        "        # print(f\"new_position : {new_position}, reward : {reward}, done : {done}, info : {info}\")\n",
        "\n",
        "        Q[position, action ] = ((1- learning_rate) * Q[position, action]) + (learning_rate * (reward + weight * np.max(Q[new_position, :])))\n",
        "\n",
        "        position = new_position\n",
        "        total_reward += reward\n",
        "        if done == True:\n",
        "            break\n",
        "    total_reward_list.append([index, total_reward])\n",
        "    print(f\"Q: {Q}\")\n",
        "    print(\"=\"* 100)\n",
        "    print(f\"total_reward = {total_reward}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ika5C2pXc_ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "result_list = list(zip(*total_reward_list))\n",
        "print(sum(result_list[1]))\n",
        "plt.bar(range(len(total_reward_list)), result_list[1], color=\"blue\")\n",
        "print(f\"score : {sum(result_list[1]) / len(result_list[1])}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}