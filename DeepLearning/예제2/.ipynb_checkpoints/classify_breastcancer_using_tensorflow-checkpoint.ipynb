{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\library\\python\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\library\\python\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\library\\python\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유방암 분류 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'c:\\\\library\\\\python\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 독립변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[\"data\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위의 경우 타입이 없어서 tensorflow에서 계산이 안된다\n",
    "## 그래서 float32 형태로 바꿔서 tensorflow에서 계산이 될 수 있도록 밑에서 작업해주고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"target\"]\n",
    "y = np.array(y, dtype=\"float32\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우에 맞는 형태로 바꿔주기 위해 아래에서 형태를 바꿔준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋을 훈련용과 테스트용으로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 값에 대한 표준화 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 값 표준화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73251146,  0.59736675,  0.73832047, ...,  1.0150046 ,\n",
       "         3.2583003 ,  0.15710242],\n",
       "       [-0.6930349 , -1.2361537 , -0.7459475 , ..., -0.50125694,\n",
       "         0.33223557, -1.0173117 ],\n",
       "       [-1.3536329 ,  2.1208596 , -1.365979  , ..., -1.7786764 ,\n",
       "        -0.7073309 , -0.84764093],\n",
       "       ...,\n",
       "       [-1.1149964 , -1.6721296 , -1.0973538 , ..., -0.746879  ,\n",
       "         0.05988938, -0.39297017],\n",
       "       [ 3.7774785 ,  1.7309039 ,  3.9171205 , ...,  2.2662282 ,\n",
       "        -0.4316633 , -0.57109463],\n",
       "       [-2.0498698 , -1.3790569 , -2.0062919 , ..., -1.7786764 ,\n",
       "         0.05158575,  0.6093577 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow weight 값 초기화 모델 생성 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30, 1) dtype=float32, numpy=\n",
       "array([[-0.16078144],\n",
       "       [ 0.07006466],\n",
       "       [ 0.415222  ],\n",
       "       [-0.07370687],\n",
       "       [ 0.03533059],\n",
       "       [ 0.36016595],\n",
       "       [-0.17426068],\n",
       "       [-0.37182084],\n",
       "       [ 0.1680128 ],\n",
       "       [-0.41048145],\n",
       "       [-0.18528852],\n",
       "       [ 0.16687107],\n",
       "       [-0.2787697 ],\n",
       "       [-0.02772826],\n",
       "       [ 0.24868077],\n",
       "       [-0.0701409 ],\n",
       "       [ 0.40701455],\n",
       "       [ 0.01052436],\n",
       "       [-0.04114589],\n",
       "       [-0.36595243],\n",
       "       [-0.12326801],\n",
       "       [ 0.3161295 ],\n",
       "       [-0.22835727],\n",
       "       [ 0.3464827 ],\n",
       "       [-0.3310516 ],\n",
       "       [ 0.42187798],\n",
       "       [-0.36608365],\n",
       "       [-0.06443477],\n",
       "       [-0.36801657],\n",
       "       [ 0.18870449]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "w = tf.Variable(initializer([30, 1]))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-1.0983639], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(initializer([1]))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기화된 모델을 사용한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35, shape=(455, 1), dtype=float32, numpy=\n",
       "array([[-2.1252222 ],\n",
       "       [-1.5490229 ],\n",
       "       [ 0.608871  ],\n",
       "       [-1.7290744 ],\n",
       "       [-2.0098555 ],\n",
       "       [-0.8528008 ],\n",
       "       [-1.9474809 ],\n",
       "       [ 0.40127265],\n",
       "       [-1.0223032 ],\n",
       "       [-0.7742876 ],\n",
       "       [-2.1731641 ],\n",
       "       [ 1.0337381 ],\n",
       "       [ 0.624583  ],\n",
       "       [ 1.4931362 ],\n",
       "       [-0.9493444 ],\n",
       "       [-0.08662248],\n",
       "       [-0.969683  ],\n",
       "       [-0.8419189 ],\n",
       "       [-1.1976266 ],\n",
       "       [-0.88844144],\n",
       "       [-1.174862  ],\n",
       "       [-2.3025477 ],\n",
       "       [-1.263816  ],\n",
       "       [-1.0483783 ],\n",
       "       [-1.9712318 ],\n",
       "       [-1.3852093 ],\n",
       "       [-0.99218225],\n",
       "       [-1.1640103 ],\n",
       "       [-0.25178653],\n",
       "       [-1.0324243 ],\n",
       "       [-1.1330237 ],\n",
       "       [ 0.20946014],\n",
       "       [-1.345972  ],\n",
       "       [-0.14745742],\n",
       "       [-1.482139  ],\n",
       "       [-2.715178  ],\n",
       "       [-2.1189485 ],\n",
       "       [-0.25359225],\n",
       "       [-0.9082525 ],\n",
       "       [-1.7756277 ],\n",
       "       [ 0.18617463],\n",
       "       [-1.245052  ],\n",
       "       [-1.3694254 ],\n",
       "       [ 0.5746101 ],\n",
       "       [-0.639305  ],\n",
       "       [-0.24138635],\n",
       "       [-1.2953861 ],\n",
       "       [-0.33743668],\n",
       "       [-0.73647004],\n",
       "       [-0.43984795],\n",
       "       [-1.2834382 ],\n",
       "       [-0.87505877],\n",
       "       [-1.1152695 ],\n",
       "       [-1.2892361 ],\n",
       "       [-0.6172465 ],\n",
       "       [ 0.01725006],\n",
       "       [-0.6942598 ],\n",
       "       [-0.6048337 ],\n",
       "       [-1.5702705 ],\n",
       "       [-0.92014825],\n",
       "       [-1.6306542 ],\n",
       "       [-0.98538053],\n",
       "       [-0.1980794 ],\n",
       "       [-0.96805036],\n",
       "       [-1.1904655 ],\n",
       "       [-0.96716106],\n",
       "       [-1.3923907 ],\n",
       "       [-1.725409  ],\n",
       "       [-1.2855482 ],\n",
       "       [ 0.55148673],\n",
       "       [-2.9951982 ],\n",
       "       [-1.4313933 ],\n",
       "       [-0.80144364],\n",
       "       [-0.61037135],\n",
       "       [-3.2223206 ],\n",
       "       [-1.7776763 ],\n",
       "       [-0.36049962],\n",
       "       [ 0.5969764 ],\n",
       "       [-0.6843068 ],\n",
       "       [-0.65398014],\n",
       "       [-0.61030746],\n",
       "       [-1.4406313 ],\n",
       "       [-1.7830486 ],\n",
       "       [-0.8661865 ],\n",
       "       [-1.8511229 ],\n",
       "       [-2.5958824 ],\n",
       "       [-1.3565319 ],\n",
       "       [-0.7530546 ],\n",
       "       [-1.0734842 ],\n",
       "       [-1.3819265 ],\n",
       "       [-2.3791847 ],\n",
       "       [-1.3687754 ],\n",
       "       [-1.7275999 ],\n",
       "       [-0.5241744 ],\n",
       "       [-0.5502703 ],\n",
       "       [-1.5392971 ],\n",
       "       [-1.3893731 ],\n",
       "       [ 0.13683844],\n",
       "       [-2.0121636 ],\n",
       "       [-1.6455755 ],\n",
       "       [-1.2423121 ],\n",
       "       [-2.520539  ],\n",
       "       [-2.7959337 ],\n",
       "       [-1.9854794 ],\n",
       "       [-1.0656126 ],\n",
       "       [-0.7012255 ],\n",
       "       [-0.5613348 ],\n",
       "       [-3.0033631 ],\n",
       "       [-0.4721011 ],\n",
       "       [-1.3253641 ],\n",
       "       [-1.7927713 ],\n",
       "       [ 0.27186775],\n",
       "       [-1.6916561 ],\n",
       "       [-1.5439317 ],\n",
       "       [-0.8998913 ],\n",
       "       [-1.4678646 ],\n",
       "       [-2.1937966 ],\n",
       "       [ 0.11454368],\n",
       "       [-1.3419168 ],\n",
       "       [-0.5039443 ],\n",
       "       [-2.0726047 ],\n",
       "       [-0.6741518 ],\n",
       "       [-1.2106084 ],\n",
       "       [-0.5523187 ],\n",
       "       [-2.0408247 ],\n",
       "       [-1.2803737 ],\n",
       "       [-1.1134844 ],\n",
       "       [-0.3058126 ],\n",
       "       [-1.8814616 ],\n",
       "       [-1.9596446 ],\n",
       "       [-0.49683362],\n",
       "       [-0.85354996],\n",
       "       [ 0.13813674],\n",
       "       [ 0.04690409],\n",
       "       [-2.3113837 ],\n",
       "       [-1.4919505 ],\n",
       "       [-0.6883692 ],\n",
       "       [-1.0140884 ],\n",
       "       [-0.15305209],\n",
       "       [-1.9366775 ],\n",
       "       [-2.2089193 ],\n",
       "       [-1.2191896 ],\n",
       "       [-1.2786655 ],\n",
       "       [-0.9009912 ],\n",
       "       [-1.3872796 ],\n",
       "       [-0.7275311 ],\n",
       "       [-1.4433868 ],\n",
       "       [-1.0085962 ],\n",
       "       [-2.2609448 ],\n",
       "       [-1.5579652 ],\n",
       "       [-0.3762769 ],\n",
       "       [-1.2694644 ],\n",
       "       [-1.4579784 ],\n",
       "       [-1.551283  ],\n",
       "       [-1.2141716 ],\n",
       "       [-1.999973  ],\n",
       "       [-0.23800242],\n",
       "       [-1.3696404 ],\n",
       "       [-1.1945648 ],\n",
       "       [-0.9932716 ],\n",
       "       [ 0.243227  ],\n",
       "       [-1.7234626 ],\n",
       "       [-0.5125244 ],\n",
       "       [-2.1211534 ],\n",
       "       [-2.1613538 ],\n",
       "       [-1.1554258 ],\n",
       "       [-1.846502  ],\n",
       "       [-2.3421135 ],\n",
       "       [-1.006346  ],\n",
       "       [-1.4874426 ],\n",
       "       [-0.621605  ],\n",
       "       [-0.33272076],\n",
       "       [-0.48100495],\n",
       "       [-1.5438147 ],\n",
       "       [-0.51159716],\n",
       "       [-1.5801072 ],\n",
       "       [-0.03473437],\n",
       "       [-0.84163094],\n",
       "       [ 0.08745515],\n",
       "       [-2.3875322 ],\n",
       "       [-2.1571624 ],\n",
       "       [-0.10949552],\n",
       "       [-4.6844387 ],\n",
       "       [-1.117908  ],\n",
       "       [-0.9209299 ],\n",
       "       [-0.23490661],\n",
       "       [-1.0099463 ],\n",
       "       [-1.340009  ],\n",
       "       [-0.11252463],\n",
       "       [-0.2547757 ],\n",
       "       [-0.08820546],\n",
       "       [-1.50014   ],\n",
       "       [-1.3515387 ],\n",
       "       [-0.6394743 ],\n",
       "       [-1.7525833 ],\n",
       "       [-1.4580762 ],\n",
       "       [-3.680069  ],\n",
       "       [-1.0371515 ],\n",
       "       [-0.08143115],\n",
       "       [-2.443491  ],\n",
       "       [-1.1436675 ],\n",
       "       [-1.42148   ],\n",
       "       [-2.3612175 ],\n",
       "       [-0.7873429 ],\n",
       "       [-2.837408  ],\n",
       "       [-0.6264609 ],\n",
       "       [-0.961931  ],\n",
       "       [-1.7349899 ],\n",
       "       [-0.518224  ],\n",
       "       [-1.1056322 ],\n",
       "       [-1.9264865 ],\n",
       "       [-3.5576546 ],\n",
       "       [-0.8149185 ],\n",
       "       [-1.2754151 ],\n",
       "       [-1.325491  ],\n",
       "       [-2.748367  ],\n",
       "       [-1.7856332 ],\n",
       "       [-1.9692147 ],\n",
       "       [-1.9680151 ],\n",
       "       [-0.61663043],\n",
       "       [-1.4425085 ],\n",
       "       [-1.4052403 ],\n",
       "       [-1.3484697 ],\n",
       "       [-1.6962395 ],\n",
       "       [-1.4775777 ],\n",
       "       [-1.7633247 ],\n",
       "       [-1.1743351 ],\n",
       "       [-0.9421723 ],\n",
       "       [-0.73961127],\n",
       "       [-0.17600566],\n",
       "       [-0.8007346 ],\n",
       "       [-0.78107625],\n",
       "       [-2.286004  ],\n",
       "       [-0.6031667 ],\n",
       "       [-0.3973304 ],\n",
       "       [-1.3930097 ],\n",
       "       [-0.93470085],\n",
       "       [ 0.48556995],\n",
       "       [-1.4942353 ],\n",
       "       [-1.2690916 ],\n",
       "       [-1.5442328 ],\n",
       "       [-0.9283763 ],\n",
       "       [-1.5435247 ],\n",
       "       [-1.570626  ],\n",
       "       [-0.26633567],\n",
       "       [-1.2832766 ],\n",
       "       [-0.35864204],\n",
       "       [ 0.71740425],\n",
       "       [-1.5514566 ],\n",
       "       [-0.9422589 ],\n",
       "       [-0.6836226 ],\n",
       "       [-1.4687694 ],\n",
       "       [-2.6071033 ],\n",
       "       [-1.3677592 ],\n",
       "       [-1.3124018 ],\n",
       "       [-1.8335176 ],\n",
       "       [-1.2694108 ],\n",
       "       [-1.1935363 ],\n",
       "       [-1.0881621 ],\n",
       "       [-0.1655817 ],\n",
       "       [-0.17001653],\n",
       "       [-2.2078922 ],\n",
       "       [-0.46449745],\n",
       "       [-0.6539931 ],\n",
       "       [-0.3270477 ],\n",
       "       [-1.8081616 ],\n",
       "       [-0.66110384],\n",
       "       [-1.2420638 ],\n",
       "       [-0.43955868],\n",
       "       [-2.6417336 ],\n",
       "       [-1.4542305 ],\n",
       "       [-0.44143772],\n",
       "       [-1.3990877 ],\n",
       "       [-1.7809535 ],\n",
       "       [-3.389742  ],\n",
       "       [-0.90909326],\n",
       "       [-0.7214323 ],\n",
       "       [-1.5464803 ],\n",
       "       [-1.2509645 ],\n",
       "       [-0.36977196],\n",
       "       [-0.6905962 ],\n",
       "       [ 0.0937748 ],\n",
       "       [-0.6714846 ],\n",
       "       [-0.62296474],\n",
       "       [-0.80925167],\n",
       "       [-0.7518554 ],\n",
       "       [-0.20883822],\n",
       "       [-2.3760328 ],\n",
       "       [-1.8096694 ],\n",
       "       [-0.95534474],\n",
       "       [-2.1166568 ],\n",
       "       [-2.0659547 ],\n",
       "       [-1.0194595 ],\n",
       "       [ 0.41788602],\n",
       "       [-1.942143  ],\n",
       "       [-0.3213181 ],\n",
       "       [-1.0909574 ],\n",
       "       [-0.27091098],\n",
       "       [-1.1830473 ],\n",
       "       [-0.95244926],\n",
       "       [-0.29492044],\n",
       "       [-0.31115514],\n",
       "       [-1.2750206 ],\n",
       "       [-1.2409592 ],\n",
       "       [ 0.10409892],\n",
       "       [-1.0469872 ],\n",
       "       [-0.51262254],\n",
       "       [ 0.58094454],\n",
       "       [-0.17060685],\n",
       "       [-0.14228344],\n",
       "       [-0.6165865 ],\n",
       "       [-1.1045548 ],\n",
       "       [-0.7869605 ],\n",
       "       [-0.1958518 ],\n",
       "       [-1.375632  ],\n",
       "       [ 0.21691132],\n",
       "       [-1.3681959 ],\n",
       "       [-0.87908447],\n",
       "       [-0.5001387 ],\n",
       "       [-0.5009515 ],\n",
       "       [-0.6338257 ],\n",
       "       [-1.6375716 ],\n",
       "       [ 0.36434805],\n",
       "       [-1.3341088 ],\n",
       "       [-0.9726842 ],\n",
       "       [-1.5407585 ],\n",
       "       [-0.40204805],\n",
       "       [-1.4295762 ],\n",
       "       [-2.1194367 ],\n",
       "       [-0.85474235],\n",
       "       [-0.2631678 ],\n",
       "       [-0.35276014],\n",
       "       [-0.26408845],\n",
       "       [-1.7366526 ],\n",
       "       [-1.244624  ],\n",
       "       [-1.3244209 ],\n",
       "       [-0.70078206],\n",
       "       [ 0.8027415 ],\n",
       "       [-1.3169073 ],\n",
       "       [-0.6488358 ],\n",
       "       [-1.7760428 ],\n",
       "       [ 0.30341125],\n",
       "       [-1.0020251 ],\n",
       "       [ 0.32447612],\n",
       "       [-1.1718041 ],\n",
       "       [ 0.05982995],\n",
       "       [-1.613755  ],\n",
       "       [-1.7772952 ],\n",
       "       [-0.90560675],\n",
       "       [-0.46957475],\n",
       "       [-1.5345151 ],\n",
       "       [-1.4613861 ],\n",
       "       [-2.034819  ],\n",
       "       [-0.5523357 ],\n",
       "       [-1.3883468 ],\n",
       "       [-1.6780639 ],\n",
       "       [-0.33250338],\n",
       "       [-3.099332  ],\n",
       "       [-2.473444  ],\n",
       "       [-1.1756973 ],\n",
       "       [-0.430826  ],\n",
       "       [-2.1314754 ],\n",
       "       [ 0.7852453 ],\n",
       "       [-0.12634432],\n",
       "       [-0.25518262],\n",
       "       [-0.02601171],\n",
       "       [-0.68538153],\n",
       "       [-0.3475154 ],\n",
       "       [-0.9937667 ],\n",
       "       [-0.9497864 ],\n",
       "       [ 0.08714986],\n",
       "       [-2.6795192 ],\n",
       "       [-1.2347527 ],\n",
       "       [ 0.65458584],\n",
       "       [-0.4472627 ],\n",
       "       [-0.61806166],\n",
       "       [-0.96189857],\n",
       "       [-0.6115296 ],\n",
       "       [-1.5337883 ],\n",
       "       [-2.6593566 ],\n",
       "       [-0.6018902 ],\n",
       "       [-2.8678122 ],\n",
       "       [-1.2389746 ],\n",
       "       [-3.2073035 ],\n",
       "       [-0.58794355],\n",
       "       [-4.8758025 ],\n",
       "       [-0.2749319 ],\n",
       "       [-0.5559027 ],\n",
       "       [-0.67943823],\n",
       "       [-0.18661326],\n",
       "       [-0.8449092 ],\n",
       "       [-1.2502356 ],\n",
       "       [-0.5393791 ],\n",
       "       [-2.636292  ],\n",
       "       [-0.5318444 ],\n",
       "       [-1.0268769 ],\n",
       "       [-0.70432824],\n",
       "       [-0.22101325],\n",
       "       [-3.5735931 ],\n",
       "       [-1.1899153 ],\n",
       "       [-0.32227552],\n",
       "       [-1.1288985 ],\n",
       "       [-2.225891  ],\n",
       "       [-1.5369151 ],\n",
       "       [-1.2920425 ],\n",
       "       [-2.305648  ],\n",
       "       [-0.7125039 ],\n",
       "       [-1.1035029 ],\n",
       "       [ 0.38248992],\n",
       "       [-0.51837945],\n",
       "       [-0.8306782 ],\n",
       "       [-0.19085878],\n",
       "       [-1.0055239 ],\n",
       "       [-0.6438453 ],\n",
       "       [-1.2682375 ],\n",
       "       [-0.70730656],\n",
       "       [-0.5559383 ],\n",
       "       [-1.2154584 ],\n",
       "       [-0.54147613],\n",
       "       [-0.06115174],\n",
       "       [-1.1308159 ],\n",
       "       [-0.81420785],\n",
       "       [-2.5563548 ],\n",
       "       [-1.3792689 ],\n",
       "       [ 0.00716758],\n",
       "       [-0.5087097 ],\n",
       "       [-1.3674481 ],\n",
       "       [-2.0393593 ],\n",
       "       [-0.57635045],\n",
       "       [-0.5641078 ],\n",
       "       [-2.161434  ],\n",
       "       [-2.018028  ],\n",
       "       [-1.507704  ],\n",
       "       [-1.2703335 ],\n",
       "       [-1.8460023 ],\n",
       "       [-0.664958  ],\n",
       "       [-0.9872715 ],\n",
       "       [-0.6574178 ],\n",
       "       [-1.9246166 ],\n",
       "       [-0.75795007],\n",
       "       [-0.2626034 ],\n",
       "       [-0.64426816],\n",
       "       [-1.0394866 ],\n",
       "       [-1.9178594 ],\n",
       "       [-1.4062252 ],\n",
       "       [-0.5671972 ],\n",
       "       [-0.5491016 ],\n",
       "       [-1.8766296 ],\n",
       "       [-0.6150334 ],\n",
       "       [-0.9773862 ],\n",
       "       [-0.55583864],\n",
       "       [-0.5956225 ],\n",
       "       [-1.8203568 ],\n",
       "       [-3.6154578 ],\n",
       "       [-1.9207566 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X_train, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(455, 1), dtype=float32, numpy=\n",
       "array([[0.10666943],\n",
       "       [0.17522743],\n",
       "       [0.6476832 ],\n",
       "       [0.15070602],\n",
       "       [0.11817202],\n",
       "       [0.29884565],\n",
       "       [0.12482831],\n",
       "       [0.59899336],\n",
       "       [0.264579  ],\n",
       "       [0.31555235],\n",
       "       [0.10218638],\n",
       "       [0.73763996],\n",
       "       [0.65126014],\n",
       "       [0.8165485 ],\n",
       "       [0.2790167 ],\n",
       "       [0.4783579 ],\n",
       "       [0.2749437 ],\n",
       "       [0.30113083],\n",
       "       [0.23189774],\n",
       "       [0.2914316 ],\n",
       "       [0.23597726],\n",
       "       [0.09091216],\n",
       "       [0.22031769],\n",
       "       [0.25953665],\n",
       "       [0.12225664],\n",
       "       [0.20017368],\n",
       "       [0.2704813 ],\n",
       "       [0.23793939],\n",
       "       [0.43738383],\n",
       "       [0.26261437],\n",
       "       [0.24360353],\n",
       "       [0.5521744 ],\n",
       "       [0.2065297 ],\n",
       "       [0.4632023 ],\n",
       "       [0.18510455],\n",
       "       [0.06208363],\n",
       "       [0.10726869],\n",
       "       [0.43693954],\n",
       "       [0.28735757],\n",
       "       [0.14484388],\n",
       "       [0.54640967],\n",
       "       [0.22355786],\n",
       "       [0.20271271],\n",
       "       [0.63982624],\n",
       "       [0.34540367],\n",
       "       [0.43994474],\n",
       "       [0.21494254],\n",
       "       [0.4164323 ],\n",
       "       [0.32377654],\n",
       "       [0.39177722],\n",
       "       [0.21696556],\n",
       "       [0.29420277],\n",
       "       [0.2468898 ],\n",
       "       [0.21598211],\n",
       "       [0.35040796],\n",
       "       [0.5043124 ],\n",
       "       [0.33308613],\n",
       "       [0.3532386 ],\n",
       "       [0.17217782],\n",
       "       [0.28492773],\n",
       "       [0.16374075],\n",
       "       [0.2718255 ],\n",
       "       [0.45064142],\n",
       "       [0.2752693 ],\n",
       "       [0.2331757 ],\n",
       "       [0.27544677],\n",
       "       [0.19902638],\n",
       "       [0.15117574],\n",
       "       [0.21660727],\n",
       "       [0.6344805 ],\n",
       "       [0.04764327],\n",
       "       [0.1928817 ],\n",
       "       [0.30971682],\n",
       "       [0.3519745 ],\n",
       "       [0.03833431],\n",
       "       [0.14459032],\n",
       "       [0.41083863],\n",
       "       [0.6449642 ],\n",
       "       [0.33530074],\n",
       "       [0.3420932 ],\n",
       "       [0.3519891 ],\n",
       "       [0.19144762],\n",
       "       [0.1439271 ],\n",
       "       [0.29604846],\n",
       "       [0.13574108],\n",
       "       [0.06940389],\n",
       "       [0.20480451],\n",
       "       [0.3201561 ],\n",
       "       [0.25474107],\n",
       "       [0.20069978],\n",
       "       [0.08477378],\n",
       "       [0.2028178 ],\n",
       "       [0.15089482],\n",
       "       [0.37187666],\n",
       "       [0.3658017 ],\n",
       "       [0.17663747],\n",
       "       [0.19950783],\n",
       "       [0.5341563 ],\n",
       "       [0.11793172],\n",
       "       [0.16170785],\n",
       "       [0.22403377],\n",
       "       [0.07443079],\n",
       "       [0.05754423],\n",
       "       [0.12073591],\n",
       "       [0.25623837],\n",
       "       [0.33154058],\n",
       "       [0.3632387 ],\n",
       "       [0.04727414],\n",
       "       [0.38411906],\n",
       "       [0.20992723],\n",
       "       [0.14273328],\n",
       "       [0.5675514 ],\n",
       "       [0.15555817],\n",
       "       [0.17596444],\n",
       "       [0.2890728 ],\n",
       "       [0.18726742],\n",
       "       [0.10030892],\n",
       "       [0.5286046 ],\n",
       "       [0.20719498],\n",
       "       [0.3766142 ],\n",
       "       [0.11178812],\n",
       "       [0.3375678 ],\n",
       "       [0.22959346],\n",
       "       [0.36532664],\n",
       "       [0.11498278],\n",
       "       [0.21748662],\n",
       "       [0.24722186],\n",
       "       [0.42413718],\n",
       "       [0.13222104],\n",
       "       [0.1235055 ],\n",
       "       [0.37828508],\n",
       "       [0.2986887 ],\n",
       "       [0.5344794 ],\n",
       "       [0.5117239 ],\n",
       "       [0.09018454],\n",
       "       [0.18362913],\n",
       "       [0.33439595],\n",
       "       [0.26618052],\n",
       "       [0.4618115 ],\n",
       "       [0.12601331],\n",
       "       [0.09895235],\n",
       "       [0.22807911],\n",
       "       [0.21777743],\n",
       "       [0.28884688],\n",
       "       [0.1998424 ],\n",
       "       [0.32573676],\n",
       "       [0.19102147],\n",
       "       [0.2672547 ],\n",
       "       [0.09440953],\n",
       "       [0.17393881],\n",
       "       [0.4070252 ],\n",
       "       [0.21934894],\n",
       "       [0.18877673],\n",
       "       [0.17490104],\n",
       "       [0.22896376],\n",
       "       [0.11920574],\n",
       "       [0.44077867],\n",
       "       [0.20267797],\n",
       "       [0.23244351],\n",
       "       [0.27026635],\n",
       "       [0.5605087 ],\n",
       "       [0.15142569],\n",
       "       [0.37460196],\n",
       "       [0.10705778],\n",
       "       [0.10327497],\n",
       "       [0.23949945],\n",
       "       [0.13628411],\n",
       "       [0.08769467],\n",
       "       [0.26769555],\n",
       "       [0.1843059 ],\n",
       "       [0.3494165 ],\n",
       "       [0.4175788 ],\n",
       "       [0.38201487],\n",
       "       [0.17598143],\n",
       "       [0.37481922],\n",
       "       [0.1707803 ],\n",
       "       [0.49131727],\n",
       "       [0.3011914 ],\n",
       "       [0.5218499 ],\n",
       "       [0.08412835],\n",
       "       [0.10366377],\n",
       "       [0.47265345],\n",
       "       [0.00915331],\n",
       "       [0.24639952],\n",
       "       [0.28476846],\n",
       "       [0.4415419 ],\n",
       "       [0.26699036],\n",
       "       [0.2075086 ],\n",
       "       [0.4718985 ],\n",
       "       [0.4366484 ],\n",
       "       [0.4779629 ],\n",
       "       [0.18240464],\n",
       "       [0.20561892],\n",
       "       [0.3453654 ],\n",
       "       [0.14772165],\n",
       "       [0.18876174],\n",
       "       [0.0246008 ],\n",
       "       [0.2617    ],\n",
       "       [0.47965345],\n",
       "       [0.07991585],\n",
       "       [0.24164766],\n",
       "       [0.1944297 ],\n",
       "       [0.08617821],\n",
       "       [0.3127395 ],\n",
       "       [0.05533585],\n",
       "       [0.34831345],\n",
       "       [0.27649176],\n",
       "       [0.14995041],\n",
       "       [0.37326762],\n",
       "       [0.24868608],\n",
       "       [0.12713999],\n",
       "       [0.02771556],\n",
       "       [0.3068434 ],\n",
       "       [0.2183317 ],\n",
       "       [0.20990619],\n",
       "       [0.06017894],\n",
       "       [0.14360893],\n",
       "       [0.12247327],\n",
       "       [0.12260225],\n",
       "       [0.3505482 ],\n",
       "       [0.19115722],\n",
       "       [0.19698587],\n",
       "       [0.20612067],\n",
       "       [0.15495703],\n",
       "       [0.18579358],\n",
       "       [0.14637443],\n",
       "       [0.2360723 ],\n",
       "       [0.2804618 ],\n",
       "       [0.32308918],\n",
       "       [0.45611182],\n",
       "       [0.30986843],\n",
       "       [0.314088  ],\n",
       "       [0.09228876],\n",
       "       [0.35361955],\n",
       "       [0.4019539 ],\n",
       "       [0.1989277 ],\n",
       "       [0.28197202],\n",
       "       [0.61906224],\n",
       "       [0.1832869 ],\n",
       "       [0.2194128 ],\n",
       "       [0.17592075],\n",
       "       [0.28325427],\n",
       "       [0.17602345],\n",
       "       [0.17212716],\n",
       "       [0.4338069 ],\n",
       "       [0.216993  ],\n",
       "       [0.41128832],\n",
       "       [0.67203516],\n",
       "       [0.174876  ],\n",
       "       [0.28044432],\n",
       "       [0.33545327],\n",
       "       [0.1871297 ],\n",
       "       [0.06868267],\n",
       "       [0.20298213],\n",
       "       [0.21208522],\n",
       "       [0.13781977],\n",
       "       [0.21935812],\n",
       "       [0.2326271 ],\n",
       "       [0.2519645 ],\n",
       "       [0.4586989 ],\n",
       "       [0.45759797],\n",
       "       [0.099044  ],\n",
       "       [0.38591945],\n",
       "       [0.34209025],\n",
       "       [0.41895914],\n",
       "       [0.14086044],\n",
       "       [0.3404917 ],\n",
       "       [0.22407696],\n",
       "       [0.39184615],\n",
       "       [0.06650031],\n",
       "       [0.18935135],\n",
       "       [0.39139846],\n",
       "       [0.19796091],\n",
       "       [0.14418542],\n",
       "       [0.03261754],\n",
       "       [0.28718543],\n",
       "       [0.3270777 ],\n",
       "       [0.17559522],\n",
       "       [0.2225332 ],\n",
       "       [0.40859613],\n",
       "       [0.33390045],\n",
       "       [0.52342653],\n",
       "       [0.3381645 ],\n",
       "       [0.34910747],\n",
       "       [0.30805   ],\n",
       "       [0.32041717],\n",
       "       [0.4479794 ],\n",
       "       [0.08501863],\n",
       "       [0.14067805],\n",
       "       [0.27781123],\n",
       "       [0.10748836],\n",
       "       [0.11245012],\n",
       "       [0.26513273],\n",
       "       [0.6029773 ],\n",
       "       [0.12541261],\n",
       "       [0.42035455],\n",
       "       [0.25143802],\n",
       "       [0.43268347],\n",
       "       [0.23450476],\n",
       "       [0.27839252],\n",
       "       [0.4267997 ],\n",
       "       [0.42283282],\n",
       "       [0.21839899],\n",
       "       [0.22426909],\n",
       "       [0.5260013 ],\n",
       "       [0.25980407],\n",
       "       [0.37457895],\n",
       "       [0.6412847 ],\n",
       "       [0.45745143],\n",
       "       [0.46448904],\n",
       "       [0.35055822],\n",
       "       [0.24888745],\n",
       "       [0.3128217 ],\n",
       "       [0.45119298],\n",
       "       [0.20171145],\n",
       "       [0.5540162 ],\n",
       "       [0.2029115 ],\n",
       "       [0.29336753],\n",
       "       [0.37750807],\n",
       "       [0.3773171 ],\n",
       "       [0.3466436 ],\n",
       "       [0.16279575],\n",
       "       [0.59009254],\n",
       "       [0.20848054],\n",
       "       [0.27434582],\n",
       "       [0.17642501],\n",
       "       [0.40082037],\n",
       "       [0.1931647 ],\n",
       "       [0.10722196],\n",
       "       [0.298439  ],\n",
       "       [0.43458515],\n",
       "       [0.41271326],\n",
       "       [0.43435895],\n",
       "       [0.14973861],\n",
       "       [0.22363216],\n",
       "       [0.21008375],\n",
       "       [0.33163887],\n",
       "       [0.6905606 ],\n",
       "       [0.2113333 ],\n",
       "       [0.34325194],\n",
       "       [0.14479244],\n",
       "       [0.5752762 ],\n",
       "       [0.26854345],\n",
       "       [0.5804147 ],\n",
       "       [0.23652905],\n",
       "       [0.514953  ],\n",
       "       [0.16606796],\n",
       "       [0.14463744],\n",
       "       [0.28789967],\n",
       "       [0.3847169 ],\n",
       "       [0.17733404],\n",
       "       [0.18825537],\n",
       "       [0.11559528],\n",
       "       [0.3653227 ],\n",
       "       [0.1996718 ],\n",
       "       [0.157352  ],\n",
       "       [0.41763166],\n",
       "       [0.04313484],\n",
       "       [0.07774091],\n",
       "       [0.2358267 ],\n",
       "       [0.39392912],\n",
       "       [0.10607499],\n",
       "       [0.6868095 ],\n",
       "       [0.46845588],\n",
       "       [0.4365483 ],\n",
       "       [0.49349743],\n",
       "       [0.33506125],\n",
       "       [0.41398507],\n",
       "       [0.27016872],\n",
       "       [0.2789278 ],\n",
       "       [0.5217737 ],\n",
       "       [0.06419274],\n",
       "       [0.22535068],\n",
       "       [0.65804315],\n",
       "       [0.3900118 ],\n",
       "       [0.35022247],\n",
       "       [0.27649826],\n",
       "       [0.35171038],\n",
       "       [0.17744005],\n",
       "       [0.06541461],\n",
       "       [0.35391137],\n",
       "       [0.05376783],\n",
       "       [0.22461453],\n",
       "       [0.03889179],\n",
       "       [0.35710686],\n",
       "       [0.00757122],\n",
       "       [0.4316967 ],\n",
       "       [0.36449605],\n",
       "       [0.33638674],\n",
       "       [0.4534816 ],\n",
       "       [0.30050188],\n",
       "       [0.22265935],\n",
       "       [0.36833203],\n",
       "       [0.06683889],\n",
       "       [0.37008685],\n",
       "       [0.26369005],\n",
       "       [0.33085334],\n",
       "       [0.44497052],\n",
       "       [0.0272893 ],\n",
       "       [0.2332741 ],\n",
       "       [0.4201213 ],\n",
       "       [0.24436444],\n",
       "       [0.09744942],\n",
       "       [0.17698419],\n",
       "       [0.2155073 ],\n",
       "       [0.09065622],\n",
       "       [0.3290458 ],\n",
       "       [0.24908414],\n",
       "       [0.5944735 ],\n",
       "       [0.37323126],\n",
       "       [0.30350167],\n",
       "       [0.45242962],\n",
       "       [0.26785678],\n",
       "       [0.34437782],\n",
       "       [0.2195591 ],\n",
       "       [0.3301943 ],\n",
       "       [0.36448777],\n",
       "       [0.22873667],\n",
       "       [0.36784428],\n",
       "       [0.48471683],\n",
       "       [0.24401057],\n",
       "       [0.30699456],\n",
       "       [0.07200074],\n",
       "       [0.20112643],\n",
       "       [0.5017919 ],\n",
       "       [0.3754961 ],\n",
       "       [0.20303243],\n",
       "       [0.11513194],\n",
       "       [0.3597728 ],\n",
       "       [0.36259753],\n",
       "       [0.10326761],\n",
       "       [0.11732301],\n",
       "       [0.1812793 ],\n",
       "       [0.21920016],\n",
       "       [0.13634294],\n",
       "       [0.33962676],\n",
       "       [0.27145135],\n",
       "       [0.34131992],\n",
       "       [0.12734768],\n",
       "       [0.3190915 ],\n",
       "       [0.43472385],\n",
       "       [0.3442824 ],\n",
       "       [0.26124907],\n",
       "       [0.12810043],\n",
       "       [0.19683015],\n",
       "       [0.36188382],\n",
       "       [0.3660729 ],\n",
       "       [0.1327765 ],\n",
       "       [0.3509119 ],\n",
       "       [0.27341074],\n",
       "       [0.36451086],\n",
       "       [0.35534585],\n",
       "       [0.13939106],\n",
       "       [0.02619971],\n",
       "       [0.12777722]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X_train, w) + b)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 비율 0.001의 AdamOptimizer를 활용한 학습 방법 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "step: 0, cost : 0.8821099996566772, w:[[-0.16178145]\n",
      " [ 0.06906466]\n",
      " [ 0.414222  ]\n",
      " [-0.07470687]\n",
      " [ 0.0343306 ]\n",
      " [ 0.35916597]\n",
      " [-0.17526068]\n",
      " [-0.37282082]\n",
      " [ 0.1670128 ]\n",
      " [-0.40948147]\n",
      " [-0.18628852]\n",
      " [ 0.16587107]\n",
      " [-0.2797697 ]\n",
      " [-0.02872826]\n",
      " [ 0.24968076]\n",
      " [-0.07114089]\n",
      " [ 0.40601456]\n",
      " [ 0.00952436]\n",
      " [-0.0401459 ]\n",
      " [-0.36695233]\n",
      " [-0.12426801]\n",
      " [ 0.31512952]\n",
      " [-0.22935727]\n",
      " [ 0.3454827 ]\n",
      " [-0.33205158]\n",
      " [ 0.420878  ]\n",
      " [-0.36708364]\n",
      " [-0.06543477]\n",
      " [-0.36901656]\n",
      " [ 0.18770449]] , b : [-1.0973638]\n",
      "==================================================\n",
      "step: 10, cost : 0.8220657110214233, w:[[-0.17175229]\n",
      " [ 0.05908696]\n",
      " [ 0.4042518 ]\n",
      " [-0.08467752]\n",
      " [ 0.02439495]\n",
      " [ 0.3492115 ]\n",
      " [-0.18522313]\n",
      " [-0.38278612]\n",
      " [ 0.15706909]\n",
      " [-0.39945912]\n",
      " [-0.1962578 ]\n",
      " [ 0.1558806 ]\n",
      " [-0.2897378 ]\n",
      " [-0.03869833]\n",
      " [ 0.25965825]\n",
      " [-0.0810786 ]\n",
      " [ 0.3960803 ]\n",
      " [-0.00042841]\n",
      " [-0.03014495]\n",
      " [-0.36934078]\n",
      " [-0.1342388 ]\n",
      " [ 0.30515197]\n",
      " [-0.2393272 ]\n",
      " [ 0.33551225]\n",
      " [-0.34200612]\n",
      " [ 0.41091996]\n",
      " [-0.37704474]\n",
      " [-0.07539951]\n",
      " [-0.37897366]\n",
      " [ 0.17777038]] , b : [-1.0873734]\n",
      "==================================================\n",
      "step: 20, cost : 0.7669699788093567, w:[[-0.1815943 ]\n",
      " [ 0.04920735]\n",
      " [ 0.3944132 ]\n",
      " [-0.09451925]\n",
      " [ 0.01474514]\n",
      " [ 0.33945465]\n",
      " [-0.19502346]\n",
      " [-0.3926001 ]\n",
      " [ 0.14737147]\n",
      " [-0.38936785]\n",
      " [-0.20609526]\n",
      " [ 0.14592163]\n",
      " [-0.2995693 ]\n",
      " [-0.0485397 ]\n",
      " [ 0.2694775 ]\n",
      " [-0.09075073]\n",
      " [ 0.3864305 ]\n",
      " [-0.0101761 ]\n",
      " [-0.02018388]\n",
      " [-0.3596275 ]\n",
      " [-0.14408043]\n",
      " [ 0.29527435]\n",
      " [-0.24916476]\n",
      " [ 0.3256716 ]\n",
      " [-0.35175994]\n",
      " [ 0.40114492]\n",
      " [-0.38683593]\n",
      " [-0.08520888]\n",
      " [-0.38874143]\n",
      " [ 0.16812044]] , b : [-1.0774298]\n",
      "==================================================\n",
      "step: 30, cost : 0.7168909311294556, w:[[-0.19122015]\n",
      " [ 0.03949223]\n",
      " [ 0.384795  ]\n",
      " [-0.10414645]\n",
      " [ 0.0055853 ]\n",
      " [ 0.3300266 ]\n",
      " [-0.20455627]\n",
      " [-0.40216312]\n",
      " [ 0.13808708]\n",
      " [-0.37920436]\n",
      " [-0.2157181 ]\n",
      " [ 0.13600717]\n",
      " [-0.30917853]\n",
      " [-0.05817136]\n",
      " [ 0.27893585]\n",
      " [-0.09998191]\n",
      " [ 0.3772638 ]\n",
      " [-0.01957802]\n",
      " [-0.010353  ]\n",
      " [-0.3475767 ]\n",
      " [-0.15370601]\n",
      " [ 0.2855657 ]\n",
      " [-0.25878128]\n",
      " [ 0.31604654]\n",
      " [-0.36117664]\n",
      " [ 0.39167506]\n",
      " [-0.39634323]\n",
      " [-0.09475717]\n",
      " [-0.39819095]\n",
      " [ 0.1589438 ]] , b : [-1.067577]\n",
      "==================================================\n",
      "step: 40, cost : 0.6716835498809814, w:[[-0.20057487]\n",
      " [ 0.02998431]\n",
      " [ 0.37545297]\n",
      " [-0.1135067 ]\n",
      " [-0.00293843]\n",
      " [ 0.32101303]\n",
      " [-0.21375564]\n",
      " [-0.41141313]\n",
      " [ 0.12932825]\n",
      " [-0.36898747]\n",
      " [-0.22507772]\n",
      " [ 0.12615338]\n",
      " [-0.31851488]\n",
      " [-0.06754623]\n",
      " [ 0.28784752]\n",
      " [-0.10864857]\n",
      " [ 0.36873162]\n",
      " [-0.02853406]\n",
      " [-0.00073439]\n",
      " [-0.33448756]\n",
      " [-0.16306172]\n",
      " [ 0.27607077]\n",
      " [-0.26812175]\n",
      " [ 0.30668843]\n",
      " [-0.3701694 ]\n",
      " [ 0.38258922]\n",
      " [-0.4054927 ]\n",
      " [-0.10397612]\n",
      " [-0.40724063]\n",
      " [ 0.15036792]] , b : [-1.0578544]\n",
      "==================================================\n",
      "step: 50, cost : 0.6310171484947205, w:[[-0.20963146]\n",
      " [ 0.02070562]\n",
      " [ 0.3664144 ]\n",
      " [-0.12257571]\n",
      " [-0.01073775]\n",
      " [ 0.31245813]\n",
      " [-0.22258987]\n",
      " [-0.4203209 ]\n",
      " [ 0.12115651]\n",
      " [-0.35874826]\n",
      " [-0.2341536 ]\n",
      " [ 0.11638017]\n",
      " [-0.3275566 ]\n",
      " [-0.07664485]\n",
      " [ 0.296058  ]\n",
      " [-0.11667724]\n",
      " [ 0.360937  ]\n",
      " [-0.03698379]\n",
      " [ 0.00861265]\n",
      " [-0.3208109 ]\n",
      " [-0.17212217]\n",
      " [ 0.26681244]\n",
      " [-0.2771604 ]\n",
      " [ 0.29761997]\n",
      " [-0.37869826]\n",
      " [ 0.37392667]\n",
      " [-0.41424674]\n",
      " [-0.11283132]\n",
      " [-0.41585183]\n",
      " [ 0.1424594 ]] , b : [-1.0482916]\n",
      "==================================================\n",
      "step: 60, cost : 0.5944710373878479, w:[[-0.21838188]\n",
      " [ 0.01166411]\n",
      " [ 0.3576872 ]\n",
      " [-0.13134779]\n",
      " [-0.01776892]\n",
      " [ 0.3043768 ]\n",
      " [-0.23105055]\n",
      " [-0.42887905]\n",
      " [ 0.11359667]\n",
      " [-0.34852138]\n",
      " [-0.24294312]\n",
      " [ 0.10671004]\n",
      " [-0.33630052]\n",
      " [-0.08546524]\n",
      " [ 0.3034456 ]\n",
      " [-0.12403223]\n",
      " [ 0.3539456 ]\n",
      " [-0.0448969 ]\n",
      " [ 0.01765483]\n",
      " [-0.30681416]\n",
      " [-0.18088117]\n",
      " [ 0.2577987 ]\n",
      " [-0.28589097]\n",
      " [ 0.28884497]\n",
      " [-0.38675725]\n",
      " [ 0.36569867]\n",
      " [-0.42259344]\n",
      " [-0.12131216]\n",
      " [-0.42401642]\n",
      " [ 0.13523908]] , b : [-1.0389078]\n",
      "==================================================\n",
      "step: 70, cost : 0.5616028308868408, w:[[-0.22682908]\n",
      " [ 0.00285949]\n",
      " [ 0.3492681 ]\n",
      " [-0.13982779]\n",
      " [-0.02401832]\n",
      " [ 0.29676628]\n",
      " [-0.2391428 ]\n",
      " [-0.43709314]\n",
      " [ 0.10665065]\n",
      " [-0.33833936]\n",
      " [-0.2514534 ]\n",
      " [ 0.09716602]\n",
      " [-0.34475368]\n",
      " [-0.09401487]\n",
      " [ 0.3099179 ]\n",
      " [-0.13070293]\n",
      " [ 0.3477972 ]\n",
      " [-0.05226308]\n",
      " [ 0.02638167]\n",
      " [-0.29267442]\n",
      " [-0.18934347]\n",
      " [ 0.24902868]\n",
      " [-0.29431835]\n",
      " [ 0.28035668]\n",
      " [-0.39436123]\n",
      " [ 0.35789967]\n",
      " [-0.43053618]\n",
      " [-0.12942249]\n",
      " [-0.43174434]\n",
      " [ 0.12869781]] , b : [-1.0297139]\n",
      "==================================================\n",
      "step: 80, cost : 0.5319859385490417, w:[[-0.23498197]\n",
      " [-0.00571298]\n",
      " [ 0.34114787]\n",
      " [-0.14802589]\n",
      " [-0.02949199]\n",
      " [ 0.2896135 ]\n",
      " [-0.24687882]\n",
      " [-0.44497547]\n",
      " [ 0.10030685]\n",
      " [-0.32823095]\n",
      " [-0.2596961 ]\n",
      " [ 0.08776988]\n",
      " [-0.3529279 ]\n",
      " [-0.10230549]\n",
      " [ 0.315407  ]\n",
      " [-0.13669491]\n",
      " [ 0.34251356]\n",
      " [-0.05908482]\n",
      " [ 0.03479938]\n",
      " [-0.27851292]\n",
      " [-0.19751947]\n",
      " [ 0.24049672]\n",
      " [-0.30245328]\n",
      " [ 0.2721432 ]\n",
      " [-0.40153623]\n",
      " [ 0.3505145 ]\n",
      " [-0.43808705]\n",
      " [-0.1371742 ]\n",
      " [-0.43905523]\n",
      " [ 0.12280857]] , b : [-1.0207142]\n",
      "==================================================\n",
      "step: 90, cost : 0.505227267742157, w:[[-0.2428524 ]\n",
      " [-0.01406042]\n",
      " [ 0.33331415]\n",
      " [-0.15595473]\n",
      " [-0.03420911]\n",
      " [ 0.28289977]\n",
      " [-0.2542745 ]\n",
      " [-0.4525415 ]\n",
      " [ 0.09454548]\n",
      " [-0.31822023]\n",
      " [-0.26768476]\n",
      " [ 0.07854085]\n",
      " [-0.36083698]\n",
      " [-0.11035068]\n",
      " [ 0.3198654 ]\n",
      " [-0.1420248 ]\n",
      " [ 0.33810347]\n",
      " [-0.06537287]\n",
      " [ 0.04292457]\n",
      " [-0.26441494]\n",
      " [-0.20542222]\n",
      " [ 0.23219475]\n",
      " [-0.3103093 ]\n",
      " [ 0.26419044]\n",
      " [-0.40831402]\n",
      " [ 0.3435233 ]\n",
      " [-0.4452626 ]\n",
      " [-0.1445834 ]\n",
      " [-0.4459734 ]\n",
      " [ 0.11753356]] , b : [-1.0119079]\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.sigmoid(tf.matmul(X_train, w) + b)\n",
    "        \n",
    "        cost = -tf.reduce_mean(y_train * tf.log(hypothesis) + (1-y_train) * tf.log(1-hypothesis))\n",
    "        \n",
    "        grads = tape.gradient(cost, [w, b])\n",
    "        \n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"step: {step}, cost : {cost.numpy()}, w:{w.numpy()} , b : {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트를 위한 X_test 값 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7643122 , -1.0980948 , -0.75629514, ..., -0.6336217 ,\n",
       "         0.06653161,  0.4873876 ],\n",
       "       [-0.20264688, -0.09050625, -0.19959095, ...,  0.42021096,\n",
       "         1.0247265 ,  0.17642455],\n",
       "       [-0.8412916 ,  3.5571585 , -0.888745  , ..., -1.3160934 ,\n",
       "         0.01671226, -0.6435524 ],\n",
       "       ...,\n",
       "       [ 0.3419118 ,  0.8807511 ,  0.32855323, ...,  0.49571574,\n",
       "        -0.5728182 , -0.9327784 ],\n",
       "       [ 0.38752922,  3.496606  ,  0.4734204 , ...,  1.3247287 ,\n",
       "         1.014763  ,  2.2142901 ],\n",
       "       [ 1.1801329 , -0.13168176,  1.0901408 , ...,  0.64210296,\n",
       "         0.506604  , -0.8663589 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델을 활용한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6850, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[4.51519430e-01],\n",
       "       [2.20027715e-01],\n",
       "       [8.47060144e-01],\n",
       "       [3.63017231e-01],\n",
       "       [6.23800695e-01],\n",
       "       [3.62491965e-01],\n",
       "       [4.82323408e-01],\n",
       "       [4.80925053e-01],\n",
       "       [6.51678860e-01],\n",
       "       [5.03819525e-01],\n",
       "       [1.12269461e-01],\n",
       "       [8.34834814e-01],\n",
       "       [3.10484171e-02],\n",
       "       [1.14017725e-02],\n",
       "       [4.72046882e-01],\n",
       "       [8.89845967e-01],\n",
       "       [5.20173192e-01],\n",
       "       [2.60322213e-01],\n",
       "       [7.11223483e-01],\n",
       "       [4.53748047e-01],\n",
       "       [3.32936198e-01],\n",
       "       [8.59707594e-02],\n",
       "       [9.58164930e-02],\n",
       "       [6.61950588e-01],\n",
       "       [6.62808180e-01],\n",
       "       [5.84268332e-01],\n",
       "       [4.63006318e-01],\n",
       "       [3.99571478e-01],\n",
       "       [3.05386603e-01],\n",
       "       [7.67283857e-01],\n",
       "       [7.62680233e-01],\n",
       "       [6.22019112e-01],\n",
       "       [5.56178391e-02],\n",
       "       [4.13089603e-01],\n",
       "       [8.02984476e-01],\n",
       "       [7.74280429e-01],\n",
       "       [7.34356284e-01],\n",
       "       [3.70598257e-01],\n",
       "       [7.78641522e-01],\n",
       "       [2.66921759e-01],\n",
       "       [9.11243558e-02],\n",
       "       [6.33589745e-01],\n",
       "       [8.48889351e-04],\n",
       "       [6.07030094e-01],\n",
       "       [3.59906256e-01],\n",
       "       [5.89655936e-01],\n",
       "       [7.04313099e-01],\n",
       "       [2.80911416e-01],\n",
       "       [8.01140070e-03],\n",
       "       [8.19900513e-01],\n",
       "       [1.56289339e-03],\n",
       "       [2.89559364e-03],\n",
       "       [6.79325938e-01],\n",
       "       [6.22670352e-01],\n",
       "       [7.60011077e-02],\n",
       "       [7.35386491e-01],\n",
       "       [2.46054590e-01],\n",
       "       [5.98902583e-01],\n",
       "       [6.78222120e-01],\n",
       "       [1.91839635e-02],\n",
       "       [5.54097891e-02],\n",
       "       [4.71990794e-01],\n",
       "       [8.65900517e-03],\n",
       "       [2.02089816e-01],\n",
       "       [6.92501068e-01],\n",
       "       [1.96105540e-01],\n",
       "       [7.04148054e-01],\n",
       "       [1.24922395e-03],\n",
       "       [1.47853464e-01],\n",
       "       [8.65497351e-01],\n",
       "       [1.05426371e-01],\n",
       "       [8.52999091e-02],\n",
       "       [4.51469421e-02],\n",
       "       [6.84074998e-01],\n",
       "       [8.56006145e-02],\n",
       "       [5.68232954e-01],\n",
       "       [6.93801939e-01],\n",
       "       [6.91123605e-02],\n",
       "       [4.37684119e-01],\n",
       "       [8.76613498e-01],\n",
       "       [6.43966198e-02],\n",
       "       [2.68787026e-01],\n",
       "       [7.87384808e-01],\n",
       "       [3.59502435e-03],\n",
       "       [7.33294606e-01],\n",
       "       [5.00264466e-01],\n",
       "       [2.47695684e-01],\n",
       "       [8.81424129e-01],\n",
       "       [5.42018831e-01],\n",
       "       [3.91179025e-01],\n",
       "       [3.94873619e-02],\n",
       "       [3.95820111e-01],\n",
       "       [2.37183183e-01],\n",
       "       [9.63426888e-01],\n",
       "       [7.20731378e-01],\n",
       "       [5.24471939e-01],\n",
       "       [8.53574276e-03],\n",
       "       [1.99636817e-02],\n",
       "       [9.53460336e-02],\n",
       "       [5.29253185e-01],\n",
       "       [4.24264133e-01],\n",
       "       [5.77022672e-01],\n",
       "       [8.00958157e-01],\n",
       "       [2.23883092e-02],\n",
       "       [7.68286347e-01],\n",
       "       [4.79903817e-01],\n",
       "       [2.59510219e-01],\n",
       "       [6.70910239e-01],\n",
       "       [3.13522667e-01],\n",
       "       [3.25986832e-01],\n",
       "       [8.89291763e-02],\n",
       "       [3.76356840e-01],\n",
       "       [1.07651502e-01],\n",
       "       [1.65716976e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = tf.sigmoid(tf.matmul(X_test, w) + b)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6854, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict01 = tf.cast(predict > 0.5, dtype=\"float32\")\n",
    "predict01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측된 값과 실제 값 비교 및 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6865, shape=(), dtype=float32, numpy=0.74561405>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac01 = tf.reduce_mean(tf.cast(tf.equal(predict01, y_test), dtype=\"float32\"))\n",
    "ac01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
