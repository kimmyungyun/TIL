{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\library\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.data\n",
    "X = np.array(X, dtype=\"float32\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"target\"]\n",
    "y = np.array(y, dtype=\"float32\")\n",
    "y = y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 숫자 값 0~n까지인 값을 M*N 의 행렬로 바꿔준다\n",
    "## M은 데이터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot = enc.transform(y_train).toarray()\n",
    "y_train_onehot = np.array(y_train_onehot, dtype=\"float32\")\n",
    "y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.78778929e-01, -3.52269679e-01,  3.24554622e-01,\n",
       "         1.45326123e-01],\n",
       "       [-7.20670342e-01,  9.96849298e-01, -1.24226058e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 3.58834118e-01, -1.02682972e+00,  1.05200434e+00,\n",
       "         2.74505258e-01],\n",
       "       [ 7.18669116e-01,  3.22289824e-01,  4.36469883e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.08050478e+00, -1.27416700e-01, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-1.20945707e-01, -1.02682972e+00, -1.23106912e-01,\n",
       "        -2.42211118e-01],\n",
       "       [-1.68022943e+00,  3.22289824e-01, -1.35417593e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 1.18944481e-01, -1.27416700e-01,  2.68596739e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.44033980e+00,  3.22289824e-01, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 3.58834118e-01, -1.27416700e-01,  6.60300672e-01,\n",
       "         7.91221619e-01],\n",
       "       [-1.20044959e+00, -1.27416700e-01, -1.29821825e+00,\n",
       "        -1.40482306e+00],\n",
       "       [-1.20044959e+00,  9.74362940e-02, -1.18630278e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-1.00032648e-03, -5.77123225e-01,  7.72215903e-01,\n",
       "         1.56629646e+00],\n",
       "       [ 1.31839371e+00,  9.74362940e-02,  6.60300672e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.44033980e+00,  9.74362940e-02, -1.24226058e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-1.08050478e+00,  9.74362940e-02, -1.24226058e+00,\n",
       "        -1.40482306e+00],\n",
       "       [-7.20670342e-01,  2.34596825e+00, -1.24226058e+00,\n",
       "        -1.40482306e+00],\n",
       "       [ 8.38613927e-01, -1.27416700e-01,  9.96046662e-01,\n",
       "         7.91221619e-01],\n",
       "       [ 1.07850349e+00, -1.27416700e-01,  7.16258287e-01,\n",
       "         6.62042677e-01],\n",
       "       [-1.20044959e+00, -1.27416700e-01, -1.29821825e+00,\n",
       "        -1.14646482e+00],\n",
       "       [ 1.91811836e+00, -5.77123225e-01,  1.33179271e+00,\n",
       "         9.20400739e-01],\n",
       "       [ 1.31839371e+00,  9.74362940e-02,  9.40089047e-01,\n",
       "         1.17875886e+00],\n",
       "       [ 3.58834118e-01, -5.77123225e-01,  5.48385143e-01,\n",
       "         1.61471423e-02],\n",
       "       [-1.68022943e+00, -3.52269679e-01, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-3.60835344e-01, -1.47653568e+00, -1.11915255e-02,\n",
       "        -2.42211118e-01],\n",
       "       [-9.60559964e-01,  9.96849298e-01, -1.35417593e+00,\n",
       "        -1.14646482e+00],\n",
       "       [ 2.38889292e-01, -3.52269679e-01,  4.36469883e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.00032648e-03,  2.12111545e+00, -1.41013348e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-8.40615153e-01,  1.67140877e+00, -1.18630278e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-2.40890518e-01, -1.27416700e-01,  4.36469883e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.20945707e-01, -3.52269679e-01,  2.68596739e-01,\n",
       "         1.45326123e-01],\n",
       "       [-1.20945707e-01,  1.67140877e+00, -1.13034511e+00,\n",
       "        -1.14646482e+00],\n",
       "       [-9.60559964e-01,  7.71996319e-01, -1.18630278e+00,\n",
       "        -1.01728582e+00],\n",
       "       [-2.40890518e-01, -5.77123225e-01,  6.60300672e-01,\n",
       "         1.04957986e+00],\n",
       "       [-1.56028461e+00, -1.70138919e+00, -1.35417593e+00,\n",
       "        -1.14646482e+00],\n",
       "       [ 2.27795267e+00, -5.77123225e-01,  1.66753876e+00,\n",
       "         1.04957986e+00],\n",
       "       [-1.20945707e-01,  3.02052832e+00, -1.24226058e+00,\n",
       "        -1.01728582e+00],\n",
       "       [ 2.15800786e+00, -1.27416700e-01,  1.61158109e+00,\n",
       "         1.17875886e+00],\n",
       "       [ 1.19844890e+00,  3.22289824e-01,  1.21987748e+00,\n",
       "         1.43711710e+00],\n",
       "       [-1.00032648e-03, -8.01976204e-01,  7.72215903e-01,\n",
       "         9.20400739e-01],\n",
       "       [-1.32039499e+00,  3.22289824e-01, -1.35417593e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 8.38613927e-01, -5.77123225e-01,  4.92427528e-01,\n",
       "         4.03684378e-01],\n",
       "       [ 8.38613927e-01, -1.27416700e-01,  8.28173518e-01,\n",
       "         1.04957986e+00],\n",
       "       [-1.00032648e-03, -1.02682972e+00,  1.56681493e-01,\n",
       "         1.61471423e-02],\n",
       "       [ 2.38889292e-01, -8.01976204e-01,  7.72215903e-01,\n",
       "         5.32863498e-01],\n",
       "       [-8.40615153e-01,  9.96849298e-01, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-1.20044959e+00,  7.71996319e-01, -1.01842976e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-9.60559964e-01,  5.47142804e-01, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-1.32039499e+00,  3.22289824e-01, -1.18630278e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-2.40890518e-01, -3.52269679e-01, -6.71492890e-02,\n",
       "         1.45326123e-01],\n",
       "       [ 2.27795267e+00,  1.67140877e+00,  1.66753876e+00,\n",
       "         1.30793822e+00],\n",
       "       [-9.60559964e-01,  9.96849298e-01, -1.18630278e+00,\n",
       "        -7.58927524e-01],\n",
       "       [-2.40890518e-01, -1.27416700e-01,  2.12639108e-01,\n",
       "         1.45326123e-01],\n",
       "       [-8.40615153e-01,  7.71996319e-01, -1.24226058e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 5.98724306e-01, -5.77123225e-01,  7.72215903e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.08050478e+00,  9.74362940e-02, -1.24226058e+00,\n",
       "        -1.40482306e+00],\n",
       "       [-9.60559964e-01,  1.22170234e+00, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 1.07850349e+00,  5.47142804e-01,  1.10796189e+00,\n",
       "         1.69547546e+00],\n",
       "       [ 1.67822814e+00,  3.22289824e-01,  1.27583504e+00,\n",
       "         7.91221619e-01],\n",
       "       [-1.08050478e+00, -1.25168276e+00,  4.36469883e-01,\n",
       "         6.62042677e-01],\n",
       "       [ 2.51784301e+00,  1.67140877e+00,  1.49966586e+00,\n",
       "         1.04957986e+00],\n",
       "       [-1.00032648e-03, -8.01976204e-01,  1.00723863e-01,\n",
       "         1.61471423e-02],\n",
       "       [ 2.38889292e-01, -1.27416700e-01,  6.04343057e-01,\n",
       "         7.91221619e-01],\n",
       "       [ 7.18669116e-01,  9.74362940e-02,  9.96046662e-01,\n",
       "         7.91221619e-01],\n",
       "       [ 5.98724306e-01, -1.25168276e+00,  6.60300672e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.20945707e-01, -5.77123225e-01,  4.36469883e-01,\n",
       "         1.45326123e-01],\n",
       "       [-1.20945707e-01, -1.25168276e+00,  7.16258287e-01,\n",
       "         1.04957986e+00],\n",
       "       [-9.60559964e-01,  7.71996319e-01, -1.24226058e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-4.80780154e-01, -1.27416700e-01,  4.36469883e-01,\n",
       "         4.03684378e-01],\n",
       "       [-8.40615153e-01,  1.67140877e+00, -1.01842976e+00,\n",
       "        -1.01728582e+00],\n",
       "       [ 2.38889292e-01, -1.92624223e+00,  7.16258287e-01,\n",
       "         4.03684378e-01],\n",
       "       [-1.44033980e+00,  1.22170234e+00, -1.52204895e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-6.00724936e-01,  1.44655585e+00, -1.24226058e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-4.80780154e-01,  7.71996319e-01, -1.13034511e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 1.67822814e+00, -1.27416700e-01,  1.16391981e+00,\n",
       "         5.32863498e-01],\n",
       "       [ 4.78778929e-01, -5.77123225e-01,  6.04343057e-01,\n",
       "         7.91221619e-01],\n",
       "       [-1.00032648e-03, -8.01976204e-01,  7.72215903e-01,\n",
       "         9.20400739e-01],\n",
       "       [-4.80780154e-01,  1.89626241e+00, -1.35417593e+00,\n",
       "        -1.01728582e+00],\n",
       "       [-9.60559964e-01, -2.37594867e+00, -1.23106912e-01,\n",
       "        -2.42211118e-01],\n",
       "       [ 2.38889292e-01, -1.92624223e+00,  1.56681493e-01,\n",
       "        -2.42211118e-01],\n",
       "       [ 4.78778929e-01, -1.92624223e+00,  4.36469883e-01,\n",
       "         4.03684378e-01],\n",
       "       [ 1.07850349e+00,  9.74362940e-02,  1.05200434e+00,\n",
       "         1.56629646e+00],\n",
       "       [ 1.07850349e+00,  5.47142804e-01,  1.10796189e+00,\n",
       "         1.17875886e+00],\n",
       "       [ 1.07850349e+00, -1.27416700e-01,  8.28173518e-01,\n",
       "         1.43711710e+00],\n",
       "       [ 1.19844890e+00, -1.27416700e-01,  9.96046662e-01,\n",
       "         1.17875886e+00],\n",
       "       [-8.40615153e-01,  5.47142804e-01, -1.13034511e+00,\n",
       "        -8.88106644e-01],\n",
       "       [-1.08050478e+00, -1.47653568e+00, -2.35022306e-01,\n",
       "        -2.42211118e-01],\n",
       "       [-7.20670342e-01, -8.01976204e-01,  1.00723863e-01,\n",
       "         2.74505258e-01],\n",
       "       [-1.80017424e+00, -1.27416700e-01, -1.46609116e+00,\n",
       "        -1.40482306e+00],\n",
       "       [ 7.18669116e-01,  3.22289824e-01,  8.84131432e-01,\n",
       "         1.43711710e+00],\n",
       "       [-8.40615153e-01,  1.44655585e+00, -1.24226058e+00,\n",
       "        -1.01728582e+00],\n",
       "       [ 5.98724306e-01, -1.25168276e+00,  7.16258287e-01,\n",
       "         9.20400739e-01],\n",
       "       [ 1.18944481e-01, -1.27416700e-01,  7.72215903e-01,\n",
       "         7.91221619e-01],\n",
       "       [ 2.27795267e+00, -1.27416700e-01,  1.33179271e+00,\n",
       "         1.43711710e+00],\n",
       "       [-1.00032648e-03, -8.01976204e-01,  2.12639108e-01,\n",
       "        -2.42211118e-01],\n",
       "       [-4.80780154e-01,  1.89626241e+00, -1.13034511e+00,\n",
       "        -1.01728582e+00],\n",
       "       [-3.60835344e-01, -1.70138919e+00,  1.56681493e-01,\n",
       "         1.45326123e-01],\n",
       "       [ 9.58558738e-01, -3.52269679e-01,  4.92427528e-01,\n",
       "         1.45326123e-01],\n",
       "       [ 3.58834118e-01, -5.77123225e-01,  1.56681493e-01,\n",
       "         1.45326123e-01],\n",
       "       [ 1.18944481e-01,  3.22289824e-01,  6.04343057e-01,\n",
       "         7.91221619e-01],\n",
       "       [-3.60835344e-01,  9.96849298e-01, -1.35417593e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 1.67822814e+00,  1.22170234e+00,  1.33179271e+00,\n",
       "         1.69547546e+00],\n",
       "       [-3.60835344e-01, -1.47653568e+00,  4.47661020e-02,\n",
       "        -1.13031991e-01],\n",
       "       [-8.40615153e-01, -1.25168276e+00, -4.02895302e-01,\n",
       "        -1.13031991e-01],\n",
       "       [-3.60835344e-01,  2.57082129e+00, -1.29821825e+00,\n",
       "        -1.27564394e+00],\n",
       "       [ 8.38613927e-01, -1.27416700e-01,  1.16391981e+00,\n",
       "         1.30793822e+00],\n",
       "       [ 1.31839371e+00,  3.22289824e-01,  1.10796189e+00,\n",
       "         1.43711710e+00],\n",
       "       [ 1.31839371e+00,  9.74362940e-02,  7.72215903e-01,\n",
       "         1.43711710e+00],\n",
       "       [-3.60835344e-01, -1.02682972e+00,  3.80512267e-01,\n",
       "         1.61471423e-02],\n",
       "       [-4.80780154e-01,  7.71996319e-01, -1.24226058e+00,\n",
       "        -1.01728582e+00],\n",
       "       [ 3.58834118e-01, -3.52269679e-01,  5.48385143e-01,\n",
       "         2.74505258e-01],\n",
       "       [ 7.18669116e-01, -5.77123225e-01,  1.05200434e+00,\n",
       "         1.17875886e+00],\n",
       "       [-1.20044959e+00,  7.71996319e-01, -1.18630278e+00,\n",
       "        -1.27564394e+00],\n",
       "       [-2.40890518e-01, -8.01976204e-01,  2.68596739e-01,\n",
       "         1.45326123e-01],\n",
       "       [ 5.98724306e-01, -3.52269679e-01,  1.05200434e+00,\n",
       "         7.91221619e-01],\n",
       "       [ 1.79817355e+00, -3.52269679e-01,  1.44370818e+00,\n",
       "         7.91221619e-01],\n",
       "       [ 7.18669116e-01, -5.77123225e-01,  1.05200434e+00,\n",
       "         1.30793822e+00],\n",
       "       [-3.60835344e-01, -1.25168276e+00,  1.56681493e-01,\n",
       "         1.45326123e-01],\n",
       "       [ 5.98724306e-01,  5.47142804e-01,  1.27583504e+00,\n",
       "         1.69547546e+00],\n",
       "       [-1.68022943e+00, -1.27416700e-01, -1.35417593e+00,\n",
       "        -1.27564394e+00]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 16) dtype=float32, numpy=\n",
       "array([[-0.3662327 , -0.45429263, -0.41040814, -0.09292522, -0.00907153,\n",
       "        -0.04091614,  0.08846319,  0.10985076, -0.14018631,  0.12326115,\n",
       "         0.19905776,  0.49585032,  0.31554776, -0.5386052 , -0.4242782 ,\n",
       "        -0.5007749 ],\n",
       "       [-0.21238604, -0.11177444,  0.27591282, -0.36575422,  0.38676155,\n",
       "        -0.5299665 ,  0.06196296,  0.27245528, -0.37738365,  0.4821391 ,\n",
       "        -0.1195986 ,  0.09631956, -0.07164028,  0.45029354,  0.40812415,\n",
       "        -0.03217477],\n",
       "       [-0.30776513,  0.23881483,  0.5274787 ,  0.06357116,  0.1642102 ,\n",
       "         0.08247054, -0.14403015, -0.06752026, -0.14245918, -0.16151446,\n",
       "         0.15997761, -0.46035632, -0.45467746, -0.21557996,  0.13209265,\n",
       "         0.4575591 ],\n",
       "       [ 0.54003453, -0.1657741 , -0.1101822 ,  0.24372214, -0.0425145 ,\n",
       "        -0.07681349, -0.23531532, -0.06307375, -0.5172264 , -0.39203033,\n",
       "         0.3350358 , -0.3822047 ,  0.00186205, -0.25556627, -0.38236883,\n",
       "        -0.46468046]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "w0 = tf.Variable(initializer([4, 16]))\n",
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=\n",
       "array([ 0.22394344, -0.06055328, -0.18736672,  0.35407868,  0.36210015,\n",
       "        0.1366156 , -0.38991475, -0.11517808,  0.22367188,  0.02182353,\n",
       "       -0.3304779 ,  0.28974226, -0.00696188, -0.23978472,  0.03856134,\n",
       "       -0.35746676], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0 = tf.Variable(initializer([16]))\n",
    "b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36, shape=(120, 16), dtype=float32, numpy=\n",
       "array([[0.52548057, 0.45381525, 0.4192449 , ..., 0.31791067, 0.42042214,\n",
       "        0.3763851 ],\n",
       "       [0.49239865, 0.5175473 , 0.4672303 , ..., 0.7669315 , 0.74551576,\n",
       "        0.49892816],\n",
       "       [0.5337195 , 0.5242142 , 0.4766953 , ..., 0.23283449, 0.37783253,\n",
       "        0.4624889 ],\n",
       "       ...,\n",
       "       [0.6575045 , 0.56380135, 0.42116362, ..., 0.3362659 , 0.4123988 ,\n",
       "        0.4669642 ],\n",
       "       [0.6014291 , 0.40852085, 0.5508338 , ..., 0.26420298, 0.38415942,\n",
       "        0.2933889 ],\n",
       "       [0.6443365 , 0.64681673, 0.47335315, ..., 0.77307653, 0.732694  ,\n",
       "        0.613299  ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis0 = tf.sigmoid((tf.matmul(X_train, w0) + b0))\n",
    "hypothesis0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(16, 3) dtype=float32, numpy=\n",
       "array([[-0.04185474,  0.20794636, -0.34811562],\n",
       "       [-0.5600708 ,  0.47719127, -0.21609285],\n",
       "       [ 0.16222382,  0.56105334, -0.07433581],\n",
       "       [-0.20685819,  0.19006222, -0.33057138],\n",
       "       [ 0.37814784, -0.31504193, -0.4713824 ],\n",
       "       [ 0.43900675,  0.15807414, -0.4251148 ],\n",
       "       [-0.52148706,  0.05162197,  0.47616023],\n",
       "       [ 0.03973758,  0.16853452,  0.31600595],\n",
       "       [-0.40592515,  0.27956426,  0.21270972],\n",
       "       [-0.2199831 , -0.28711575,  0.40673625],\n",
       "       [-0.22993362,  0.461253  , -0.09069741],\n",
       "       [ 0.42528105,  0.52131194, -0.47767287],\n",
       "       [ 0.29374236,  0.4998204 , -0.38646796],\n",
       "       [-0.03850108,  0.2704535 , -0.00377136],\n",
       "       [ 0.0490095 , -0.19507882, -0.21777028],\n",
       "       [ 0.5075168 ,  0.19338238, -0.14769009]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(initializer([16, 3]))\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([ 0.518245  , -0.59863377, -0.13884902], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = tf.Variable(initializer([3]))\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=72, shape=(120, 3), dtype=float32, numpy=\n",
       "array([[0.3915185 , 0.5456829 , 0.06279858],\n",
       "       [0.3794137 , 0.5476736 , 0.07291271],\n",
       "       [0.3746634 , 0.56795734, 0.05737931],\n",
       "       [0.4190197 , 0.51222014, 0.06876019],\n",
       "       [0.34368432, 0.5953344 , 0.06098131],\n",
       "       [0.35317436, 0.59061134, 0.05621432],\n",
       "       [0.34118828, 0.5965514 , 0.0622603 ],\n",
       "       [0.39037025, 0.5467372 , 0.06289257],\n",
       "       [0.34660533, 0.5901584 , 0.06323624],\n",
       "       [0.4007129 , 0.5362035 , 0.06308361],\n",
       "       [0.34113672, 0.5982518 , 0.06061144],\n",
       "       [0.3474022 , 0.59029657, 0.06230116],\n",
       "       [0.38297787, 0.5590859 , 0.05793626],\n",
       "       [0.42757934, 0.50371134, 0.06870937],\n",
       "       [0.3418699 , 0.59686893, 0.06126116],\n",
       "       [0.34933254, 0.58754647, 0.06312104],\n",
       "       [0.41227466, 0.50339615, 0.08432911],\n",
       "       [0.41426373, 0.5211285 , 0.06460781],\n",
       "       [0.41699538, 0.51759994, 0.06540465],\n",
       "       [0.34123462, 0.59854746, 0.06021785],\n",
       "       [0.42618358, 0.51058537, 0.06323105],\n",
       "       [0.4318819 , 0.5013745 , 0.06674364],\n",
       "       [0.38362613, 0.55549675, 0.06087714],\n",
       "       [0.3264934 , 0.61693925, 0.05656733],\n",
       "       [0.33669195, 0.61073816, 0.05256995],\n",
       "       [0.37353522, 0.5550481 , 0.07141662],\n",
       "       [0.38794488, 0.55050594, 0.0615492 ],\n",
       "       [0.42305925, 0.48968604, 0.08725472],\n",
       "       [0.39404246, 0.52790964, 0.07804789],\n",
       "       [0.38349992, 0.55486983, 0.06163029],\n",
       "       [0.37725303, 0.562048  , 0.06069893],\n",
       "       [0.4123922 , 0.5056578 , 0.08195005],\n",
       "       [0.36993402, 0.5610507 , 0.06901526],\n",
       "       [0.37461248, 0.56775534, 0.05763218],\n",
       "       [0.2996492 , 0.6529313 , 0.04741959],\n",
       "       [0.43599522, 0.5002846 , 0.06372016],\n",
       "       [0.44722039, 0.46168888, 0.09109071],\n",
       "       [0.44672105, 0.48637146, 0.06690756],\n",
       "       [0.4374363 , 0.49442545, 0.06813826],\n",
       "       [0.3735918 , 0.56937367, 0.05703456],\n",
       "       [0.3486476 , 0.58755827, 0.06379423],\n",
       "       [0.39500538, 0.54337424, 0.06162042],\n",
       "       [0.41375437, 0.52222353, 0.06402213],\n",
       "       [0.35869238, 0.5849387 , 0.05636891],\n",
       "       [0.37751478, 0.56432307, 0.05816207],\n",
       "       [0.37615183, 0.55156106, 0.07228712],\n",
       "       [0.36494756, 0.56679887, 0.06825355],\n",
       "       [0.36237633, 0.5700526 , 0.06757101],\n",
       "       [0.35011974, 0.58614814, 0.06373214],\n",
       "       [0.37134624, 0.56839615, 0.06025761],\n",
       "       [0.49029717, 0.42547855, 0.08422424],\n",
       "       [0.37706575, 0.55239725, 0.07053705],\n",
       "       [0.38047576, 0.5575032 , 0.06202104],\n",
       "       [0.3710915 , 0.55870444, 0.07020406],\n",
       "       [0.39207858, 0.5468891 , 0.06103224],\n",
       "       [0.34933254, 0.58754647, 0.06312104],\n",
       "       [0.37900352, 0.54737705, 0.07361939],\n",
       "       [0.43995082, 0.49087512, 0.06917413],\n",
       "       [0.44710332, 0.48209342, 0.0708032 ],\n",
       "       [0.33412442, 0.6145735 , 0.05130211],\n",
       "       [0.4941694 , 0.4208252 , 0.08500531],\n",
       "       [0.36481366, 0.5772589 , 0.05792744],\n",
       "       [0.3974813 , 0.53982025, 0.06269849],\n",
       "       [0.41820723, 0.51568395, 0.06610878],\n",
       "       [0.36978588, 0.5739077 , 0.05630647],\n",
       "       [0.37219766, 0.5687781 , 0.05902425],\n",
       "       [0.35742348, 0.5885597 , 0.05401682],\n",
       "       [0.3683685 , 0.56208277, 0.06954876],\n",
       "       [0.37796074, 0.5612947 , 0.06074465],\n",
       "       [0.39741635, 0.52516747, 0.07741612],\n",
       "       [0.34171093, 0.60655874, 0.05173031],\n",
       "       [0.36631262, 0.5623477 , 0.0713397 ],\n",
       "       [0.39349028, 0.5289344 , 0.07757529],\n",
       "       [0.38040787, 0.547417  , 0.07217507],\n",
       "       [0.4326347 , 0.4999454 , 0.06741987],\n",
       "       [0.38940158, 0.5505779 , 0.0600205 ],\n",
       "       [0.3735918 , 0.56937367, 0.05703456],\n",
       "       [0.40893272, 0.5095488 , 0.08151851],\n",
       "       [0.30227765, 0.6512234 , 0.04649892],\n",
       "       [0.3370213 , 0.6112759 , 0.05170275],\n",
       "       [0.3443873 , 0.603653  , 0.05195972],\n",
       "       [0.4280332 , 0.5064235 , 0.06554327],\n",
       "       [0.43998724, 0.48969164, 0.07032117],\n",
       "       [0.4202346 , 0.5160259 , 0.0637395 ],\n",
       "       [0.4232296 , 0.51208293, 0.06468743],\n",
       "       [0.3679454 , 0.56473476, 0.06731984],\n",
       "       [0.32088414, 0.6287298 , 0.05038609],\n",
       "       [0.34982187, 0.59484345, 0.05533466],\n",
       "       [0.3277263 , 0.6141591 , 0.05811451],\n",
       "       [0.4248993 , 0.50840104, 0.06669962],\n",
       "       [0.3896283 , 0.5347304 , 0.07564142],\n",
       "       [0.37229332, 0.571945  , 0.05576167],\n",
       "       [0.39609495, 0.54159975, 0.06230534],\n",
       "       [0.44786534, 0.48628   , 0.06585468],\n",
       "       [0.36529875, 0.5763969 , 0.05830429],\n",
       "       [0.41082117, 0.5079442 , 0.08123467],\n",
       "       [0.33210942, 0.6166787 , 0.05121186],\n",
       "       [0.40372452, 0.53186744, 0.06440803],\n",
       "       [0.380455  , 0.5589501 , 0.06059493],\n",
       "       [0.40765634, 0.5264066 , 0.06593707],\n",
       "       [0.3866884 , 0.5379551 , 0.07535645],\n",
       "       [0.468481  , 0.4544668 , 0.07705217],\n",
       "       [0.33721235, 0.61027426, 0.05251347],\n",
       "       [0.32983133, 0.61788523, 0.05228339],\n",
       "       [0.42720708, 0.48505157, 0.08774141],\n",
       "       [0.41669014, 0.5195648 , 0.06374504],\n",
       "       [0.43937764, 0.4923584 , 0.06826402],\n",
       "       [0.43139464, 0.50273377, 0.06587156],\n",
       "       [0.35298696, 0.59173715, 0.05527587],\n",
       "       [0.3804531 , 0.54783833, 0.07170857],\n",
       "       [0.39124355, 0.54657817, 0.06217827],\n",
       "       [0.39958096, 0.5401563 , 0.06026269],\n",
       "       [0.36348066, 0.5682153 , 0.06830402],\n",
       "       [0.36138692, 0.58159477, 0.0570182 ],\n",
       "       [0.40253842, 0.5353119 , 0.06214975],\n",
       "       [0.43103015, 0.50371283, 0.06525701],\n",
       "       [0.40003932, 0.53987306, 0.06008761],\n",
       "       [0.34483147, 0.60143507, 0.05373346],\n",
       "       [0.43023515, 0.50181466, 0.0679502 ],\n",
       "       [0.33099553, 0.6105966 , 0.05840794]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis1 = tf.nn.softmax((tf.matmul(hypothesis0, w1) + b1))\n",
    "hypothesis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=75, shape=(120,), dtype=int64, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.argmax(hypothesis1, 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis0 = tf.sigmoid((tf.matmul(X_train, w0) + b0))\n",
    "hypothesis1 = tf.nn.softmax((tf.matmul(hypothesis0, w1) + b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor로부터 shape 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis1.get_shape().as_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hypothesis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "epoch : 0, cost : 1.4794293642044067\n",
      "==================================================\n",
      "epoch : 100, cost : 0.2640448808670044\n",
      "==================================================\n",
      "epoch : 200, cost : 0.14154182374477386\n",
      "==================================================\n",
      "epoch : 300, cost : 0.08798494935035706\n",
      "==================================================\n",
      "epoch : 400, cost : 0.06918991357088089\n",
      "==================================================\n",
      "epoch : 500, cost : 0.0604599304497242\n",
      "==================================================\n",
      "epoch : 600, cost : 0.05572155863046646\n",
      "==================================================\n",
      "epoch : 700, cost : 0.052924059331417084\n",
      "==================================================\n",
      "epoch : 800, cost : 0.05112423747777939\n",
      "==================================================\n",
      "epoch : 900, cost : 0.0498068667948246\n",
      "==================================================\n",
      "epoch : 1000, cost : 0.048700880259275436\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis0 = tf.sigmoid((tf.matmul(X_train, w0) + b0))\n",
    "        hypothesis1 = tf.nn.softmax((tf.matmul(hypothesis0, w1) + b1))\n",
    "        \n",
    "        cost = -tf.reduce_sum(y_train_onehot * tf.log(hypothesis1)) /  hypothesis1.get_shape().as_list()[0]\n",
    "        \n",
    "        grads = tape.gradient(cost, [w0, w1, b0, b1])\n",
    "        \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [w0, w1, b0, b1]))\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"epoch : {epoch}, cost : {cost.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 시킬 때 데이터 표준화를 했으면 테스트할 때도 해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47877893,  0.7719963 ,  0.94008905,  1.4371171 ],\n",
       "       [-0.12094571, -0.5771232 ,  0.21263911,  0.14532612],\n",
       "       [ 0.95855874, -0.1274167 ,  0.38051227,  0.27450526],\n",
       "       [ 1.0785035 ,  0.09743629,  0.38051227,  0.27450526],\n",
       "       [ 0.35883412, -0.1274167 ,  0.49242753,  0.27450526],\n",
       "       [ 1.0785035 ,  0.09743629,  0.54838514,  0.40368438],\n",
       "       [-0.84061515,  0.9968493 , -1.2982183 , -1.1464648 ],\n",
       "       [ 0.5987243 , -0.8019762 ,  0.6603007 ,  0.7912216 ],\n",
       "       [-1.4403398 ,  0.7719963 , -1.2982183 , -1.1464648 ],\n",
       "       [-0.48078015,  1.4465559 , -1.2422606 , -1.275644  ],\n",
       "       [-0.96055996, -0.1274167 , -1.1863028 , -1.275644  ],\n",
       "       [ 0.5987243 ,  0.5471428 ,  0.54838514,  0.5328635 ],\n",
       "       [-0.24089052, -1.2516828 ,  0.10072386, -0.11303199],\n",
       "       [-0.96055996, -1.7013892 , -0.2350223 , -0.24221112],\n",
       "       [-1.0805048 ,  0.09743629, -1.2422606 , -1.4048231 ],\n",
       "       [ 0.23888929,  0.7719963 ,  0.43646988,  0.5328635 ],\n",
       "       [ 0.5987243 , -1.7013892 ,  0.38051227,  0.14532612],\n",
       "       [ 1.5582833 , -0.1274167 ,  1.2198775 ,  1.1787589 ],\n",
       "       [ 1.1984489 , -0.5771232 ,  0.60434306,  0.27450526],\n",
       "       [-0.96055996,  0.32228982, -1.4101335 , -1.275644  ],\n",
       "       [-0.84061515,  1.6714088 , -1.2422606 , -1.1464648 ],\n",
       "       [ 1.4383385 ,  0.32228982,  0.54838514,  0.27450526],\n",
       "       [ 0.8386139 ,  0.32228982,  0.7722159 ,  1.0495799 ],\n",
       "       [-0.72067034,  0.7719963 , -1.2982183 , -1.275644  ],\n",
       "       [ 0.5987243 ,  0.7719963 ,  1.0520043 ,  1.5662965 ],\n",
       "       [ 2.2779527 , -1.0268297 ,  1.7794542 ,  1.4371171 ],\n",
       "       [ 0.7186691 , -0.35226968,  0.32455462,  0.14532612],\n",
       "       [-0.12094571, -0.1274167 ,  0.26859674,  0.01614714],\n",
       "       [ 0.7186691 , -0.8019762 ,  0.88413143,  0.92040074],\n",
       "       [ 1.0785035 , -1.2516828 ,  1.1639198 ,  0.7912216 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84280, shape=(30, 3), dtype=float32, numpy=\n",
       "array([[6.76876425e-07, 3.45045235e-03, 9.96548951e-01],\n",
       "       [7.17504707e-04, 9.99118030e-01, 1.64447294e-04],\n",
       "       [2.07575722e-04, 9.99553263e-01, 2.39115136e-04],\n",
       "       [3.07603856e-04, 9.99583066e-01, 1.09375884e-04],\n",
       "       [4.02039004e-04, 9.97990847e-01, 1.60712027e-03],\n",
       "       [1.65446196e-04, 9.97886837e-01, 1.94764603e-03],\n",
       "       [9.99426007e-01, 5.74060774e-04, 2.35565040e-12],\n",
       "       [4.69250017e-06, 9.46527347e-02, 9.05342519e-01],\n",
       "       [9.99464691e-01, 5.35367057e-04, 2.21901208e-12],\n",
       "       [9.99480903e-01, 5.19155932e-04, 2.02800277e-12],\n",
       "       [9.98711467e-01, 1.28853833e-03, 6.83906404e-12],\n",
       "       [8.73978424e-04, 9.95962560e-01, 3.16355820e-03],\n",
       "       [3.33911419e-04, 9.99592006e-01, 7.41390540e-05],\n",
       "       [1.29511510e-03, 9.98688519e-01, 1.63923487e-05],\n",
       "       [9.99200523e-01, 7.99470872e-04, 3.60391079e-12],\n",
       "       [6.09828671e-03, 9.93261039e-01, 6.40753424e-04],\n",
       "       [3.88234985e-05, 9.97542381e-01, 2.41884799e-03],\n",
       "       [2.75899890e-08, 7.01247831e-04, 9.99298692e-01],\n",
       "       [5.68210380e-05, 9.95013654e-01, 4.92948294e-03],\n",
       "       [9.99298692e-01, 7.01248471e-04, 3.00073681e-12],\n",
       "       [9.99526858e-01, 4.73160122e-04, 1.85628184e-12],\n",
       "       [2.31429687e-04, 9.99563754e-01, 2.04887168e-04],\n",
       "       [5.04268382e-06, 4.44053821e-02, 9.55589592e-01],\n",
       "       [9.99371111e-01, 6.28944661e-04, 2.60038605e-12],\n",
       "       [1.44841721e-07, 1.16738991e-03, 9.98832524e-01],\n",
       "       [3.02993364e-09, 1.10598201e-04, 9.99889374e-01],\n",
       "       [2.53032107e-04, 9.99621153e-01, 1.25822437e-04],\n",
       "       [5.35077974e-03, 9.94625866e-01, 2.33912779e-05],\n",
       "       [2.08629089e-07, 4.67738882e-03, 9.95322406e-01],\n",
       "       [6.23877838e-08, 1.73334463e-03, 9.98266578e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis0 = tf.sigmoid((tf.matmul(X_test, w0) + b0))\n",
    "hypothesis1 = tf.nn.softmax((tf.matmul(hypothesis0, w1) + b1))\n",
    "hypothesis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84283, shape=(30,), dtype=int64, numpy=\n",
       "array([2, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 1,\n",
       "       2, 0, 2, 2, 1, 1, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.argmax(hypothesis1, 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84291, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.cast(tf.equal(y_test.reshape(-1), pred), dtype=\"float32\"))/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
