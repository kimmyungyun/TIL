{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\library\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n=============================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드\n",
    "## y의 경우 reshape를 해주어야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[\"data\"]\n",
    "X = np.array(X, dtype=\"float32\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"target\"]\n",
    "y = np.array(y, dtype=\"float32\")\n",
    "y = y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2419883 , -0.8430437 , -1.2516576 , ..., -0.9673552 ,\n",
       "        -0.07385019, -0.10366599],\n",
       "       [-0.3853996 ,  0.4907649 , -0.40848032, ..., -1.0274909 ,\n",
       "        -1.1345507 , -0.8588474 ],\n",
       "       [ 1.3769999 , -0.09016222,  1.2918456 , ...,  0.12645894,\n",
       "        -0.07385019, -1.0499591 ],\n",
       "       ...,\n",
       "       [-0.78993124,  0.45590937, -0.8004836 , ..., -0.48144054,\n",
       "        -0.09307724,  0.27682063],\n",
       "       [-1.2586788 ,  0.00975732, -1.2701484 , ..., -1.1719098 ,\n",
       "        -0.53690517, -0.25134325],\n",
       "       [ 0.3501121 ,  0.80446565,  0.33854535, ...,  0.52840173,\n",
       "        -0.530496  , -0.88375   ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight 값을 초기화 하기 위한 xavier_initializer() 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xavier 방식을 통한 weight 값들 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30, 30) dtype=float32, numpy=\n",
       "array([[-0.07945381, -0.25427008, -0.0158101 ,  0.0291903 , -0.1458343 ,\n",
       "         0.19697866,  0.16021061, -0.28989816, -0.23500858,  0.28895512,\n",
       "         0.27960065,  0.20342633,  0.2312558 ,  0.13165236, -0.01881707,\n",
       "         0.31472853,  0.17049557,  0.26115337,  0.06981117, -0.03569821,\n",
       "         0.18034124,  0.1433278 , -0.27631155,  0.05771139,  0.16935754,\n",
       "         0.270739  , -0.27178562, -0.02006114,  0.3083531 ,  0.11005324],\n",
       "       [ 0.17304051, -0.10694396,  0.28690413,  0.20988509,  0.08334854,\n",
       "        -0.14945588, -0.02948704,  0.10519367, -0.30984908, -0.31571922,\n",
       "        -0.13212341,  0.09706938, -0.24613696,  0.23456004,  0.18442228,\n",
       "        -0.2582445 ,  0.31267962,  0.00766951, -0.01651171, -0.00532836,\n",
       "        -0.04980031, -0.134041  , -0.02061129,  0.28679487, -0.10946561,\n",
       "         0.01712331,  0.00871417, -0.08643807, -0.27034074,  0.25334695],\n",
       "       [-0.21862331, -0.02688813, -0.314433  ,  0.0880188 ,  0.10906172,\n",
       "        -0.27227792, -0.00665501, -0.29233682,  0.0540359 , -0.21348056,\n",
       "         0.10583884,  0.0792464 ,  0.00059786,  0.24440888,  0.15090126,\n",
       "         0.08814961, -0.16239825,  0.2609472 , -0.19148254, -0.07796372,\n",
       "        -0.26273108,  0.07599819,  0.2550936 , -0.20352781, -0.19673377,\n",
       "        -0.21839976,  0.06329632, -0.26036286,  0.28368983, -0.14824706],\n",
       "       [-0.10512741, -0.13018426, -0.2704543 , -0.06566355,  0.26624295,\n",
       "         0.2531267 ,  0.05533865, -0.09425656,  0.12178177,  0.05464607,\n",
       "        -0.07089624, -0.15659529,  0.27864173, -0.00358126, -0.08220127,\n",
       "        -0.2627451 ,  0.19035593,  0.05310214, -0.25152224, -0.16335222,\n",
       "        -0.31337264, -0.24771762, -0.14579093,  0.24634615,  0.07420871,\n",
       "         0.17279863,  0.04436284,  0.09152442,  0.11592707, -0.12906873],\n",
       "       [ 0.27451232,  0.09542397, -0.19923785,  0.22609583, -0.2170906 ,\n",
       "        -0.10210958,  0.01563254,  0.123018  ,  0.05936599, -0.17841426,\n",
       "        -0.0682759 , -0.23371631, -0.03751597, -0.0840127 ,  0.28878382,\n",
       "         0.1204116 , -0.14250562,  0.3152236 , -0.2341089 ,  0.1267823 ,\n",
       "        -0.21248868, -0.2918448 ,  0.04773712,  0.13675082,  0.26255348,\n",
       "         0.23703906, -0.09641005, -0.20333043,  0.3113334 ,  0.20684537],\n",
       "       [-0.16045624,  0.28012148, -0.21828833,  0.03320068,  0.23965147,\n",
       "        -0.22291952,  0.04054826,  0.04283249,  0.08720505, -0.2784927 ,\n",
       "        -0.06225798, -0.21405974,  0.08583641, -0.00694174,  0.27063206,\n",
       "         0.08913222,  0.08089256,  0.22439852,  0.07750201, -0.03522986,\n",
       "        -0.06578213,  0.23051956, -0.17165174,  0.12831667,  0.2362065 ,\n",
       "         0.2970871 ,  0.16999057, -0.02936897,  0.03109244, -0.14540568],\n",
       "       [-0.09313589, -0.05554551,  0.03503692, -0.21514687, -0.10085064,\n",
       "         0.2947969 , -0.0342274 , -0.2569149 , -0.1164289 , -0.08180274,\n",
       "         0.17472345, -0.26473984,  0.2772229 , -0.26737073, -0.30600584,\n",
       "         0.14982516, -0.22261244, -0.28798947, -0.04398814,  0.22000667,\n",
       "        -0.19268523,  0.13543436,  0.0979968 ,  0.01384065, -0.06671432,\n",
       "        -0.1318746 ,  0.2830622 ,  0.26071766, -0.31515187,  0.27270165],\n",
       "       [ 0.14603853,  0.17928731, -0.08423074,  0.03331739,  0.09067962,\n",
       "         0.27028486, -0.17081176, -0.01660159, -0.27739397,  0.18533674,\n",
       "         0.20021942, -0.2975882 , -0.09025696, -0.0102863 ,  0.15957737,\n",
       "        -0.25581396,  0.30416825,  0.25972667, -0.00627923,  0.27344272,\n",
       "         0.17565376,  0.08114538, -0.1859871 ,  0.07943767,  0.07310936,\n",
       "        -0.27139634, -0.11296421,  0.06372628, -0.14034957, -0.07648432],\n",
       "       [-0.31153905, -0.24898568,  0.13236934, -0.21241713,  0.07371977,\n",
       "         0.04283008,  0.23364219,  0.20821533,  0.24134406, -0.10352044,\n",
       "         0.11402443, -0.18939479,  0.18679729,  0.28471598, -0.2917917 ,\n",
       "        -0.07068112, -0.17112118,  0.10345522,  0.1833033 ,  0.24442282,\n",
       "         0.08856261, -0.2507187 , -0.11855902, -0.24220733, -0.03730002,\n",
       "         0.15934658, -0.11994326, -0.30214158, -0.24666096, -0.1936031 ],\n",
       "       [-0.03679028,  0.04790828,  0.17173994, -0.14626329, -0.29444015,\n",
       "        -0.15911534, -0.03382766, -0.08496071,  0.10587412,  0.2649009 ,\n",
       "         0.01148742,  0.24639699, -0.22920576, -0.23309553, -0.06471041,\n",
       "         0.08746862, -0.04755768, -0.2547278 ,  0.22425196, -0.11140324,\n",
       "        -0.26335755,  0.04704267,  0.04516587, -0.21802634, -0.14612012,\n",
       "        -0.0338833 , -0.14008605,  0.00837633,  0.27091184, -0.06673875],\n",
       "       [-0.29121578,  0.29816338,  0.02761167,  0.19465634, -0.27381137,\n",
       "         0.24224511, -0.2267819 , -0.05359113, -0.09247212, -0.20155293,\n",
       "        -0.13706884, -0.20851523,  0.12390992,  0.07730907,  0.06893432,\n",
       "        -0.13122387, -0.21073696, -0.314445  ,  0.15506026,  0.12978122,\n",
       "        -0.09391148, -0.03814521, -0.23822024, -0.10824211,  0.03854072,\n",
       "         0.08154374, -0.29651546,  0.16368434, -0.21584924,  0.15959427],\n",
       "       [-0.2747608 ,  0.14621127, -0.01364791,  0.22779611, -0.10085352,\n",
       "         0.13503876,  0.1698964 ,  0.00764674,  0.1852245 ,  0.04251999,\n",
       "        -0.08053935,  0.22522178, -0.12006104,  0.23057643, -0.25924823,\n",
       "         0.08910236,  0.06287462, -0.21678776,  0.27113155,  0.16757199,\n",
       "         0.24504057, -0.1473918 ,  0.17175758, -0.27329063,  0.306798  ,\n",
       "        -0.00086048,  0.03031841, -0.20498127,  0.22977427, -0.21647161],\n",
       "       [-0.20642605,  0.25160924,  0.15545645,  0.00607356, -0.2620024 ,\n",
       "        -0.05059353,  0.01071456, -0.04914007,  0.08568314,  0.12317452,\n",
       "         0.0991309 ,  0.07428694,  0.04408637, -0.2842399 , -0.2976265 ,\n",
       "        -0.13725974,  0.2574338 ,  0.18988684, -0.30113325, -0.04688999,\n",
       "         0.20461455,  0.16810337, -0.2854395 ,  0.30285588, -0.05666476,\n",
       "         0.24651542,  0.1431767 ,  0.24168286,  0.04473394, -0.25025126],\n",
       "       [ 0.06580046, -0.06633101,  0.03354508,  0.28703353, -0.07829373,\n",
       "         0.15598339, -0.23792869,  0.00422859, -0.23720565,  0.20155063,\n",
       "        -0.04727203, -0.02707443, -0.06233042, -0.11544824,  0.26812324,\n",
       "        -0.11843778, -0.13123195, -0.2277857 ,  0.14437932, -0.0071235 ,\n",
       "         0.15054035,  0.12403095, -0.16060838, -0.2165654 , -0.31362206,\n",
       "        -0.13034041,  0.2904466 , -0.02104744, -0.30836186,  0.10388979],\n",
       "       [-0.05687428,  0.16839045, -0.27009344, -0.18151161, -0.24344607,\n",
       "         0.01036915, -0.2805944 , -0.08338535, -0.1779817 ,  0.12386867,\n",
       "        -0.10104637,  0.16982031, -0.2152546 ,  0.11008483,  0.09567964,\n",
       "        -0.27471334,  0.04225156, -0.25278163,  0.12530172, -0.20546107,\n",
       "         0.27324846, -0.2527888 ,  0.3016108 , -0.14619981,  0.10011435,\n",
       "        -0.23720852,  0.17978778, -0.14710243, -0.15876928,  0.01869935],\n",
       "       [-0.17542975, -0.1600329 ,  0.01950058, -0.18368576,  0.23388186,\n",
       "         0.21703783, -0.2694336 ,  0.02391163,  0.10782036,  0.13805711,\n",
       "        -0.30346286,  0.29087767, -0.09043217,  0.13853309, -0.04107407,\n",
       "        -0.30702707,  0.269568  , -0.15059727, -0.29676843, -0.14801198,\n",
       "         0.09118354,  0.09513053,  0.05060703,  0.0929046 , -0.08465077,\n",
       "        -0.02247241,  0.16437584, -0.11999333,  0.23462   , -0.12222502],\n",
       "       [-0.15101933,  0.10330287,  0.02826127,  0.15950319, -0.26013097,\n",
       "        -0.2827375 , -0.15083273,  0.0468376 , -0.21118298,  0.2681261 ,\n",
       "         0.11719409,  0.25927606, -0.2447292 ,  0.03615659,  0.00429809,\n",
       "         0.10782939, -0.02748591,  0.09828979, -0.07345241, -0.00493684,\n",
       "         0.19344172,  0.05809748, -0.27005476, -0.00350231,  0.2043483 ,\n",
       "         0.21095195, -0.0656113 , -0.00758824,  0.10240409,  0.23836997],\n",
       "       [-0.27513772, -0.21991828,  0.02744415,  0.15722346, -0.12830204,\n",
       "         0.04485238, -0.239955  , -0.15274903, -0.18591751,  0.1451804 ,\n",
       "         0.00082865, -0.25242427, -0.16309272,  0.10288244, -0.2602709 ,\n",
       "        -0.18998204,  0.04481679, -0.13721646,  0.06976885, -0.08036444,\n",
       "         0.08940545, -0.11452775, -0.2777652 , -0.14891416, -0.1466435 ,\n",
       "        -0.02470598,  0.11647445, -0.18533969, -0.08044383, -0.08084244],\n",
       "       [ 0.13139904, -0.19562855,  0.28292635,  0.24530223,  0.28969333,\n",
       "        -0.05232209, -0.24780816,  0.23949525,  0.26936957, -0.09035279,\n",
       "         0.02744415, -0.19225836,  0.09015548, -0.3065532 , -0.04581615,\n",
       "         0.01199672,  0.15664014, -0.0682673 ,  0.13222286,  0.21888152,\n",
       "         0.20900735,  0.24382922, -0.2652663 ,  0.26330397, -0.3057228 ,\n",
       "         0.04914391, -0.08814229,  0.2993326 ,  0.2784126 , -0.29402918],\n",
       "       [-0.00932217,  0.01453954, -0.11327432,  0.23619077,  0.13852397,\n",
       "        -0.14238891, -0.06928542,  0.16175386,  0.09297553,  0.12976146,\n",
       "        -0.1696264 , -0.26743224,  0.286608  ,  0.13221148, -0.18142709,\n",
       "        -0.08360957, -0.22180533,  0.04868174, -0.03764662, -0.05986947,\n",
       "        -0.08587842, -0.31395137,  0.02759013,  0.29582396,  0.17547807,\n",
       "         0.01433802,  0.25361738,  0.03920496,  0.01372084, -0.26190898],\n",
       "       [-0.06045446, -0.16705538, -0.29061526,  0.25045505,  0.29948452,\n",
       "        -0.01156431, -0.14408559,  0.0544036 , -0.03988683, -0.09262721,\n",
       "        -0.00337359,  0.20928428,  0.20254722, -0.06545711,  0.25675425,\n",
       "        -0.10176428, -0.12604314,  0.05577111, -0.01213062,  0.03088117,\n",
       "        -0.02622291, -0.24701765,  0.12700757,  0.09877482,  0.25114617,\n",
       "        -0.29155874, -0.02153745,  0.23746184, -0.1789736 ,  0.14890927],\n",
       "       [ 0.20885232, -0.09760039, -0.26494256,  0.03682768,  0.24590096,\n",
       "        -0.25462008,  0.1359187 ,  0.28094116,  0.0160616 , -0.21027005,\n",
       "         0.25476936,  0.07280868, -0.20054603,  0.16250628, -0.2554761 ,\n",
       "        -0.17625178, -0.1961334 ,  0.17605862,  0.11112121, -0.1470633 ,\n",
       "         0.08695218, -0.07810169,  0.06105793,  0.09075162, -0.2540859 ,\n",
       "         0.09879577, -0.0402672 ,  0.19555429, -0.2773627 ,  0.02695122],\n",
       "       [ 0.26532826,  0.05031705, -0.05610842,  0.16984114, -0.13235608,\n",
       "        -0.19488654,  0.05276075, -0.27542204, -0.00040835,  0.2043747 ,\n",
       "        -0.02268767, -0.17678037, -0.23310149, -0.19448921,  0.21559396,\n",
       "         0.00428301,  0.31223187,  0.22447279,  0.02146506, -0.09450416,\n",
       "        -0.16030107,  0.0614922 ,  0.17175871,  0.01314896,  0.1747644 ,\n",
       "        -0.220388  , -0.01270965, -0.12773801,  0.0556047 ,  0.2794796 ],\n",
       "       [ 0.10342795,  0.28447893,  0.11409339,  0.11472288,  0.26208857,\n",
       "         0.13631451,  0.02143604, -0.10729659,  0.26918504, -0.06250301,\n",
       "         0.1290749 , -0.30761153,  0.20498517, -0.29836127,  0.02960646,\n",
       "        -0.11533003,  0.06360278,  0.12495813,  0.02086341,  0.02807745,\n",
       "         0.00778261,  0.18310401,  0.19242874, -0.26791358, -0.18844074,\n",
       "        -0.06710705, -0.12558323, -0.06242549, -0.18944198,  0.13581458],\n",
       "       [ 0.0923993 , -0.21245542, -0.16005288,  0.03782094, -0.25332975,\n",
       "         0.27373162, -0.05443969,  0.18815199, -0.09350918,  0.16464403,\n",
       "         0.3077545 ,  0.22274885,  0.04783666,  0.09803987, -0.23798554,\n",
       "         0.10754809,  0.2800344 ,  0.30058488,  0.15869132, -0.1837791 ,\n",
       "        -0.03151539, -0.1467829 , -0.00363371, -0.21057448,  0.2457774 ,\n",
       "        -0.01282227,  0.04788414, -0.14704762,  0.04038149, -0.04239497],\n",
       "       [ 0.16299334, -0.14397559, -0.25097406, -0.08457477,  0.15075567,\n",
       "         0.01679406,  0.17756772, -0.02260074, -0.15237424, -0.23842749,\n",
       "        -0.24159709, -0.27531913,  0.00392443, -0.07204758, -0.05508712,\n",
       "        -0.0163739 ,  0.14777774, -0.11634627,  0.05773544,  0.03418088,\n",
       "         0.10817507,  0.2596313 , -0.15735768, -0.04484123, -0.03969109,\n",
       "        -0.03151041,  0.0773865 , -0.18635239, -0.25671604,  0.06356201],\n",
       "       [-0.12391151,  0.23835585, -0.0856275 , -0.25296268,  0.06817999,\n",
       "        -0.00304487, -0.23481768, -0.0923012 , -0.22123165,  0.29947922,\n",
       "        -0.1173169 ,  0.25697276, -0.21711776,  0.02515391, -0.260388  ,\n",
       "        -0.16488582,  0.18580255,  0.09808066, -0.06497142, -0.27161416,\n",
       "        -0.28182432, -0.08129887,  0.11987746,  0.2901989 , -0.24999951,\n",
       "         0.27174887,  0.29322955,  0.14685974,  0.00185448,  0.2519926 ],\n",
       "       [ 0.1531505 , -0.2538965 ,  0.12242359,  0.18165508,  0.04957917,\n",
       "        -0.09443849, -0.05994895, -0.14778821, -0.08951658, -0.233026  ,\n",
       "         0.12766293, -0.04026583,  0.08022487, -0.03034058, -0.26586682,\n",
       "        -0.28754887, -0.01681933, -0.28823194, -0.15338483,  0.03851736,\n",
       "        -0.06261867, -0.23740983,  0.09382567,  0.18143561, -0.00998142,\n",
       "         0.02122334,  0.11706117, -0.18637523, -0.24516574,  0.21699545],\n",
       "       [-0.05307183,  0.19070736,  0.21332517,  0.06034824, -0.11747326,\n",
       "         0.12113842, -0.25437045, -0.12997971, -0.08799957,  0.26935533,\n",
       "        -0.12597944,  0.264645  , -0.20298994,  0.28502586, -0.19851112,\n",
       "        -0.11965571,  0.16745219,  0.18496111, -0.20135221, -0.02882192,\n",
       "         0.25597635,  0.19272664,  0.2648799 , -0.17758657, -0.30988142,\n",
       "        -0.04677585,  0.08635899, -0.13121453, -0.16255763, -0.29693624],\n",
       "       [ 0.20944878,  0.13431135,  0.18136746,  0.21133444,  0.06679845,\n",
       "        -0.13785648,  0.04110798,  0.14661464, -0.05534491,  0.0664508 ,\n",
       "         0.07144752, -0.18603204,  0.01936826, -0.26826227, -0.26540482,\n",
       "        -0.02671427, -0.20027845,  0.2846423 , -0.0197821 ,  0.0640516 ,\n",
       "         0.05261695, -0.05628258, -0.20791547, -0.08282734, -0.01865834,\n",
       "        -0.01986882,  0.1186673 , -0.12332864,  0.16142234,  0.06202009]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = tf.Variable(initializer([30, 30]))\n",
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30,) dtype=float32, numpy=\n",
       "array([ 0.12382933,  0.07901117,  0.18715903, -0.09648372, -0.01997188,\n",
       "       -0.08259219,  0.24359307,  0.1590082 ,  0.18060642,  0.01526508,\n",
       "       -0.18565258, -0.08274637, -0.00540164, -0.05931267, -0.07525064,\n",
       "       -0.08939293,  0.3048562 ,  0.14026639,  0.11396825,  0.28877202,\n",
       "        0.2275072 , -0.11885834,  0.10187429, -0.20368259, -0.04003069,\n",
       "       -0.07476638,  0.27228728,  0.1625602 ,  0.00644383, -0.042564  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0 = tf.Variable(initializer([30]))\n",
    "b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30, 10) dtype=float32, numpy=\n",
       "array([[-0.18572943,  0.30476737,  0.29936677,  0.06646496, -0.2212834 ,\n",
       "         0.10124883,  0.31700677,  0.2622648 ,  0.21541744, -0.29196697],\n",
       "       [ 0.3076653 ,  0.10221323,  0.3274567 , -0.32190287,  0.02367705,\n",
       "         0.08954474, -0.0131287 , -0.1803819 ,  0.20476913,  0.29842478],\n",
       "       [-0.35775822, -0.34639183, -0.17423478, -0.27732208, -0.33132756,\n",
       "         0.3435657 , -0.18287301,  0.35317683, -0.08141744,  0.27755737],\n",
       "       [ 0.22030294,  0.38317752,  0.3396542 ,  0.15324557,  0.09349069,\n",
       "        -0.131527  , -0.05412209,  0.3350106 ,  0.06462252,  0.24614573],\n",
       "       [-0.01989225, -0.24250387,  0.10879821, -0.3482893 ,  0.29476124,\n",
       "         0.1690396 ,  0.09725478, -0.38622472,  0.01245248,  0.2873168 ],\n",
       "       [ 0.021485  , -0.20588568,  0.11407906, -0.15152721,  0.33347464,\n",
       "        -0.24889964,  0.28584248,  0.12643874,  0.04715252,  0.11341703],\n",
       "       [-0.33251992,  0.32263702, -0.3704577 , -0.2128667 , -0.3063749 ,\n",
       "        -0.2820202 ,  0.26722878, -0.2966905 ,  0.38261926, -0.14563873],\n",
       "       [ 0.03389418,  0.38367236, -0.2821988 ,  0.32687438, -0.32364494,\n",
       "         0.27659905,  0.08795938, -0.19935   ,  0.22204834,  0.10847816],\n",
       "       [-0.23653996, -0.02176765,  0.09598947, -0.13657704, -0.24483025,\n",
       "         0.19581455, -0.17143017, -0.33066455,  0.1822455 , -0.32266676],\n",
       "       [ 0.30478716, -0.14643951,  0.27883184,  0.1566729 , -0.360767  ,\n",
       "         0.22119838,  0.27049553,  0.05212072, -0.27880847, -0.38116702],\n",
       "       [ 0.33400494,  0.20240605,  0.34715134, -0.32008007,  0.14086455,\n",
       "        -0.38204294, -0.33539823, -0.07021245, -0.27058843, -0.18078855],\n",
       "       [ 0.02759841, -0.04860702, -0.14587845, -0.16447961,  0.14903444,\n",
       "        -0.19633725, -0.36670524, -0.21571739, -0.15170911,  0.26314127],\n",
       "       [ 0.2149347 ,  0.22490752,  0.0727154 ,  0.28172094, -0.09472296,\n",
       "         0.24461436, -0.13639781, -0.26895642,  0.07368928, -0.3655438 ],\n",
       "       [ 0.36780983, -0.1883537 ,  0.02484846,  0.30962306,  0.2769817 ,\n",
       "         0.10906404,  0.09722459,  0.28185743,  0.23445117, -0.12833402],\n",
       "       [ 0.30944186, -0.3748199 , -0.30109635,  0.2206679 , -0.37690577,\n",
       "        -0.20711333, -0.33476117,  0.00913483,  0.34066463,  0.10209733],\n",
       "       [-0.3787276 ,  0.24907553,  0.19257212,  0.29334688, -0.12005442,\n",
       "        -0.27113685, -0.02506536, -0.15396506, -0.29564464,  0.35511094],\n",
       "       [-0.27844843, -0.2934876 ,  0.20705682,  0.24882162, -0.3455354 ,\n",
       "         0.38445032,  0.37646264, -0.36187407,  0.18357283, -0.15185428],\n",
       "       [ 0.06948981, -0.30416718,  0.3434041 , -0.33155802, -0.05968347,\n",
       "         0.12404358, -0.34555903,  0.35966468,  0.21102822,  0.21355814],\n",
       "       [-0.38698235, -0.14512376,  0.37143844,  0.02881691,  0.23809153,\n",
       "         0.2521943 ,  0.13415748, -0.09590849, -0.10100543,  0.2620445 ],\n",
       "       [ 0.15305382, -0.16633295, -0.18661764,  0.08301833, -0.05972522,\n",
       "         0.09230828,  0.28327113,  0.04485014,  0.24252826,  0.12338346],\n",
       "       [-0.12151828,  0.09706485, -0.2785044 , -0.28666383, -0.302528  ,\n",
       "        -0.15404178, -0.07800439,  0.29028666,  0.12199569, -0.09616685],\n",
       "       [-0.06332293, -0.21043837, -0.28453636, -0.1403575 , -0.15251541,\n",
       "        -0.09478185, -0.10100615, -0.07456976,  0.24446756,  0.3520463 ],\n",
       "       [-0.1853549 , -0.06128612,  0.1026305 ,  0.00877544,  0.34831524,\n",
       "         0.17326456, -0.18699633, -0.01135504, -0.17482483,  0.0073863 ],\n",
       "       [ 0.19196296,  0.15501487,  0.12544203,  0.21369147,  0.0903613 ,\n",
       "         0.3514889 , -0.1413446 ,  0.2670899 ,  0.16934496,  0.26578522],\n",
       "       [-0.36111245, -0.05284891, -0.21013217, -0.28139192,  0.18282437,\n",
       "         0.26680404, -0.2178747 ,  0.09707713,  0.25562423, -0.22863702],\n",
       "       [ 0.0786373 ,  0.20898348, -0.34556004,  0.23827004, -0.2982272 ,\n",
       "         0.0647938 , -0.2770819 , -0.18439254, -0.02676448, -0.02406007],\n",
       "       [ 0.02249557,  0.22794336,  0.29122633, -0.30007952,  0.25672925,\n",
       "         0.2951007 , -0.06381741, -0.20138165, -0.35508004, -0.14244603],\n",
       "       [ 0.10173637, -0.37426144, -0.10213593, -0.32439306, -0.19058943,\n",
       "         0.14356506,  0.34950072, -0.20631856,  0.11988372, -0.02770886],\n",
       "       [-0.15935323, -0.18891753, -0.13064757, -0.37968424,  0.10209179,\n",
       "        -0.07555354,  0.01619315, -0.0953286 ,  0.05428341, -0.24598375],\n",
       "       [-0.30147606, -0.34485254, -0.10862738,  0.03643647, -0.09463605,\n",
       "        -0.07219386,  0.28871477, -0.06048158,  0.02264914, -0.12867135]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(initializer([30, 10]))\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=\n",
       "array([ 0.39916116, -0.37575656, -0.42639816,  0.22062963,  0.04688084,\n",
       "       -0.14114311, -0.21939114, -0.18652129,  0.4144057 , -0.12350485],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = tf.Variable(initializer([10]))\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
       "array([[ 0.5173914 ],\n",
       "       [ 0.3605166 ],\n",
       "       [-0.5656107 ],\n",
       "       [-0.72406286],\n",
       "       [ 0.07728636],\n",
       "       [-0.46490487],\n",
       "       [ 0.2880512 ],\n",
       "       [ 0.31703   ],\n",
       "       [ 0.4694075 ],\n",
       "       [-0.3153467 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = tf.Variable(initializer([10, 1]))\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.75419486], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = tf.Variable(initializer([1]))\n",
    "b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\library\\python\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "==================================================\n",
      "step: 0, cost : 0.665410578250885\n",
      "==================================================\n",
      "step: 100, cost : 0.05362467095255852\n",
      "==================================================\n",
      "step: 200, cost : 0.029094940051436424\n",
      "==================================================\n",
      "step: 300, cost : 0.018425986170768738\n",
      "==================================================\n",
      "step: 400, cost : 0.0026923895347863436\n",
      "==================================================\n",
      "step: 500, cost : 0.0014747817767784\n",
      "==================================================\n",
      "step: 600, cost : 0.0009856660617515445\n",
      "==================================================\n",
      "step: 700, cost : 0.0007209399482235312\n",
      "==================================================\n",
      "step: 800, cost : 0.0005564090679399669\n",
      "==================================================\n",
      "step: 900, cost : 0.00044525970588438213\n",
      "==================================================\n",
      "step: 1000, cost : 0.00036578302388079464\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "for epoch in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis1 = tf.sigmoid(tf.matmul(X_train, w0) + b0)\n",
    "        hypothesis2 = tf.sigmoid(tf.matmul(hypothesis1, w1) + b1)\n",
    "        pred = tf.sigmoid(tf.matmul(hypothesis2, w2) + b2)\n",
    "        \n",
    "        cost =  -tf.reduce_mean(y_train * tf.log(pred) + (1-y_train) * tf.log(1-pred))\n",
    "        grads = tape.gradient(cost, [w0, w1, w2, b0, b1, b2])\n",
    "        \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [w0, w1, w2,  b0, b1, b2]))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"step: {epoch}, cost : {cost.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 값들 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5014713 , -0.11107563,  1.4849713 , ...,  1.4382259 ,\n",
       "         0.60711294,  0.37932593],\n",
       "       [-0.47309536,  1.1019005 , -0.3283536 , ...,  1.6719135 ,\n",
       "         2.3696063 ,  7.178855  ],\n",
       "       [-0.27224404, -0.25049824, -0.31561565, ..., -0.14306077,\n",
       "        -1.0448236 , -0.8275744 ],\n",
       "       ...,\n",
       "       [-0.6201979 ,  0.33972394, -0.5790057 , ...,  0.0283102 ,\n",
       "        -0.6763024 ,  0.94223714],\n",
       "       [-0.8238779 ,  3.3721638 , -0.8699267 , ..., -1.3033981 ,\n",
       "         0.03830845, -0.6063482 ],\n",
       "       [-0.1194839 , -0.14360741, -0.13276264, ...,  0.22928153,\n",
       "        -0.06103185,  0.39206675]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 값들에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107410, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[3.2851100e-04],\n",
       "       [3.3813715e-04],\n",
       "       [9.9989903e-01],\n",
       "       [9.9583149e-01],\n",
       "       [9.9992085e-01],\n",
       "       [9.9986768e-01],\n",
       "       [9.9991125e-01],\n",
       "       [3.2842159e-04],\n",
       "       [9.9985981e-01],\n",
       "       [3.2970309e-04],\n",
       "       [9.9988353e-01],\n",
       "       [3.2877922e-04],\n",
       "       [3.2940507e-04],\n",
       "       [9.9990743e-01],\n",
       "       [9.9862003e-01],\n",
       "       [9.9992114e-01],\n",
       "       [9.9991798e-01],\n",
       "       [3.2848120e-04],\n",
       "       [9.9955952e-01],\n",
       "       [9.9991977e-01],\n",
       "       [9.9988234e-01],\n",
       "       [9.1009295e-01],\n",
       "       [9.9990642e-01],\n",
       "       [3.2860041e-04],\n",
       "       [9.9991930e-01],\n",
       "       [9.9991584e-01],\n",
       "       [9.9992126e-01],\n",
       "       [9.9985325e-01],\n",
       "       [9.9992108e-01],\n",
       "       [9.9980938e-01],\n",
       "       [9.9991030e-01],\n",
       "       [3.2868981e-04],\n",
       "       [9.9991989e-01],\n",
       "       [3.4922361e-04],\n",
       "       [3.2866001e-04],\n",
       "       [9.9880993e-01],\n",
       "       [9.9991381e-01],\n",
       "       [3.2877922e-04],\n",
       "       [1.5123129e-02],\n",
       "       [9.9992132e-01],\n",
       "       [3.3369660e-04],\n",
       "       [9.7660482e-01],\n",
       "       [9.9991810e-01],\n",
       "       [3.2958388e-04],\n",
       "       [9.9962926e-01],\n",
       "       [3.3199787e-04],\n",
       "       [9.9992085e-01],\n",
       "       [3.2842159e-04],\n",
       "       [9.9983811e-01],\n",
       "       [3.2880902e-04],\n",
       "       [9.9991179e-01],\n",
       "       [9.9991965e-01],\n",
       "       [9.9987882e-01],\n",
       "       [3.3062696e-04],\n",
       "       [9.9990976e-01],\n",
       "       [9.9992085e-01],\n",
       "       [3.2946467e-04],\n",
       "       [3.8060546e-04],\n",
       "       [9.9990857e-01],\n",
       "       [3.3086538e-04],\n",
       "       [9.9991667e-01],\n",
       "       [3.2854080e-04],\n",
       "       [9.9991107e-01],\n",
       "       [1.0435551e-02],\n",
       "       [9.9992061e-01],\n",
       "       [9.9991727e-01],\n",
       "       [3.4019351e-04],\n",
       "       [9.9992114e-01],\n",
       "       [9.9991965e-01],\n",
       "       [6.8783009e-01],\n",
       "       [9.9992108e-01],\n",
       "       [9.9989551e-01],\n",
       "       [3.2946467e-04],\n",
       "       [9.9992061e-01],\n",
       "       [3.2925606e-04],\n",
       "       [9.9992061e-01],\n",
       "       [9.9991834e-01],\n",
       "       [3.2854080e-04],\n",
       "       [9.9992120e-01],\n",
       "       [3.3128262e-04],\n",
       "       [9.9991912e-01],\n",
       "       [9.9989194e-01],\n",
       "       [9.6626937e-01],\n",
       "       [3.3769011e-04],\n",
       "       [4.4628978e-04],\n",
       "       [9.8582888e-01],\n",
       "       [6.0576200e-04],\n",
       "       [3.3768117e-03],\n",
       "       [9.9983442e-01],\n",
       "       [3.8039684e-04],\n",
       "       [3.2860041e-04],\n",
       "       [3.3125281e-04],\n",
       "       [9.9992132e-01],\n",
       "       [3.3137202e-04],\n",
       "       [9.9991792e-01],\n",
       "       [9.9988478e-01],\n",
       "       [3.3727288e-04],\n",
       "       [3.2931566e-04],\n",
       "       [4.2214990e-04],\n",
       "       [9.9992049e-01],\n",
       "       [5.8367848e-04],\n",
       "       [9.9987388e-01],\n",
       "       [9.9991846e-01],\n",
       "       [9.9992085e-01],\n",
       "       [1.5812278e-01],\n",
       "       [9.9992138e-01],\n",
       "       [3.9160252e-04],\n",
       "       [9.9878293e-01],\n",
       "       [9.9991739e-01],\n",
       "       [9.9985075e-01],\n",
       "       [9.9873984e-01],\n",
       "       [9.9991953e-01],\n",
       "       [9.9982077e-01],\n",
       "       [9.9984026e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis0 = tf.sigmoid(tf.matmul(X_test, w0) + b0)\n",
    "hypothesis1 = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
    "predict = tf.sigmoid(tf.matmul(hypothesis1, w2) + b2)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107414, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred01 = tf.cast(predict>0.5, dtype=\"float32\")\n",
    "pred01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107417, shape=(114, 1), dtype=bool, numpy=\n",
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac01 = tf.equal(pred01, y_test)\n",
    "ac01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107421, shape=(), dtype=float32, numpy=0.99122804>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac01 = tf.cast(ac01, dtype=\"float32\")\n",
    "tf.reduce_mean(ac01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 데이터에 대한 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107491, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis0 = tf.sigmoid(tf.matmul(X_train, w0) + b0)\n",
    "hypothesis1 = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
    "predict = tf.sigmoid(tf.matmul(hypothesis1, w2) + b2)\n",
    "pred01 = tf.cast(predict>0.5, dtype=\"float32\")\n",
    "ac01 = tf.equal(pred01, y_train)\n",
    "ac01 = tf.cast(ac01, dtype=\"float32\")\n",
    "tf.reduce_mean(ac01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
