{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom FFNN\n",
    "#### 2) 여러개의 layer가 있는 FFNN\n",
    "이제 여러개의 layer가 있는 FFNN을 고려해보자.\n",
    "$$\\begin{aligned}\n",
    "s_1 &= x \\cdot w_1 + b_1,  &(b, h_1^1)\\\\\n",
    "h_1 &= f_1(s_1), &(b, h_1^1) \\\\\n",
    "s_2 &= h_1 \\cdot w_2 + b_2,  &(b, h_2^1) \\\\\n",
    "h_2 &= f_2(s_2),  &(b, h_2^1) \\\\\n",
    "s_3 &= h_2 \\cdot w_3 + b_3,  &(b, h_3^1 = 1) \\\\\n",
    "\\hat y &= f(s_3),  &(b, 1) \\\\\n",
    "e &= \\sum_i (\\hat y - y)^2, &(1, ) \\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_3} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial w_3}, &(h_2^1, h_3^1=1) \\\\\n",
    "&= h_2^T \\cdot \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right]\\\\\n",
    "(h_2^1, h_3^1=1) &= (b, h_2^1)^T \\cdot [(b, 1) \\times (b, 1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_2} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial h_2}, &(b, h_2^1) \\\\\n",
    "&= \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right] \\cdot w_3 \\\\\n",
    "(b, h_2^1) &= [(b, 1) \\times (b, 1)] \\cdot (h_3^1=1, h_2^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial w_2}, &(h_1^1, h_2^1) \\\\\n",
    "&= h_1^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_1^1, h_2^1) &= (b, h_1^1)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\\\\\n",
    "& \\\\\n",
    "\\text{for b, }& \\text{We assume } b \\cdot x_0, \\text{and always } x_0 = 1\\\\\n",
    "\\cfrac {\\partial e}{\\partial b_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial b_2}, &(h_2^1,) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_2^1,) &= (b, 1)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\n",
    "\\end{aligned}$$\n",
    "\n",
    "따라서 일반화를 하면:\n",
    "$$\\begin{aligned}\n",
    "\\cfrac {\\partial e}{\\partial w_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial w_i}, &(h_{i-1}^1, h_i^1) \\\\\n",
    "&= h_{i-1}^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_{i-1}^1, h_i^1) &= (b, h_{i-1}^1)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_i} &= \\cfrac{\\partial e}{\\partial h_{i+1}} \\cfrac{\\partial h_{i+1}}{\\partial s_{i+1}} \\cfrac{\\partial s_{i+1}}{\\partial h_i}, &(b, h_2^1) \\\\\n",
    "&= \\left[ \\cfrac{\\partial e}{\\partial h_{i+1}}  \\times f^{'}(s_{i+1}) \\right] \\cdot w^T_{i+1} \\\\\n",
    "(b, h_i^1) &= [(b, h_{i+1}^1) \\times (b, h_{i+1}^1)] \\cdot (h_{i+1}^1, h_i^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial b_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial b_i}, &(h_i^1, ) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_i^1,) &= (b, 1)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\n",
    "\\end{aligned}$$\n",
    "- $b_i$를 구할 때, np.sum(arr, axis=-1)을 사용하면 된다.\n",
    "\n",
    "이를 위해 propagate_forward(self, x)함수를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import shuffle, rand\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(1024,2)\n",
    "y_train = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_train ] )\n",
    "\n",
    "x_val = np.random.rand(32,2)\n",
    "y_val = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_val ] )\n",
    "\n",
    "x_test = np.array( [ [0.2, 0.1], [0.3, 0.1], [0.4, 0.1], [0.5, 0.1] ] )\n",
    "y_test = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_test ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 위해 multi layer를 구현할 수 있도록 다음과 같은 절차에 따라 작성한다.\n",
    "\n",
    "1. layer를 추가할 수 있는 add 함수를 구현한다.\n",
    " - 인자로, input의 size와 activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    \n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr # learning rate\n",
    "        # weights list\n",
    "        self.ws = []; self.bs = []\n",
    "        self.fs = []; self.f_derivs = []\n",
    "        self.N_layers = 0\n",
    "        \n",
    "    # layer를 추가하며, weights를 초기화하기\n",
    "    def add(self, units, activation=None, activation_deriv=None, input_dim=None):\n",
    "        self.ws.append(np.random.rand(input_dim * units).reshape(input_dim, units))\n",
    "        self.bs.append(np.zeros(units))\n",
    "        self.fs.append(activation)\n",
    "        self.f_derivs.append(activation_deriv)\n",
    "        self.N_layers += 1\n",
    "        \n",
    "    # feed forwarding\n",
    "    def propagate_forward(self, x):\n",
    "        s = [x]; o = [x] # for l = 0\n",
    "        for idx in range(self.N_layers):\n",
    "            s_input = np.dot(x, self.ws[idx]) + self.bs[idx]\n",
    "            y = self.fs[idx](s_input)\n",
    "            x = y\n",
    "            o.append(y)\n",
    "            s.append(s_input)\n",
    "        return s, o\n",
    "\n",
    "    # predicting\n",
    "    def predict(self, x):\n",
    "        s, o = self.propagate_forward(x)\n",
    "        return o[-1] # output from the last layer\n",
    "\n",
    "    # train for one batch. x 자체가 batch\n",
    "    def train_on_batch(self, x_batch, y_batch, istrain=True):\n",
    "        s, o = self.propagate_forward(x_batch)\n",
    "        Y = o[-1]\n",
    "        N = x_batch.shape[0]\n",
    "        loss = np.sum((Y - y_batch))\n",
    "        if istrain:\n",
    "            qq = (2 * (Y - y_batch.reshape(-1, 1)) * self.f_derivs[3](s[3]) )\n",
    "            dw3 = np.dot(o[2].T, qq)\n",
    "            db3 = np.sum(Y - y_batch)\n",
    "            \n",
    "#             dw2 = \n",
    "            print(dw3)    \n",
    "        return loss\n",
    "\n",
    "    # epochs에 대해 batch 별로 학습하기\n",
    "    def fit(self, x, y, batch_size, epochs, validation_data):\n",
    "        Losses = [] # validation loss after each epoch\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            Loss = 0\n",
    "            N = x.shape[0]\n",
    "            for j in range(0, N, batch_size):\n",
    "                x_batch = x[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                n = x_batch.shape[0]\n",
    "                Loss += (self.train_on_batch(x_batch, y_batch) / n)\n",
    "        \n",
    "            print(\"Train Loss at Epoch %d is %.8f\" %(epoch, Loss))\n",
    "            Losses[\"train_loss\"].append(Loss)                \n",
    "\n",
    "        return Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 activation 함수 구현:\n",
    "$$\\begin{aligned}\n",
    "\\text{Linear}(x) &= x\\\\\n",
    "\\cfrac {\\partial \\text{Linear}(x)}{\\partial x} &= 1\\\\\n",
    "\\text{Sigmoid}(x) &= \\sigma (x) = \\cfrac {1}{1-\\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{Sigmoid}(x)}{\\partial x} &= \\sigma(x) * (1-\\sigma(x))\\\\\n",
    "\\text{tahn}(x) &= \\cfrac {\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{tahn}(x)}{\\partial x} &= 1-\\text{tahn}^2(x)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x): # linear y = x\n",
    "    return x\n",
    "\n",
    "def linear_deriv(x): # derivative of y = x\n",
    "    return 1\n",
    "\n",
    "def sigmoid(x): # sigmoid\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x): # derivative of sigmoid\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x): # hyperbolicv tangent\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x): # derivative of hyperbolic tangent\n",
    "    return 1 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 > 3 > 3 > 1 layer를 갖는 FFNN의 인스턴스를 생성한다.\n",
    "- 출력 2개의 선형 활성함수를 갖는 첫 hidden layer 추가\n",
    "- 출력 3개의 sigmoid 활성함수를 갖는 둘째 hidden layer 추가\n",
    "- 출력 3개의 tanh 활성함수를 갖는 셋째 hidden layer 추가\n",
    "- 출력 1개의 선형 활성함수를 갖는 출력 layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn = FFNN()\n",
    "fnn.add(2, activation=linear, activation_deriv=linear_deriv, input_dim=2)\n",
    "fnn.add(3, activation=sigmoid, activation_deriv=sigmoid_deriv, input_dim=2)\n",
    "fnn.add(3, activation=tanh, activation_deriv=tanh_deriv, input_dim=3)\n",
    "fnn.add(1, activation=linear, activation_deriv=linear_deriv, input_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.45835394]\n",
      " [17.51188543]\n",
      " [17.41021938]]\n",
      "[[15.85710376]\n",
      " [16.90036225]\n",
      " [16.7525848 ]]\n",
      "[[19.28909527]\n",
      " [20.56067273]\n",
      " [20.41877638]]\n",
      "[[32.96269037]\n",
      " [35.13226913]\n",
      " [34.8626111 ]]\n",
      "[[26.17110277]\n",
      " [27.8749166 ]\n",
      " [27.65077779]]\n",
      "[[15.10910823]\n",
      " [16.11781614]\n",
      " [15.98723928]]\n",
      "[[22.0137833 ]\n",
      " [23.45955011]\n",
      " [23.30636787]]\n",
      "[[27.53213592]\n",
      " [29.36722545]\n",
      " [29.10605003]]\n",
      "[[21.13821865]\n",
      " [22.54672877]\n",
      " [22.36208499]]\n",
      "[[4.9693352 ]\n",
      " [5.33095889]\n",
      " [5.22371485]]\n",
      "[[17.54747917]\n",
      " [18.69266665]\n",
      " [18.56497352]]\n",
      "[[16.25982829]\n",
      " [17.32427045]\n",
      " [17.19323546]]\n",
      "[[27.0808948 ]\n",
      " [28.88973563]\n",
      " [28.61462813]]\n",
      "[[24.68507998]\n",
      " [26.29185526]\n",
      " [26.07176781]]\n",
      "[[26.09105952]\n",
      " [27.79690636]\n",
      " [27.52224102]]\n",
      "[[20.54932637]\n",
      " [21.90365567]\n",
      " [21.75821435]]\n",
      "[[29.60136049]\n",
      " [31.51425353]\n",
      " [31.29902563]]\n",
      "[[22.71426805]\n",
      " [24.21809355]\n",
      " [23.99293241]]\n",
      "[[17.36048358]\n",
      " [18.53581921]\n",
      " [18.33080322]]\n",
      "[[38.28658272]\n",
      " [40.8161044 ]\n",
      " [40.46844308]]\n",
      "[[30.20307218]\n",
      " [32.19669989]\n",
      " [31.91775086]]\n",
      "[[23.04348401]\n",
      " [24.61357374]\n",
      " [24.37760014]]\n",
      "[[33.72812468]\n",
      " [35.92912343]\n",
      " [35.64622253]]\n",
      "[[32.55926738]\n",
      " [34.70137264]\n",
      " [34.42515624]]\n",
      "[[23.97468224]\n",
      " [25.54495313]\n",
      " [25.31833021]]\n",
      "[[18.94115726]\n",
      " [20.20121015]\n",
      " [20.04640621]]\n",
      "[[15.19547827]\n",
      " [16.1984872 ]\n",
      " [16.02698116]]\n",
      "[[20.24976022]\n",
      " [21.56505951]\n",
      " [21.40850482]]\n",
      "[[23.7469647 ]\n",
      " [25.32732258]\n",
      " [25.08966024]]\n",
      "[[12.14197518]\n",
      " [12.9672803 ]\n",
      " [12.86690606]]\n",
      "[[23.45456017]\n",
      " [24.98159603]\n",
      " [24.79591423]]\n",
      "[[26.00535561]\n",
      " [27.74323696]\n",
      " [27.521199  ]]\n",
      "[[20.73997823]\n",
      " [22.08275564]\n",
      " [21.96506192]]\n",
      "[[27.44272505]\n",
      " [29.26222292]\n",
      " [29.07073565]]\n",
      "[[24.28939277]\n",
      " [25.84670449]\n",
      " [25.70202927]]\n",
      "[[10.65002934]\n",
      " [11.37341324]\n",
      " [11.28537733]]\n",
      "[[22.95846626]\n",
      " [24.47167494]\n",
      " [24.29382856]]\n",
      "[[28.08158291]\n",
      " [29.9053162 ]\n",
      " [29.71390371]]\n",
      "[[32.88418774]\n",
      " [35.09091615]\n",
      " [34.76468374]]\n",
      "[[24.52530489]\n",
      " [26.13166971]\n",
      " [25.90666836]]\n",
      "[[14.05752591]\n",
      " [14.98114993]\n",
      " [14.85353521]]\n",
      "[[28.01500472]\n",
      " [29.89070115]\n",
      " [29.63151455]]\n",
      "[[21.29860187]\n",
      " [22.67042675]\n",
      " [22.57438266]]\n",
      "[[19.62831515]\n",
      " [20.92811599]\n",
      " [20.71185535]]\n",
      "[[24.23932578]\n",
      " [25.79041486]\n",
      " [25.70719548]]\n",
      "[[20.64258209]\n",
      " [22.00654995]\n",
      " [21.81992081]]\n",
      "[[22.75283479]\n",
      " [24.21008122]\n",
      " [24.03203871]]\n",
      "[[14.66341028]\n",
      " [15.55342522]\n",
      " [15.47617094]]\n",
      "[[31.10544752]\n",
      " [33.17819024]\n",
      " [32.90077138]]\n",
      "[[31.52009224]\n",
      " [33.56795043]\n",
      " [33.32895277]]\n",
      "[[12.99456761]\n",
      " [13.88598942]\n",
      " [13.73178061]]\n",
      "[[8.36185536]\n",
      " [8.92131103]\n",
      " [8.83425977]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-fa27da82b84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-6daaa2c46df5>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, validation_data)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mLoss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train Loss at Epoch %d is %.8f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mLosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "Losses = fnn.fit(x_train, y_train, 20, 1000, (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "[[0.97862965]\n",
      " [0.9794233 ]\n",
      " [0.98018522]\n",
      " [0.9809166 ]]\n",
      "y_test\n",
      "[0.98 1.28 1.58 1.88]\n"
     ]
    }
   ],
   "source": [
    "y_pred = fnn.predict(x_test)\n",
    "print('y_pred'); print(y_pred)\n",
    "print('y_test'); print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses의 결과를 이전과 같이 시각화하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
