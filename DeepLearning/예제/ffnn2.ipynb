{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom FFNN\n",
    "#### 2) 여러개의 layer가 있는 FFNN\n",
    "이제 여러개의 layer가 있는 FFNN을 고려해보자.\n",
    "$$\\begin{aligned}\n",
    "s_1 &= x \\cdot w_1 + b_1,  &(b, h_1^1)\\\\\n",
    "h_1 &= f_1(s_1), &(b, h_1^1) \\\\\n",
    "s_2 &= h_1 \\cdot w_2 + b_2,  &(b, h_2^1) \\\\\n",
    "h_2 &= f_2(s_2),  &(b, h_2^1) \\\\\n",
    "s_3 &= h_2 \\cdot w_3 + b_3,  &(b, h_3^1 = 1) \\\\\n",
    "\\hat y &= f(s_3),  &(b, 1) \\\\\n",
    "e &= \\sum_i (\\hat y - y)^2, &(1, ) \\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_3} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial w_3}, &(h_2^1, h_3^1=1) \\\\\n",
    "&= h_2^T \\cdot \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right]\\\\\n",
    "(h_2^1, h_3^1=1) &= (b, h_2^1)^T \\cdot [(b, 1) \\times (b, 1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_2} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial h_2}, &(b, h_2^1) \\\\\n",
    "&= \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right] \\cdot w_3 \\\\\n",
    "(b, h_2^1) &= [(b, 1) \\times (b, 1)] \\cdot (h_3^1=1, h_2^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial w_2}, &(h_1^1, h_2^1) \\\\\n",
    "&= h_1^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_1^1, h_2^1) &= (b, h_1^1)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\\\\\n",
    "& \\\\\n",
    "\\text{for b, }& \\text{We assume } b \\cdot x_0, \\text{and always } x_0 = 1\\\\\n",
    "\\cfrac {\\partial e}{\\partial b_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial b_2}, &(h_2^1,) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_2^1,) &= (b, 1)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\n",
    "\\end{aligned}$$\n",
    "\n",
    "따라서 일반화를 하면:\n",
    "$$\\begin{aligned}\n",
    "\\cfrac {\\partial e}{\\partial w_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial w_i}, &(h_{i-1}^1, h_i^1) \\\\\n",
    "&= h_{i-1}^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_{i-1}^1, h_i^1) &= (b, h_{i-1}^1)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_i} &= \\cfrac{\\partial e}{\\partial h_{i+1}} \\cfrac{\\partial h_{i+1}}{\\partial s_{i+1}} \\cfrac{\\partial s_{i+1}}{\\partial h_i}, &(b, h_2^1) \\\\\n",
    "&= \\left[ \\cfrac{\\partial e}{\\partial h_{i+1}}  \\times f^{'}(s_3) \\right] \\cdot w_3 \\\\\n",
    "(b, h_i^1) &= [(b, h_{i+1}^1) \\times (b, h_{i+1}^1)] \\cdot (h_{i+1}^1, h_i^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial b_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial b_i}, &(h_i^1, ) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_i^1,) &= (b, 1)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\n",
    "\\end{aligned}$$\n",
    "- $b_i$를 구할 때, np.sum(arr, axis=-1)을 사용하면 된다.\n",
    "\n",
    "이를 위해 propagate_forward(self, x)함수를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(1024,2)\n",
    "y_train = np.array( [ [x[0]+x[1], x[0]-x[1]] for x in x_train ] ) * 0.1\n",
    "\n",
    "x_val = np.random.rand(32,2)\n",
    "y_val = np.array( [ [x[0]+x[1], x[0]-x[1]] for x in x_val ] ) * 0.1\n",
    "\n",
    "x_test = np.array( [ [0.2, 0.1], [0.3, 0.1], [0.4, 0.1], [0.5, 0.1] ] )\n",
    "y_test = np.array( [ [x[0]+x[1], x[0]-x[1]] for x in x_test ] ) * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 위해 multi layer를 구현할 수 있도록 다음과 같은 절차에 따라 작성한다.\n",
    "\n",
    "1. layer를 추가할 수 있는 add 함수를 구현한다.\n",
    " - 인자로, input의 size와 activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    \n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr # learning rate\n",
    "        # weights list\n",
    "        self.ws = []; self.bs = []\n",
    "        self.fs = []; self.f_derivs = []\n",
    "        self.N_layers = 0\n",
    "        \n",
    "    # layer를 추가하며, weights를 초기화하기\n",
    "    def add(self, units, activation=None, activation_deriv=None, input_dim=None):\n",
    "        pass\n",
    "        \n",
    "    # feed forwarding\n",
    "    def propagate_forward(self, x):\n",
    "        s = [x]; o = [x] # for l = 0\n",
    "        pass\n",
    "        return s, o\n",
    "\n",
    "    # predicting\n",
    "    def predict(self, x):\n",
    "        s, o = self.propagate_forward(x)\n",
    "        return o[-1] # output from the last layer\n",
    "\n",
    "    # train for one batch. x 자체가 batch\n",
    "    def train_on_batch(self, x_batch, y_batch):\n",
    "\n",
    "        pass\n",
    "\n",
    "    # epochs에 대해 batch 별로 학습하기\n",
    "    def fit(self, x, y, batch_size, epochs, validation_data):\n",
    "        Losses = [] # validation loss after each epoch\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            pass\n",
    "\n",
    "        return Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 activation 함수 구현:\n",
    "$$\\begin{aligned}\n",
    "\\text{Linear}(x) &= x\\\\\n",
    "\\cfrac {\\partial \\text{Linear}(x)}{\\partial x} &= 1\\\\\n",
    "\\text{Sigmoid}(x) &= \\sigma (x) = \\cfrac {1}{1-\\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{Sigmoid}(x)}{\\partial x} &= \\sigma(x) * (1-\\sigma(x))\\\\\n",
    "\\text{tahn}(x) &= \\cfrac {\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{tahn}(x)}{\\partial x} &= 1-\\text{tahn}^2(x)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x): # linear y = x\n",
    "    return x\n",
    "\n",
    "def linear_deriv(x): # derivative of y = x\n",
    "    return 1\n",
    "\n",
    "def sigmoid(x): # sigmoid\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x): # derivative of sigmoid\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x): # hyperbolicv tangent\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x): # derivative of hyperbolic tangent\n",
    "    return 1 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 > 3 > 3 > 2 layer를 갖는 FFNN의 인스턴스를 생성한다.\n",
    "- 입력 layer를 추가한다.\n",
    "- 출력 3개의 선형 활성함수를 갖는 첫 hidden layer 추가\n",
    "- 출력 3개의 sigmoid 활성함수를 갖는 둘째 hidden layer 추가\n",
    "- 출력 2개의 tanh 활성함수를 갖는 출력 layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Losses = fnn.fit(x_train, y_train, 20, 1000, (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fnn.predict(x_test)\n",
    "print('y_pred'); print(y_pred)\n",
    "print('y_test'); print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses의 결과를 이전과 같이 시각화하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
