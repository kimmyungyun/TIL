# NLP

## 텍스트 분석

#### 텍스트 정규화

- 텍스트의 형태를 일관되게 변형하는 작업
- 토큰화
  - 텍스트를 의미 단위로 분할하는 작업
- 어간 추출
  - 형태가 변형된 단어로부터 어간을 분리하는 작업

#### 토큰화

- 영어는 공백을 기준으로 단순 분할
- 언어에 따른 토큰화 작업
  - 영어
    - 단순 공백 기준 분할
  - 독일어
    - 복합 명사에 대한 분리 방법이 요구
  - 중국어
    - 공백 X, 여러 문자로 한 단어가 이루어짐
  - 한국어
    - 단순 공백 기준이 아닌 품사 기준

## 정보 추출

#### Term Frequency(TF)

- 단어 빈도는 특정 단어 t가 특정 문서 d 내에 등장하는 빈도
- 빈도수가 높지만, 정보가 부족한 단어일 가능성 높음
- 드물게 등장하는 단어가 더 중요한 정보를 가지고 있는 경우가 높음



#### Inverse Document Frequency(IDF)

- df(t) 는 document frequency로 단어 t가 등장한 문장의 수
- 단어 t의 idf 수치는 t의 단어 중요도를 나타내는 척도



#### TF-IDF

- TF와 IDF의 곱
- 문서군 내에서 특정 단어의 중요도를 수치화한 값
- tf-idf 값은 특정 문서 내 특정 단어의 빈도가 높아질 수록 커짐
- tf-idf 값은 문서군 내에서 단어가 희박하게 등장할 수록(idf) 커짐

## Word2Vec

- 단어에 대한 OneHotEncoding의 문제점을 해결하기 위해서 나온 방법
- 기존 OneHotEncoding은 단어끼리의 유사도를 고려하지 않음
- 문장에서 이웃한 문자끼리의 유사도를 고려하여 단어에 대한 벡터를 구함
- 어떤 단어를 기준((1, 1)로 설정)으로 얼마만큼 떨어졌나를 계산

#### 구하는 방법

1. 문서 내의 단어에 대하여 OneHotEncoding을 수행
2. Hidden layer와 softmax를 통해 학습을 수행

