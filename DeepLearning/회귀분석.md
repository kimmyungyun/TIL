# 회귀분석

## 종류

- 단순 선형 회귀

  - $$
    y = ax + b
    $$

- 다중 선형 회귀

  - $$
    y = ax_1 + bx_2 + c
    $$

- 곡선 회귀(다항 회귀)

  - $$
    y = ax + bx^2 + c
    $$

  - 다항 회귀는 치환을 해버리면 선형회귀로 치환이 가능하다

  - $$
    \begin{align}
    x_2  = &x^2\\
    y  = ax_1+&bx_2+c
    \end{align}
    $$

- 위의 회귀식들을 벡터 및 행렬로 치환할 때

  - $$
    \begin{aligned}
    \vec{y} &= \vec{x} \cdot{} \vec{w} + \varepsilon\\
    y &= \vec{X} \cdot{} \vec{W} + \varepsilon\\
    \hat{y} &= {X} \cdot{} {W}
    \end{aligned}
    $$

## 잔차(Residual)

- 잔차를 구하는 방법

  - 실제 데이터 - 예측 값

  - $$
    \varepsilon = y_i - \hat{y}_i
    $$
    
  
- 잘만든 회귀 모양이라면 평균이 0인 정규분포의 모양을 가져야한다

- 잔차가 일정한 형태로 반복될 때

  - 어떤 값이 빠진 것이기 때문에 범주형 변수를 추가해 주면 된다
  - Ex)  sin(x)

- 잔차를 활용한 loss 계산법

  - $$
    loss = \frac{1}{N} \sum{\varepsilon^2} = \sum{(y_i-\hat{y}_i)^2}
    $$

- 잔차가 정규분포를 이루고 있지 않으면 뭔가가 빠진 것이다

## 회귀 분석의 기본

- 회귀 분석의 기본은 관계 없음으로 시작한다
- 이후에 나타나는 오류를 범할 확률을 통해서 관계가 있는지 없는지 판단한다
- 오차항의 분산이 동일해야 한다
  - 데이터에 대한 오차들을 절반으로 나눴을 때, 분산이 동일하게 이뤄지는지 확인한다
  - 이런 경우에는 독립변수를 더 추가해서 분산이 동일하게(등분산) 나오도록 만들어 줘야한다

- 오차(Residual)의 분산이 클 경우, log 를 취함으로써 압축할 필요성이 있다