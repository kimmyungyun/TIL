# 회귀분석

## 종류

- 단순 선형 회귀

  - ![](https://latex.codecogs.com/gif.latex?y&space;=&space;ax&space;&plus;&space;b)

- 다중 선형 회귀

  - ![](https://latex.codecogs.com/gif.latex?y&space;=&space;ax_1&space;&plus;&space;bx_2&space;&plus;&space;c)

- 곡선 회귀(다항 회귀)

  - ![](https://latex.codecogs.com/gif.latex?y&space;=&space;ax&space;&plus;&space;bx^2&space;&plus;&space;c)

  - 다항 회귀는 치환을 해버리면 선형회귀로 치환이 가능하다

  - ![](https://latex.codecogs.com/gif.latex?x_2&space;=&space;x^2\\&space;y&space;=&space;ax_1&space;&plus;&space;bx_2&space;&plus;&space;c)

- 위의 회귀식들을 벡터 및 행렬로 치환할 때

  - ![](https://latex.codecogs.com/gif.latex?\begin{aligned}&space;\vec{y}&space;&=&space;\vec{x}&space;\cdot{}&space;\vec{w}&space;&plus;&space;\varepsilon\\&space;y&space;&=&space;\vec{X}&space;\cdot{}&space;\vec{W}&space;&plus;&space;\varepsilon\\&space;\hat{y}&space;&=&space;{X}&space;\cdot{}&space;{W}&space;\end{aligned})

## 잔차(Residual)

- 잔차를 구하는 방법

  - 실제 데이터 - 예측 값

  - ![](https://latex.codecogs.com/gif.latex?\varepsilon&space;=&space;y_i&space;-&space;\hat{y}_i)
    
  
- 잘만든 회귀 모양이라면 평균이 0인 정규분포의 모양을 가져야한다

- 잔차가 일정한 형태로 반복될 때

  - 어떤 값이 빠진 것이기 때문에 범주형 변수를 추가해 주면 된다
  - Ex)  sin(x)

- 잔차를 활용한 loss 계산법

  - ![](https://latex.codecogs.com/gif.latex?loss&space;=&space;\frac{1}{N}&space;\sum{\varepsilon^2}&space;=&space;\sum{(y_i-\hat{y}_i)^2})

- 잔차가 정규분포를 이루고 있지 않으면 뭔가가 빠진 것이다



## 회귀 분석의 기본

- 회귀 분석의 기본은 관계 없음으로 시작한다
- 이후에 나타나는 오류를 범할 확률을 통해서 관계가 있는지 없는지 판단한다
- 오차항의 분산이 동일해야 한다
  - 데이터에 대한 오차들을 절반으로 나눴을 때, 분산이 동일하게 이뤄지는지 확인한다
  - 이런 경우에는 독립변수를 더 추가해서 분산이 동일하게(등분산) 나오도록 만들어 줘야한다

- 오차(Residual)의 분산이 클 경우, log 를 취함으로써 압축할 필요성이 있다



## 선형회귀분석

### Gradient Descent

- 오차평면에서 공을 올려 놓았을 때 공이 굴러가는 방향(오차가 적어지는 방향)으로 가기 위해서 W와 b의 값을 수정하는 것

---

#### 간단 예제

1. ![](https://latex.codecogs.com/gif.latex?\inline&space;\dpi{150}&space;X&space;=&space;\{1,&space;2,&space;3\}\\&space;W&space;=&space;?&space;\\&space;b&space;=&space;?&space;\\&space;y&space;=&space;\{2,&space;2.5,&space;3.5\})

2. ![formula](https://latex.codecogs.com/gif.latex?\inline&space;\dpi{150}&space;XW&space;&plus;&space;b&space;=&space;y&space;\\&space;XW&space;&plus;&space;b&space;=&space;hypothesis&space;\\&space;cost&space;=&space;(hypothesis&space;-&space;y)^2&space;=&space;0)
   
3. ![](assets/eq3.png)

4. 3번에서 계산한 항목에 대해서 W와 b에 대해서 편미분을 진행

5. 파이썬으로 구한 내용
   [예제 링크](예제2/gradient_descent.ipynb)